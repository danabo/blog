<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>blogging on Dan&#39;s Notepad</title>
    <link>https://danabo.github.io/blog/tags/blogging/</link>
    <description>Recent content in blogging on Dan&#39;s Notepad</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Â©2021 Daniel Abolafia.</copyright>
    <lastBuildDate>Sat, 06 Feb 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://danabo.github.io/blog/tags/blogging/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The Reversibility Problem</title>
      <link>https://danabo.github.io/blog/posts/the-reversibility-problem/</link>
      <pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/the-reversibility-problem/</guid>
      <description>&lt;p&gt;This is my exploration into formalizing the reversibility problem, i.e. the question &amp;ldquo;Which processes are reversible?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;My long term goals are to,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;formally define what it means for any process to be reversible, regardless of equilibrium considerations;&lt;/li&gt;
&lt;li&gt;clarify the connection between information and reversibility (and by extension the connection between information and entropy);&lt;/li&gt;
&lt;li&gt;clarify (make well defined) the meaning of statements like &amp;ldquo;breaking a glass is irreversible because the entropy of the broken glass is higher than the entropy of the unbroken glass,&amp;rdquo; and &amp;ldquo;the entropy of the universe is monotonically increasing.&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\ms}{\mathscr}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\es}{\emptyset}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\th}{\theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\L}{\Lambda}&lt;br&gt;
\newcommand{\G}{\Gamma}&lt;br&gt;
\newcommand{\g}{\gamma}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\N}{\mb{N}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\H}{\mc{H}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\Z}{\mb{Z}}&lt;br&gt;
\newcommand{\s}{\sigma}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\tup}{\par}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[1]{_{\mid #1}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Dt}{{\Delta t}}&lt;br&gt;
\newcommand{\tr}{\rightarrowtail}&lt;br&gt;
\newcommand{\qed}{\ \ \blacksquare}&lt;br&gt;
\newcommand{\c}{\overline}&lt;br&gt;
\newcommand{\dg}{\dagger}&lt;br&gt;
\newcommand{\dd}{\mathrm{d}}&lt;br&gt;
\newcommand{\pd}{\partial}&lt;br&gt;
\newcommand{\Ue}{U_{\text{ext}}}&lt;br&gt;
\newcommand{\Ui}{U_{\text{int}}}&lt;br&gt;
\newcommand{\Us}{U_{\text{sys}}}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;With goal #1 I am interested in being able to ask (make well posed) thermodynamic-type questions of non-equlibrium systems. Even if those questions don&amp;rsquo;t have tractable answers, does being able to precisely formulate those questions (as well as what an answer looks like) open up new directions on course-grained (effective theory) non-equlilibrium thermodynamics? Does doing this allow us to make any progress towards the thermodynamics of living systems (i.e. open systems far from equilibrium) ? In the philosophical direction, does formalizing this problem in generality allow for the laws of thermodynamics (or some version of them) to be derived from the laws of classical mechanics?&lt;/p&gt;
&lt;p&gt;With goals #2 and #3, I am interested in being able to answer philosophical (specifically interpretational questions) about physics and thermodynamics - specifically the role information plays, whether thermodynamics (and statistical mechanics in general) is anthropocentric (i.e. dependent on the beliefs/models of an agent), and whether the phenomenon of irreversibility and its quantitative property, entropy, generalize well beyond thermodynamics and touch on the fundamental nature of reality, ala the arrow of time and limits on our ability (as intelligent systems) to control the environment around us. Finally, is there a precise argument to be made as to how irreversible processes can exist in classical mechanics, which has &lt;a href=&#34;https://en.wikipedia.org/wiki/Time_reversibility&#34;target=&#34;_blank&#34;&gt;time-reversible dynamics&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;reverisibility-and-thermodynamics&#34;&gt;Reverisibility and Thermodynamics&lt;/h1&gt;
&lt;p&gt;The importance of reversibility in thermodynamics is due to its relationship with (energy) efficiency. The energy efficiency of a process that converts an energy source into &amp;ldquo;useful&amp;rdquo; work (where &amp;ldquo;useful&amp;rdquo; is relative to a goal-driven entity) is the ratio of useful work extracted to energy consumed (both measured in Joules).&lt;/p&gt;
&lt;p&gt;The canonical problem in thermodynamics is to determine the efficiency of a a process that uses energy from a heat source to move a piston against some resistance (e.g. pushing mass against gravity or moving the wheels of a locomotive). The heat source could, for instance, come from burning fuel (converting chemical potential into heat energy). The more heat energy that goes into useful work (e.g. the piston), the higher the efficiency of the engine. The theoretical limit on efficiency for any given transformation is the efficiency of a reversible process that achieves it.&lt;/p&gt;
&lt;p&gt;(In general reversible processes are not perfectly efficient, i.e. not all all input energy is converted to useful work. E.g. see &lt;a href=&#34;&#34; class=&#34;broken&#34;&gt;Carnot Cycle&lt;/a&gt;. However, in a reversible process, all the wasted energy can be recovered if the transformation is reversed.),&lt;/p&gt;
&lt;p&gt;In classical thermodynamics, entropy is a quantity (property of a system) defined out of the need to determine which processes are reversible. The role of entropy in thermodynamics is this: any process that results in a net zero change in entropy is reversible. Positive changes in entropy during a process indicate irreversibility (and negative changes in entropy require positive changes in entropy elsewhere).&lt;/p&gt;
&lt;p&gt;Statistical thermodynamics sets out to explain what entropy is in terms of the low-level rules (fine-grained representation) of classical mechanics, and to derive all the laws of thermodynamics from classical mechanics. However, as a subfield of statistical mechanics, it has another goal: derive simplified representations of high-dimensional (many degrees of freedom) complicated systems s.t. predictions of behavior can be made solely based on that simplified representation. This is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Coarse-grained_modeling&#34;target=&#34;_blank&#34;&gt;course-graining&lt;/a&gt; (course-grained representations could be called &lt;a href=&#34;https://en.wikipedia.org/wiki/Effective_theory&#34;target=&#34;_blank&#34;&gt;effective theories&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For example, rather than modeling a gas with millions of particles, it is much easier (and tractable) to model an ideal gas described by just a handful of quantities: temperature, volume, pressure, internal energy, and entropy. The course-grained theory needs to be able to predict the time-evolution of these quantities without referring to the fine-grained theory (so that we avoid modeling millions of particles). However, this course-grained representation of the gas will only make accurate predictions within a certain regime. It fails to model gasses outside of equilibrium where these course-grained quantities cease to be well-defined.&lt;/p&gt;
&lt;p&gt;I suspect that the philosophical problems I mentioned above are muddled by conflation between course-grained models as instrumental representations (they are useful approximations) and course-grained models as meta-physical assertions about what things really are. For instance, in classical thermodynamics the entropy of a gas is only well-defined when the gas is at equilibrium, but there is a strong impulse to want to generalize the idea of entropy as a universal and fundamental property of things in the universe - things that happen cannot be undone because the entropy of those things has increased. And more striking, while energy in the universe may be conserved, it becomes less useful over time because the entropy of the universe is increasing. Is entropy a well-defined concept in these use-cases?&lt;/p&gt;
&lt;p&gt;One avenue towards seeking a general understanding of entropy is to pose the reversibility problem in general - i.e. for arbitrary processes. Although equilibrium or other simplifying assumptions are not necessary to pose the problem, but determining if a process is reversible will likely require course-grained representations to make reasoning about it tractable. It seems to me that a fine-grained definition of reversibility (and entropy if it exists) is useful for clarifying the meaning of things and what we are doing (philosophical considerations), and course-grained representations are useful for making calculations and predictions tractable.&lt;/p&gt;
&lt;h2 id=&#34;towards-defining-reversibility&#34;&gt;Towards Defining Reversibility&lt;/h2&gt;
&lt;p&gt;What do we mean when we say some process (done to a system) is reversible or irreversible? I posit the following answer: a reversible (forward) process has a corresponding reverse process s.t. the combined forward+reverse process can be repeated forever.&lt;/p&gt;
&lt;p&gt;That answer by itself does not necessarily imply that the system being transformed is actually returned to its initial state (start of the forward process) at the end of the reverse process. For example, consider a chaotic closed system like the &lt;a href=&#34;https://en.wikipedia.org/wiki/Double_pendulum&#34;target=&#34;_blank&#34;&gt;double pendulum&lt;/a&gt;. The pendula will move through space in a &lt;a href=&#34;https://physics.stackexchange.com/a/363497/55723&#34;target=&#34;_blank&#34;&gt;non-repeating way&lt;/a&gt; forever. Since the system is closed, there is no exchange of energy with the outside, and so it can in principle &amp;ldquo;run&amp;rdquo; forever.&lt;/p&gt;
&lt;p&gt;Clearly we need a second condition on reversibility. This condition will be motivated by our interest in reversibility in the first place: optimal efficiency of transformations converting stored energy into useful work. The word &amp;ldquo;useful&amp;rdquo; indicates an agent-relative goal (i.e. anthropocentrism). This condition second condition is then that the forward process put the system in a desired state (where useful work is extracted), and that the reverse process undo this useful work (returning the energy to its initial source), thereby guaranteeing optimal theoretical efficiency of the forward process.&lt;/p&gt;
&lt;p&gt;This second leads to two implications about the system:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;That the system is interacting with the outside world in some way, i.e. it does work on the outside world. This means we must also consider and define the immediate boundary between system and outside, which we call the &lt;em&gt;environment&lt;/em&gt; of the system.&lt;/li&gt;
&lt;li&gt;The useful work done during the forward process would not be undone by itself, so the reverse process requires some sort of agent-driven change in the system&amp;rsquo;s environment that induces the reverse process to happen. In practice, the forward and reverse processes are both driven by an agent via the environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The inclusion of an environment (which is itself an open system, being the boundary between system and universe) makes defining reversibility in terms of a fine-grained representation (i.e. classical mechanics) a much greater challenge, simply because formalizing environments in the same fine-grained representation is anywhere between challenging and intractable.&lt;/p&gt;
&lt;p&gt;Furthermore, the reversibility of the system now also depends on the repeatibility of the environment. By that I mean, with every cycle of the forward+reverse process the environment needs to behave the same w.r.t. its interaction with the system. Of course, the entire universe beyond the system&amp;rsquo;s environment need not repeat, so this presents a problem of what it means for the system&amp;rsquo;s environment to be reversed along with the system.&lt;/p&gt;
&lt;p&gt;I will expand on these difficulties arising from formalizing the environment further later in the post. In the next section, I will naively formulate an environment and show where this breaks down.&lt;/p&gt;
&lt;h1 id=&#34;naive-formulation&#34;&gt;Naive Formulation&lt;/h1&gt;
&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;
&lt;h3 id=&#34;canonical-coordinates&#34;&gt;Canonical Coordinates&lt;/h3&gt;
&lt;p&gt;In everything that follows I&amp;rsquo;m dealing only with classical mechanics. My goal is to define a system (in generality), its environment, and what it means for a process the system undergoes to be reversible - all in terms of the fine-grained representation we call classical mechanics (specifically Hamiltonian or Lagrangian mechanics). In general, we can describe a system with &lt;a href=&#34;https://en.wikipedia.org/wiki/Canonical_coordinates&#34;target=&#34;_blank&#34;&gt;cannonical coordinates&lt;/a&gt; (or &lt;a href=&#34;https://en.wikipedia.org/wiki/Generalized_coordinates&#34;target=&#34;_blank&#34;&gt;generalized coordinates&lt;/a&gt;) and a &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamiltonian_mechanics#Overview&#34;target=&#34;_blank&#34;&gt;Hamiltonian&lt;/a&gt; (or &lt;a href=&#34;https://en.wikipedia.org/wiki/Lagrangian_mechanics#The_Lagrangian&#34;target=&#34;_blank&#34;&gt;Lagrangian&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Let the state of some system be described by a real-valued tuple $\o  = (\o_1,\o_2,\dots,\o_{2n}) = (q_1, q_n, p_1, p_n) \in \O$, where $\O$ is the system&amp;rsquo;s state space (set of all valid states), and the coordinates $q_i$ are degrees of freedom of that system (e.g. positions or orientations) with $p_i$ being the corresponding momenta of those degrees of freedom. In order for this system to be properly described by classical mechanics, each degree of freedom needs to be &lt;em&gt;intertial&lt;/em&gt;, meaning that they have momenta which change in the presence of a force.&lt;/p&gt;
&lt;p&gt;(Typically $p_i = m_i\dot{q}_i$ where $m_i$ is the intertial mass of the $i$-th degree of freedom, and $\dot{q}_i$ is the time-derivative of $q_i$. But technically, the relationship between $q_i$ and $p_i$ is &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamiltonian_mechanics#Phase_space_coordinates_%28p,q%29_and_Hamiltonian_H&#34;target=&#34;_blank&#34;&gt;determined by the given Hamiltonian&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;In my notation, I am supposing that $q_i$ may itself be a scalar, 2-tuple or 3-tuple depending on whether it represents a spatial coordinate in 1D, 2D or 3D space, or some other sort of degree of freedom (e.g. angle of orientation or distance between two bodies).&lt;/p&gt;
&lt;h3 id=&#34;the-hamiltonian&#34;&gt;The Hamiltonian&lt;/h3&gt;
&lt;p&gt;The dynamics of the system (its possible trajectories through time) are fully determined by a collection of kinetic energy and potential energy functions of the system&amp;rsquo;s state (and time). When these terms are summed, we get the system&amp;rsquo;s total energy (i.e. the Hamiltonian).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;internal&lt;/em&gt; dynamics of the system (how the components of the system interact with each other irrespective of the environment) are specified with an internal time-independent energy term $\Ui:\O\to\R$, which is a function mapping  states of the system to potential energies. The qualifier &amp;ldquo;time-independent&amp;rdquo; indicates that $\Ui$ is not a function of time, meaning that the internal dynamics of the system satisfy &lt;a href=&#34;https://en.wikipedia.org/wiki/Time_translation_symmetry&#34;target=&#34;_blank&#34;&gt;time-translational invariance&lt;/a&gt; (the system has no notion of any absolute time, i.e. the system will do what it does regardless of the age of the universe).&lt;/p&gt;
&lt;p&gt;We also must specify the time-independent kinetic energy term $T:\O\to\R_{\geq0}$ and &lt;em&gt;external&lt;/em&gt; time-dependent potential energy term $\Ue:\O\times\R\to\R$, the latter being a function mapping state and time to potential energy. The qualifier &amp;ldquo;external&amp;rdquo; indicates that $\Ue$ tells us what we need to know about the system&amp;rsquo;s interaction with the outside world. That is to say, $\Ue$ fully represents all the influence the environment has on the system. For example, systems are often confined to a region of space via an extenral potential well, e.g. a gas in a box, or a system acted on by Earth&amp;rsquo;s gravity (a very big potential well).&lt;/p&gt;
&lt;p&gt;All three terms fully describe the dynamics of any process the system may undergo, where the total energy  $\H=T+\Ui+\Ue$ is the Hamiltonian of the given process. ($\mc{L}=T-\Ui-\Ue$ is the Lagrangian.) Given $\H$ (or $\mc{L}$), every possible trajectory the system can take through state space is fully determined.&lt;/p&gt;
&lt;p&gt;By default $\H:\O\times\R\to\R$ is a function of state and time, making it time-dependent. The Hamiltonian&amp;rsquo;s time-dependence is due solely to the environment. For time-independent $\Ue$ the Hamiltonian $\H$ is also time-independent (and conversely if $\H$ is time-independent then so is $\Ue$).&lt;/p&gt;
&lt;h3 id=&#34;constraints-on-the-external-potential&#34;&gt;Constraints on the external potential&lt;/h3&gt;
&lt;p&gt;To specify that $\Ue$ is an external potential is to say that it doesn&amp;rsquo;t at all determine the internal interactions of the system. Formally that means $\Ue$ does not contain &lt;em&gt;interaction energy&lt;/em&gt; terms.&lt;/p&gt;
&lt;p&gt;Interaction energy is potential energy that depend on the states of two or more degrees of freedom. For example, a potential function $U\up{i,j}(q_i,q_j)$ depending only on two DoFs $i$ and $j$ (and symmetric in its arguments) is an interaction potential (interaction potentials may also depend on momenta). One possible way to construct the internal potential $\Ui$ is to make it a sum of pair-wise interaction potentials: $\Ui(q_1,\dots,q_n,p_1,\dots,p_n)=\sum_{i&amp;lt;j} U\up{i,j}(q_i,q_j,p_i,p_j)$.&lt;/p&gt;
&lt;p&gt;We require that the external potential $\Ue$ be free of all interaction potentials. This can be satisfied by requiring that $\Ue$ be a sum of a singular potential function $U\up{i}(q_i,p_i)$ for each DoF. That is to say, we require that $\Ue = \sum_{i=1}^n U\up{i}(q_i,p_i)$.&lt;/p&gt;
&lt;p&gt;(Note that a potential function of a single spatial coordinate, $U(q)$ (either 1D, 2D or 3D), is called a &lt;a href=&#34;https://en.wikipedia.org/wiki/Field_%28physics%29&#34;target=&#34;_blank&#34;&gt;field&lt;/a&gt;. When $U(q)$ is time-independent, it is a constant field.)&lt;/p&gt;
&lt;p&gt;Furthermore, in many situations we want to specify that some degrees of freedom are &lt;em&gt;indistinguishable&lt;/em&gt;, meaning that swapping them does not change the dynamics of the system (and the outside universe cannot distinguish between them). For example, in a gas containing N identical particles, the external potential cannot affect each particle differently.&lt;/p&gt;
&lt;p&gt;In general, if DoF $i$ and $j$ are specified as indistinguishable, then we require that their singular potential functions are equal, i.e. $U\up{i}(q,p)=U\up{j}(q,p)$ for all $q,p$. In general, the indistingiushability of DoFs in a system can be fully specified by a set of permutations of coordinate indices for which the dynamics of the system are invariant.&lt;/p&gt;
&lt;h3 id=&#34;trajectories-and-propagators&#34;&gt;Trajectories and propagators&lt;/h3&gt;
&lt;p&gt;It is more convenient to represent the trajectories of a process explicitly. A &lt;em&gt;trajectory&lt;/em&gt; is a function $\s:\R\to\O$ from time to state.&lt;/p&gt;
&lt;p&gt;The relationship between the possible trajectories of a process and the provided Hamiltonian is not straightforward. For this reason, it is easier to work with &lt;em&gt;propagators&lt;/em&gt;. A propagator $\t_t:\O\to\O$ is a function mapping state to state - specifically, taking a state at time $0$ and outputting the state of the system at time $t$.&lt;/p&gt;
&lt;p&gt;The possible trajectories of the system are fully determined by the family of propagators $\set{\t_t\mid t\in\R}$ - one for every time $t$. The time-dependent Hamiltonian $\H$ uniquely determines the family of propagators.&lt;/p&gt;
&lt;p&gt;Note that this is a family of time-dependent propagators since they give time-evolution w.r.t. to the absolute time $t=0$. We can derive the propagator mapping between any initial time $t_i$ and final time $t_f$ in terms of propagators relative to time $0$, specifically $\t_{t_i\to t_f}=\t_{t_f}\circ\t_{t_i}^{-1}$.&lt;/p&gt;
&lt;p&gt;If $\H$ is time-independent, then we induce a family of time-independent propagators $\set{\t_\Dt\mid \Dt\in\R}$ which do not depend on the absolute time of the given state. In this case $\t_{t_i\to t_f}=\t_{t_f-t_i}$.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;valid trajectory&lt;/em&gt; $\s:\R\to\O$ is consistent will all propagators, i.e. satisfies $\s(t_2)=\t_{t_1\to t_2}(\s(t_1))$ for all $t_1,t_2 \in \R$.&lt;/p&gt;
&lt;p&gt;When the system is isolated (i.e. total energy is constant), the system&amp;rsquo;s trajectory is uniquely determined by specifying its state at some time. That is to say, if the system is in state $\o_t$ at time $t$, there exists exactly one trajectory $\s$ s.t. $\s(t)=\o_t$. Then at time $t$, there is a unique trajectory for every state $\o_t \in\O$. An equivalent statement is that all of the valid trajectories of the system are non-intersecting, i.e. $\s_1(t) \neq \s_2(t)$ for all valid trajectories $\s_1,\s_2$ and for all times $t\in\R$. This will be true so long as every propagator $\t_t$ is a bijection.&lt;/p&gt;
&lt;h3 id=&#34;example-orbiting-bodies&#34;&gt;Example: Orbiting bodies&lt;/h3&gt;
&lt;p&gt;To make the terms $T,\Ui$ and $\Ue$ more concrete, let&amp;rsquo;s consider an example.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s model a system of $n$ small bodies in orbit around a star by supposing the star is fixed and generates a static &lt;a href=&#34;https://en.wikipedia.org/wiki/Newton%27s_law_of_universal_gravitation&#34;target=&#34;_blank&#34;&gt;gravity potential&lt;/a&gt;. The small bodies produce gravitational attraction between themselves (also via gravitational potentials).&lt;/p&gt;
&lt;p&gt;We have a kinetic energy term $T(p_1,\dots,p_n)=\sum_{i=1}^n\frac{1}{2m_i}p_i^2$ where $m_i$ is the mass of the $i$-th body, an internal potential term  $\Ui(q_1,\dots,q_n)=\sum_{i\neq j} G\frac{m_im_j}{\abs{q_i-q_j}^2}$, and a time-independent external potential term $\Ue(q_1,\dots,q_n)=\sum_{i=1}^n G\frac{Mm_i}{\abs{q_i}^2}$, where the star has mass $M \gg m_i$ and is positioned at the origin (and $G$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Gravitational_constant&#34;target=&#34;_blank&#34;&gt;gravitational constant&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;We may instead make the star move along a fixed path $x(t)$, giving us a time-dependent external potential $\Ue(q_1,\dots,q_n;\ t)=\sum_{i=1}^n G\frac{Mm_i}{\abs{x(t)-q_i}^2}$.&lt;/p&gt;
&lt;h2 id=&#34;reversibility---naive-definition&#34;&gt;Reversibility - Naive Definition&lt;/h2&gt;
&lt;p&gt;Now we are ready to define reversibility. Suppose we are given the specification of a process, operating from time $t=\th$ to $t=0$ (with $\th &amp;lt; 0$), with a time-dependent Hamiltonian $\H=V+\Ui+\Ue$, which induces the family of time-dependent propagators $\set{\t_t\mid t\in\R}$. That is to say, $\Ue$ is defined on the time interval $[\th,0]$.&lt;/p&gt;
&lt;p&gt;When we talk about reversing a process on a large system like a gas, we don&amp;rsquo;t actually care about the system retracing in reverse the exact same trajectory that it took. We also don&amp;rsquo;t care about returning the gas particles to their exact initial positions. Remember, our interest in reversibility is that it lets us determine the theoretically optimal efficiency of some transformation of energy from a source into useful work. Whichever starting states and trajectories allow the system to do and reverse that work forever are all equally good to us. This brings us to the concept of a &lt;em&gt;state region&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A state region is a subset of the entire state space $\O$ of the system. State regions represent information about state. Specifically, a state region $\L\subseteq\O$ represents the knowledge that the state of the system $\o$ is in $\L$ (and not in the complement $\O-\L$). For now, just think of state regions as encoding what aspects of the system&amp;rsquo;s state we care about, motivated by the work we want the system to perform. (See &lt;a href=&#34;#the-interpretation-of-state-regions&#34;&gt;#The Interpretation of State Regions&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&amp;ldquo;State region&amp;rdquo; is essentially a synonym for &amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/Microstate_%28statistical_mechanics%29&#34;target=&#34;_blank&#34;&gt;macrostate&lt;/a&gt;&amp;rdquo; from thermodynamics. For example, for a gas at some temperature and volume, $\L$ would be the set of all gas states in equilibrium at that temperature and volume. Or in the case of the Szilard engine, $\L$ is the set of all left-side (or right-side) positions of the container. This is an example of a state region representing a single bit of information about state.&lt;/p&gt;
&lt;p&gt;So in addition to providing the Hamiltonian $\H=V+\Ui+\Ue$, with $\Ue$ defined on the time-interval $[\th,0]$, we also suppose an initial state region $\L_{\th}$ is provided, i.e. $\L_{\th}\subseteq\O$ is the set of potential initial states the system is in at time $t=\th$. The state region of the system at the end of the forward process (time $t=0$) is determined: $\L_0 = \t_{\th\to0}(\L_\th)=\set{\t_{\th\to0}(\o_\th) \mid \o_\th \in \L_\th}$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now we come to the definition of reversibility:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The forward process is reversible iff there exists a time $\phi &amp;gt; 0$ and a time-dependent $\Ue$ defined on the time interval $(0,\phi)$ (and satisfying the &lt;a href=&#34;#constraints-on-the-external-potential&#34;&gt;#Constraints on the external potential&lt;/a&gt; specified above) s.t. $\t_{0\to\phi}(\L_0)=\L_\th$ (the behavior of all the propagators on the time interval $(0,\phi]$ is determined by the choice of $\Ue$).&lt;/p&gt;
&lt;p&gt;We could also formulate reversibility a bit more abstractly. Given the KE term $T$ and internal PE term $\Ui$, and an initial state region $\L\up{1}$ and intermediary state region $\L\up{2}$, we want to find an external potential $\Ue$ defined on all time $(-\infty,\infty)$ s.t. the system oscillates periodically from $\L\up{1}$ to $\L\up{2}$ and back to $\L\up{1}$ (the combined forward and reverse process). Formally, for the chosen $\Ue$ let $\L(t)=\t_{0\to t}(\L\up{1})$. Then the transformation from $\L\up{1}$ to $\L\up{2}$ has a reversible process iff there exits $\Ue$ and time intervals $\Dt_f$ and $\Dt_r$ s.t. $\L(k(\Dt_f+\Dt_r))=\L(0)=\L\up{1}$ for all $k\in\Z$ and $\L(\Dt_f+k(\Dt_f+\Dt_r))=\L(\Dt_f)=\L\up{2}$ for all $k\in\Z$.&lt;/p&gt;
&lt;p&gt;The reversibility problem is a special case of a more general problem:&lt;br&gt;
Given $\O$, $T$, $\Ui$, $\L_i$ (initial) and $\L_f$ (final), does there exist time interval $\Dt$ and $\Ue$ defined on $[t,t+\Dt]$ s.t. $\L_f=\t_{t\to t+\Dt}(\L_i)$ ? (choice of $t \in\R$ here is arbitrary.)&lt;/p&gt;
&lt;h3 id=&#34;example-free-expansion&#34;&gt;Example: Free Expansion&lt;/h3&gt;
&lt;p&gt;A gas expands to fill a vacuum, a.k.a. &lt;a href=&#34;https://en.wikipedia.org/wiki/Joule_expansion&#34;target=&#34;_blank&#34;&gt;Joule expansion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The system is gas (a collection of N particles) confined to a container.&lt;br&gt;
The internal potential produces elastic collisions between particles. The external potential produces the walls of the container.&lt;/p&gt;
&lt;p&gt;The elastic collisions between particles can be achieved by making the internal potential a repulsive inverse-square potential between each pair of particles, i.e. $\Ui\up{i,j}(q_i,q_j)\propto \frac{1}{\abs{q_i-q_j}^2}$ for all $i,j$. A simpler model would turn interactions off when particles are outside of collision zones and turn interactions on when they are inside, e.g. $\Ui\up{i,j}(q_i,q_j)= \begin{cases}\frac{1}{\abs{q_i-q_j}^2}-\frac{1}{r^2} &amp;amp; \abs{q_i-q_j} &amp;lt; r \\ 0 &amp;amp; \abs{q_i-q_j}\geq r\end{cases}$ for all $i,j$.&lt;br&gt;
As $r\to 0$ this potential approaches an &lt;a href=&#34;https://en.wikipedia.org/wiki/Elastic_collision&#34;target=&#34;_blank&#34;&gt;instantaneous collision&lt;/a&gt; model.&lt;/p&gt;
&lt;p&gt;Similarly for the walls, a steep potential hill can be placed within some zone around the walls. Taking the width of this zone to 0 gives us an idealized infinitely thin wall with infinite repulsive force. (see diagrams, and &lt;a href=&#34;https://danabo.github.io/blog/posts/why-doesnt-uncopying-defeat-the-2nd-law/#the-reversibility-game&#34;&gt;Why Doesn&amp;#39;t Uncopying Defeat The 2nd Law#the-reversibility-game&lt;/a&gt; for more discussion.)&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/gas_container_potential.jpg&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;Steep potential hills make up the walls of the box holding a gas.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/potential_wall.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;An idealized wall is an infinitely steep and infinitely high potential hill (depicted on the right). This can be constructed by taking the limit of a finite hill (left) as its height goes to infinity and its width goes to zero.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;First to describe the forward process on $t=-100$ to $0$, we suppose the container is fixed (external potential $\Ue$ is a constant field) for time $t \in (-\infty,-100)$.  At time $t=-100$ the system is in an equilibrium state at temperature $T$ and approximately uniformly filling the container (with some spatial volume $V$). The set of all such states at time $-100$ is the state region $\L\up{1}$. Formally, let $\L\up{1}$ be the set of all positions and momenta of the N particles s.t. the gas is in equilibrium with a constant temperature $T$ and uniformly filling the container. Equilibrium states are those with &lt;a href=&#34;https://en.wikipedia.org/wiki/Ergodicity&#34;target=&#34;_blank&#34;&gt;ergodic&lt;/a&gt; trajectories. Specifically, let&amp;rsquo;s make $\L\up{1}$ the set of all such states which are ergodic over the time interval $(-\infty,-100)$ (i.e. ergodic into the past). Note that specifying that the gas is at temperature $T$ amounts to restricting ourselves to gas states s.t. the average KE is proportional to $T$ (and average KE continues to ergodically bounce around $T$ forever if the container is held fixed).&lt;/p&gt;
&lt;p&gt;At time $t=-100$, the container suddenly changes so that its spatial volume increases. This creates a vacuum for the gas to expand into.  The gas expands to fill the larger container during the interval $t\in[-100,0]$ (supposing $100$ units of time is enough for the gas to approach close to equilibrium in the larger container). We have that $\Ue$ is also a constant field on the time interval $[-100,0]$. We can determine $\L\up{2}$, the state region at time $t=0$, using a propagator, i.e. $\L\up{2}=\t_{(-100)\to0}(\L\up{1})$.&lt;/p&gt;
&lt;p&gt;This forward process is reversible if there exists $\Ue$ defined on the time-interval $(0,\phi]$ s.t. $\t_{0\to\phi}(\L\up{2})=\L\up{1}$. This would be the reverse process.&lt;/p&gt;
&lt;p&gt;We know from classical thermodynamics that the forward process from $\L\up{1}$ to $\L\up{2}$ is irreversible. In my naive formulation of the reversibility problem, there is not much we will be able to do with the external potential except to push the particles around. However, pushing particles back to their smaller volume transfers extra KE to them, which means the gas temperature rises (see &lt;a href=&#34;https://danabo.github.io/blog/posts/szilard-cycle-particle-piston-interaction-model/#particles-colliding-with-moving-walls&#34;&gt;Szilard Cycle Particle-Piston Interaction Model#particles-colliding-with-moving-walls&lt;/a&gt;). One would then have to figure out how to return the extra KE back to the environment.&lt;/p&gt;
&lt;h3 id=&#34;example-isentropic-adiabatic-expansion&#34;&gt;Example: Isentropic (adiabatic) Expansion&lt;/h3&gt;
&lt;p&gt;A gas is expanded/compressed by a driven piston. See &lt;a href=&#34;https://danabo.github.io/blog/posts/szilard-cycle-particle-piston-interaction-model/#simulation&#34;&gt;Szilard Cycle Particle-Piston Interaction Model#simulation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This process trades $q_i$ volume with $p_i$ volume while keeping total state volume fixed. A wall pushing against (compressing) gas particles adds KE to them. A wall pulling away from (expanding) gas particles absorbs KE from them. In classical thermodynamics, this process is reversible.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220217150254.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;An example particle trajectory (blue) with a movable wall (orange) moving along a predefined path. Here the wall is moving away from the particle. When the particle collides with the moving wall, the particle loses KE.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220301134051.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;An example particle trajectory (blue) with a movable wall (orange) moving along a predefined path. Here the wall is moving towards the particle. When the particle collides with the moving wall, the particle gains KE.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;video controls autoplay loop src=&#34;../../isentropic_expansion_one_particle.mp4&#34; caption=&#34;How the state region (position and velocity) of a 1D one-particle gas changes over time as a movable wall pulls away. As the container length increases, the particle slows down and the velocity range of this state region shrinks. The spatial range of the state region grows. The total state area should remain constant during the transformation.&#34; width=&#34;100%&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;p&gt;As in the previous example, we let $\L\up{1}$ be the set of states in equilibrium (ergodic infinitely far into the past) at time $t=-100$ with temperature $T$ and spatial volume $V$. $\Ue$ is a fixed field during the time interval $(-\infty,-100)$. On the interval $[-100,0]$, $\Ue$ changes as a function of $t$ s.t. one of the walls of the container pushes or pulls along a fixed trajectory, until reaching its final position at time $t=0$. The resulting potential region is again determined by the propagator $\L\up{2}=\t_{-100\to0}(\L\up{1})$.&lt;/p&gt;
&lt;p&gt;Another result from classical thermodynamics is that this process, isentropic expansion/compression, is reversible. One possible reverse process defines $\Ue(\o;\ t)=\Ue(\o;\ -t)$ on the time interval $(0,100]$, so that the wall backtracks its movement from the forward process, returning to its initial position at time $t=-100$.&lt;/p&gt;
&lt;p&gt;(Note that an alternative way to model isentropic expansion/compression is to make the moving wall an inertial object with mass, and vary the mass of the wall as a function of its position. See &lt;a href=&#34;&#34; class=&#34;broken&#34;&gt;Carnot Cycle#2-isentropic-adiabatic-expansion&lt;/a&gt;. The wall is now part of the system. By altering the mass function of the wall, the agent drives the process from the outside.)&lt;/p&gt;
&lt;h3 id=&#34;issues&#34;&gt;Issues&lt;/h3&gt;
&lt;p&gt;I call the above formulation of the reversibility problem naive because,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There are environments and environment interactions which we cannot be modeled.&lt;/li&gt;
&lt;li&gt;Energy transfers between different parts of the environment are not accounted for.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Some examples of environments we are not able to model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Isothermal_process&#34;target=&#34;_blank&#34;&gt;Isothermal expansion/compression&lt;/a&gt; (requires an infinite heat reservoir).&lt;/li&gt;
&lt;li&gt;Environment noise, e.g. thermal noise or shape uncertainty in the container walls of a gas. (see &lt;a href=&#34;https://danabo.github.io/blog/posts/why-doesnt-uncopying-defeat-the-2nd-law/#environment-noise&#34;&gt;Why Doesn&amp;#39;t Uncopying Defeat The 2nd Law#environment-noise&lt;/a&gt;.)&lt;/li&gt;
&lt;li&gt;Measurements of system state (the environment gains information about the system&amp;rsquo;s state). This includes any kind of &lt;a href=&#34;https://en.wikipedia.org/wiki/Maxwell%27s_demon&#34;target=&#34;_blank&#34;&gt;demon&lt;/a&gt;. (see &lt;a href=&#34;https://danabo.github.io/blog/posts/why-doesnt-uncopying-defeat-the-2nd-law/#measurement&#34;&gt;Why Doesn&amp;#39;t Uncopying Defeat The 2nd Law#measurement&lt;/a&gt; and &lt;a href=&#34;https://danabo.github.io/blog/posts/why-doesnt-uncopying-defeat-the-2nd-law/#superdemons&#34;&gt;Why Doesn&amp;#39;t Uncopying Defeat The 2nd Law#superdemons&lt;/a&gt;.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Heat reservoirs also mess up this formulation of reversibility because irreversible energy transfers between parts of the environment could take place. For instance, in &lt;a href=&#34;#example-free-expansion&#34;&gt;#Example Free Expansion&lt;/a&gt;, we could perform isothermal compression to put the gas back into its original container at its original temperature. That means the gas is in thermal contact with a heat reservoir at constant temperature. The energy transferred to the gas as KE during compression is absorbed by the heat reservoir. If the heat reservoir is considered part of the environment, then we are ignoring the conversion of potential energy in the moving wall to heat energy of the reservoir. That distinction is needed for free expansion to be considered irreversible.&lt;/p&gt;
&lt;p&gt;Remember, our primary interest is in the reversibility of processes that convert an energy source into useful work. If both the energy source and the thing work is being done to are considered part of the environment, then it wouldn&amp;rsquo;t make sense to suppose we are indifferent to all the ways energy may be moved around in the environment. It is not enough to suppose that the system is reversed simply if its energy gain/loss is returned to the environment - we care about where in the environment it goes.&lt;/p&gt;
&lt;h1 id=&#34;other-formulations&#34;&gt;Other Formulations&lt;/h1&gt;
&lt;p&gt;There are two potential avenues towards resolving the above issues with my naive formulation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Model the environment as part of the system, i.e. model the environment and system together as an isolated parent system.&lt;/li&gt;
&lt;li&gt;Model the environment as a conditional potential.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I don&amp;rsquo;t have an issue-free solution at present. Below I will detail how these two approaches work and their pros and cons.&lt;/p&gt;
&lt;h2 id=&#34;1-model-environmentsystem-as-a-joint-system&#34;&gt;1. Model environment+system as a joint system&lt;/h2&gt;
&lt;p&gt;Everything in the outside that has a causal relationship with the system is explicitly modeled in the physics. That is to say, we suppose that the environment has $m$ degrees of freedom, so that the joint state of the system and environment is $\o  = (\o_1,\o_2,\dots,\o_{2n+2m}) = (q_1, q_{n+m}, p_1, p_{n+m}) \in \O$. The provided Hamiltonian (and induced propagators) is a function of all the coordinates of both the system and environment.&lt;/p&gt;
&lt;p&gt;The Hamiltonian of the joint system must now be time-independent, implying a time-independent external potential term. This allows for some influence from the outside (outside of the environment), but in a limited fashion. The external potential is a sum of fixed (in time) potential fields, so there is no outside to drive the system anymore.&lt;/p&gt;
&lt;p&gt;Pros&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If we are able to model the physics of the environment, then the definition of reversibility I gave in &lt;a href=&#34;#reversibility---naive-definition&#34;&gt;#Reversibility - Naive Definition&lt;/a&gt; works.&lt;/li&gt;
&lt;li&gt;We can properly model environment uncertainty (e.g. noise) with a state region on the joint system+environment state space.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Infinite heat reservoirs require infinite degrees of freedom in the environment, i.e. $m=\infty$. This can easily make the definition of the joint system ill posed (e.g. the Hamiltonian can become infinite).&lt;/li&gt;
&lt;li&gt;The system+environment must be otherwise isolated (except for the fixed external potential). That means we cannot model open systems, which is something of particular interest in the thermodynamics of living systems.&lt;/li&gt;
&lt;li&gt;The model of the environment needs to be physically accurate. That means no more walls moving along pre-programmed paths (equivalent to inertial walls with infinite mass), like in &lt;a href=&#34;#example-isentropic-adiabatic-expansion&#34;&gt;#Example Isentropic adiabatic Expansion&lt;/a&gt;. Also no more discrete degrees of freedom, since all the coordinates must be real-valued and the Hamiltonian must be a smooth function. That means the physical memory bits, like in the Szilard engine (&lt;a href=&#34;https://danabo.github.io/blog/posts/reversible-szilard-cycle-problem/#uncopying&#34;&gt;Reversible Szilard Cycle Problem#uncopying&lt;/a&gt;), must be modeled as some kind of continuous process (e.g. magnets). That can be quite cumbersome.&lt;/li&gt;
&lt;li&gt;It is not straightforward to have an outside agent drive the forward and reverse processes, though it is still technically possible. In &lt;a href=&#34;#example-isentropic-adiabatic-expansion&#34;&gt;#Example Isentropic adiabatic Expansion&lt;/a&gt;, at the bottom, I briefly mentioned that an agent can drive the interaction between the gas an an inertial wall (movable wall with finite mass whose degree of freedom is included in the Hamiltonian) by modifying the wall&amp;rsquo;s mass as a function of its position. The generalization of that operation is to modify the Hamiltonian at moments in time, e.g. at time $t$, in a way such that the kinetic energy and potential energy of each $i$-th coordinate is unchanged for states in the state region $\L(t)$ at time $t$. In other words, we are creating a time-dependent Hamiltonian as piecewise (in time) stitching together of time-independent Hamiltonians within various time intervals, so that the boundaries between the piecewise segments have a continuous transition (in this case, all the individual KE and PE for every coordinate is continuously transitioned between Hamiltonians).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-model-the-environment-as-a-conditional-potential&#34;&gt;2. Model the environment as a conditional potential&lt;/h2&gt;
&lt;p&gt;A conditional external potential function conditions its own trajectory on the trajectory of the system. There are a few ways to formally define conditional potentials:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\Ue(\o;\ \s_{(-\infty,t]}, t)$ is a function of the entire history of the system, $\s_{(-\infty,t]} : (-\infty,t]\to\O$, which is a segment of the system&amp;rsquo;s trajectory defined on the time interval $(-\infty,t]$. Think of this as associating a different trajectory of $\Ue$ to every trajectory of the system. This allows the external potential&amp;rsquo;s time evolution to condition on what the system is doing, essentially allowing the environment to measure the state of the system. Given an initial state region, the external potential can fork (behave differently for different system trajectories stemming from the state region), resulting in uncertainty on $\Ue$. We could implement environment noise as initial uncertainty on $\Ue$, i.e. we have a set of initial potential functions $\Ue$ as well as an initial state region.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The field-snapshot ${\Ue}\up{t} : \o\mapsto\Ue(\o;\ t)$ is treated as the state of the environment. The propagators time-evolve both system and environment state: $(\o&#39;, \Ue&#39;) = \t_{t_1\to t_2}(\o, \Ue)$ where $\Ue,\Ue&#39; : \O\to\R$ are time-independent external potentials.&lt;br&gt;
(this is problematic, as entropy may be absorbed into the environment and carried away so that it is no longer reflected in the external potential)&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The environment has its own state $\vec{\xi}$.&lt;br&gt;
Let $\vec{q}=(q_1,\dots,q_n)$, $\vec{p}=(p_1,\dots,p_n)$, and $\vec{\xi}$ some state vector for the environment. The environment&amp;rsquo;s state need not be inertial. $\H(\vec{q},\vec{p};\ \vec{\xi}, t)=T(\vec{p})+\Ui(\vec{q},\vec{p})+\Ue(\vec{q},\vec{p};\ \vec{\xi},t)$, where $\vec{\xi}, t$ are not inertial coordinates involved in Hamilton&amp;rsquo;s equations (not involved in the physics), but merely specify which external potential to use. ($t$ can be considered part of the environment state, e.g. if someone has a clock.)  There is a joint propagator $(\vec{q}&#39;,\vec{p}&#39;, \vec{\xi}&#39;) = \t_{t_1\to t_2}(\vec{q},\vec{p}, \vec{\xi})$.&lt;/p&gt;
&lt;p&gt;Pros&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can get away with modeling less of the environment (only need to model interactions relevant to the system). Don&amp;rsquo;t care about the state of the universe. Don&amp;rsquo;t need to reverse literally everything in the universe to reverse the system+environment. E.g. don&amp;rsquo;t need to reverse things that happened in far away galaxies or wipe the memories of people who know the process occurred.&lt;/li&gt;
&lt;li&gt;Can potentially model open environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reversibility is not longer well defined for open environments because it is not clear what it means for the environment to be reset, i.e. will the environment behave the same every time if its behavior depends on outside state which we are not modeling?
&lt;ul&gt;
&lt;li&gt;Boundary between system and environment is not well defined - is a piston part of the system or environment? Anything that cannot be repeated (requires energy that isn&amp;rsquo;t ambient in the env) is part of the system, like the piston.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mathematically unwieldy to deal with trajectories of potential fields directly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;what-is-entropy&#34;&gt;What is Entropy?&lt;/h1&gt;
&lt;p&gt;The use of state regions (subsets of state space) in the formulation of the reversibility problem above looks like &lt;a href=&#34;https://en.wikipedia.org/wiki/Boltzmann%27s_entropy_formula&#34;target=&#34;_blank&#34;&gt;Boltzmann&amp;rsquo;s definition of thermodynamic entropy&lt;/a&gt;. Instead of saying &amp;ldquo;state region&amp;rdquo;, it is standard to say &amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/Microstate_%28statistical_mechanics%29&#34;target=&#34;_blank&#34;&gt;macrostate&lt;/a&gt;&amp;rdquo;, which is a set of microstates, i.e. set of fine-grain states, i.e. elements of state space $\O$.&lt;/p&gt;
&lt;p&gt;Boltzmann defines the entropy $S$ of a finite macrostate $\L\subseteq\O$ to be&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
S \propto \log\abs{\L}\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;i.e. entropy is proportional to the log of the cardinality of $\L$.&lt;/p&gt;
&lt;p&gt;For infinite $\L$, we need a &lt;a href=&#34;https://en.wikipedia.org/wiki/Measure_%28mathematics%29&#34;target=&#34;_blank&#34;&gt;measure&lt;/a&gt; on $\O$ (in the measure-theoretic sense, not physical measurement) to give us a way to quantify sizes of state regions (**ahem**, macrostates). Let $\mu : \mc{E} \to \R_{\geq0}$ be a measure on $\O$, i.e. $\mu$ is a function from measurable subsets of $\O$ to their respective sizes (not cardinality, but more like length, area or volume for 1D, 2D or 3D regions). Briefly, $\mc{E}$ is a set of measurable subsets of $\O$, and the tuple $(\O,\mc{E},\mu)$ is called a &lt;a href=&#34;https://en.wikipedia.org/wiki/Measure_space&#34;target=&#34;_blank&#34;&gt;measure space&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then Boltzmann entropy takes the general form&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
S \propto \log\mu(\L)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;When $\L$ is finite, we can define $\mu$ to be the &lt;a href=&#34;https://en.wikipedia.org/wiki/Counting_measure&#34;target=&#34;_blank&#34;&gt;counting measure&lt;/a&gt; (uses set cardinality as set size) to get back Boltzmann&amp;rsquo;s definition. I hope to show in another post that this definition of entropy of state regions makes sense in the case of gas thermodynamics.&lt;/p&gt;
&lt;p&gt;In statistical thermodynamics, there is a common derivation where state space (positions and momenta) of the system (e.g. gas) is discretized into a finite state space. Then the limit of Boltzmann entropy as the discretization size goes to zero gives the entropy of the continuous system. This is equivalent to choosing a uniform measure on state space.&lt;/p&gt;
&lt;p&gt;(However, this does not make the choice of measure unique or objective, since what is considered uniform depends on choice of coordinates. E.g. going from cartesian to polar coordinates alters what is considered a uniform measure on the respective coordinate spaces. You could argue that the measure should be uniform on physical space, but then there is no unique uniform measure on canonical coordinates which don&amp;rsquo;t correspond directly to physical space.)&lt;/p&gt;
&lt;p&gt;Before this section, no mention of measures on $\O$ is made. The formulation of the reversibility problem above does not require any quantity like entropy, and does not depend on the choice of measure $\mu$ on $\O$. This allows us to avoid a pesky interpretation problem: what does $\mu$ represent and is there a unique most appropriate choice of $\mu$ for a given system? One could say that side-stepping this issue is necessary for dealing with non-equilibrium (ir)reversibility in general.&lt;/p&gt;
&lt;p&gt;The formulation above considers state regions of $\O$ for a single system. In thermodynamics it is often the case that you might consider the separate entropies of multiple different systems (including the environment), and it is common to talk about one system transferring entropy to another. Supposing the state space $\O$ contains multiple systems (each system is described by a subset of coordinate indices) and we have a state region $\L\subseteq\O$ and measure $\mu$ on $\O$, what is the entropy of each system? I propose that the entropy of a system described by coordinates $(\o_i,\dots,\o_j)$ is the log-measure of the projection of $\L$ onto $(\o_i,\dots,\o_j)$, i.e. $S\up{i,\dots,j} \propto \log\mu\Big(\bigcup\set{[\o]_{i,\dots,j}\mid\o\in\L}\Big)$ where $S\up{i,\dots,j}$ is the entropy of the subsystem occupying coordinates $i,\dots,j$, and $[\o]_{i,\dots,j}=\set{\zeta \in \O \mid (\zeta_i,\dots,\zeta_j)=(\o_i,\dots,\o_j)}$ is the set of all states sharing the coordinates $(\o_i,\dots,\o_j)$.&lt;/p&gt;
&lt;p&gt;I hope to write more about what justifies this definition of entropy in a future post: &lt;a href=&#34;&#34; class=&#34;broken&#34;&gt;Connecting Entropy And Information&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;the-interpretation-of-state-regions&#34;&gt;The Interpretation of State Regions&lt;/h1&gt;
&lt;p&gt;I briefly mentioned a generalized problem at the bottom of &lt;a href=&#34;#reversibility---naive-definition&#34;&gt;#Reversibility - Naive Definition&lt;/a&gt;. To recap, given $\O$, $T$, $\Ui$, $\L_i$ (initial) and $\L_f$ (final), does there exist time interval $\Dt$ and $\Ue$ defined on $[t,t+\Dt]$ s.t. $\L_f=\t_{t\to t+\Dt}(\L_i)$ ?&lt;/p&gt;
&lt;p&gt;The chosen state regions are seemingly agent-specific, i.e. are dependent on an agent&amp;rsquo;s goals. We could characterize them in the following way: $\L_i$ represents what the agent knows, and $\L_f$ represents what the agent wants to have happen in the future.&lt;/p&gt;
&lt;p&gt;Given $\L_i$ and $\L_f$, whether there exists a process (specified by $\Ue$) that transforms $\L_i$ to $\L_f$ should be objective, i.e. is a question about physics with a well defined answer. The same is true with the reversibility question: when what is considered successful reversal is defined, the question of whether its achievable has an objective answer.&lt;/p&gt;
&lt;p&gt;A further note, the agent&amp;rsquo;s state of information, $\L_i$, is not subjective or arbitrary. For instance, if the agent posits to know the state of the system to higher resolution then they actually do, the reliable repeatability of the transformation from states in $\L_i$ to states in $\L_f$ will not bear out in practice. Though, the agent could disregard information they have and make $\L_i$ larger than the state region representing what they know, the agent cannot pretend to have more information than they do.&lt;/p&gt;
&lt;p&gt;The general problem of reliably transforming $\L_i$ to $\L_f$ is essentially what intelligent systems (agents) try to solve. Agents seek to control their environments. That means causing changes in their environments (i.e. taking actions) so that those environments tend towards desired states. In this way, the generalization of reversibility is controllability. That too would seem to be an objective property of physical systems, once the goal of the agent is defined.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szilard Cycle Particle-Piston Interaction Model</title>
      <link>https://danabo.github.io/blog/posts/szilard-cycle-particle-piston-interaction-model/</link>
      <pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/szilard-cycle-particle-piston-interaction-model/</guid>
      <description>&lt;p&gt;Admittedly my first-pass interaction model in &lt;a href=&#34;https://danabo.github.io/blog/posts/reversible-szilard-cycle-problem/#part-ii-information-is-never-lost&#34;&gt;Reversible Szilard Cycle Problem#part-ii-information-is-never-lost&lt;/a&gt; is not physically realistic. By interaction model, I mean how the particle and piston interact over time. Here I explore some alternative interaction models that try to be more realistic. My main question is whether which-side information is still preserved.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\ms}{\mathscr}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\es}{\emptyset}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\d}{\delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\L}{\Lambda}&lt;br&gt;
\newcommand{\G}{\Gamma}&lt;br&gt;
\newcommand{\g}{\gamma}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\N}{\mb{N}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\H}{\mc{H}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\s}{\sigma}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[1]{_{\mid #1}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Dt}{{\Delta t}}&lt;br&gt;
\newcommand{\tr}{\rightarrowtail}&lt;br&gt;
\newcommand{\qed}{\ \ \blacksquare}&lt;br&gt;
\newcommand{\c}{\overline}&lt;br&gt;
\newcommand{\dg}{\dagger}&lt;br&gt;
\newcommand{\dd}{\mathrm{d}}&lt;br&gt;
\newcommand{\pd}{\partial}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;The physically realistic thing to do would be to make the piston an inertial body, meaning that it has its own momentum. If the particle is doing work on the piston by pushing it, then the piston must be climbing a potential gradient. Then, as an inertial body, the piston should fall back down the gradient when not being pushed.&lt;/p&gt;
&lt;p&gt;I also tried settling this matter by going to the source: &lt;a href=&#34;http://fab.cba.mit.edu/classes/863.18/notes/computation/Szilard-1929.pdf&#34;target=&#34;_blank&#34;&gt;Szilard&amp;rsquo;s original paper&lt;/a&gt;. Szilard specifies that the piston is forcibly moved by an operator. This can be modeled as a wall that moves in a predefined way, regardless of its interaction with the particle. That is certainly easier to model on a computer.&lt;/p&gt;
&lt;p&gt;Szilard specifies that the expansion is &lt;a href=&#34;https://en.wikipedia.org/wiki/Isothermal_process&#34;target=&#34;_blank&#34;&gt;isothermal&lt;/a&gt;, which means the particle regains lost KE (on average) by interacting with oscillating particles in the walls of the container. However, I am modeling the expansion as &lt;a href=&#34;https://en.wikipedia.org/wiki/Isentropic_process&#34;target=&#34;_blank&#34;&gt;isentropic&lt;/a&gt; to avoid the issue of environmental noise (see &lt;a href=&#34;https://danabo.github.io/blog/posts/why-doesnt-uncopying-defeat-the-2nd-law/#defining-environmental-noise&#34;&gt;Why Doesn&amp;#39;t Uncopying Defeat The 2nd Law#defining-environmental-noise&lt;/a&gt;). That means the particle does not exchange KE with the walls of the container, and so the particle loses net KE over time.&lt;/p&gt;
&lt;h1 id=&#34;inertial-piston-model&#34;&gt;Inertial Piston Model&lt;/h1&gt;
&lt;p&gt;Like last time I am modeling this in one spatial dimension. The piston and particle each have one position coordinate. The container has a length, with &amp;ldquo;caps&amp;rdquo; on each end.&lt;/p&gt;
&lt;p&gt;If the piston is pushing a mass $M$ up against gravity, then the potential field has a constant slope $g$. Then the motion of the piston is described by $M \ddot{x}=-g$, which gives us a parabola (think ball thrown in the air).&lt;/p&gt;
&lt;p&gt;The particle experiences no forces, except for elastic collisions with the walls of the container and the piston. We can use the &lt;a href=&#34;https://en.wikipedia.org/wiki/Elastic_collision#One-dimensional_Newtonian&#34;target=&#34;_blank&#34;&gt;1D elastic collision formula&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\pmatrix{u_f\\v_f}=\frac{1}{M+m}\pmatrix{M-m &amp;amp; 2m \\ 2M &amp;amp; m-M}\pmatrix{u_i\\v_i}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $M$ is the mass of the piston (i.e. the mass it is pushing), $m$ is the mass of the particle, $v_i,v_f$ are the initial and final velocities of the particle before and after the collision, and $u_i,u_f$ are the initial and final velocities of the piston before and after collision.&lt;/p&gt;
&lt;p&gt;When the particle collides with a fixed wall, its velocity sign changes, i.e. $v_f = -v_i$.&lt;/p&gt;
&lt;p&gt;To have the particle push the piston slowly over the course of many back-and-forth bounces, the piston&amp;rsquo;s mass should be greater than the particle&amp;rsquo;s, and the particle&amp;rsquo;s velocity should be greater than piston.&lt;/p&gt;
&lt;p&gt;For example, here is a simulation with the following settings&lt;br&gt;
piston: (mass) $M=1$ and (initial velocity) $u_0 = 0$&lt;br&gt;
particle: (mass) $m = 1/10$ and (initial velocity) $v_0=5$&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220215093814.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;Blue is the particle&amp;#39;s trajectory, and orange is the piston&amp;#39;s trajectory. The particle bounces off both the piston and the fixed wall at position -1. The behavior of the combined system is locally chaotic, and globally seems to oscillate.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;With a much lower particle mass and much higher initial particle velocity, we see less chaotic behavior and a more stable oscillation:&lt;br&gt;
piston: (mass) $M=1$ and (initial velocity) $u_0 = 0$&lt;br&gt;
particle: (mass) $m = 1/100$ and (initial velocity) $v_0=20$&lt;br&gt;


  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220215093846.png&#34; alt=&#34;&#34;&gt;
&lt;/p&gt;
&lt;p&gt;To avoid this sort of oscillation, I should have the piston mass decrease as it is pushed up, corresponding to &lt;a href=&#34;https://en.wikipedia.org/wiki/Isentropic_process&#34;target=&#34;_blank&#34;&gt;adiabatic (isentropic) expansion&lt;/a&gt;, where the entropy of the gas remains fixed as it expands. The gas does not absorb thermal energy from its container, and so it cools as it transfers KE to the piston. In order to maintain approximate equilibrium through out the change (making it a &lt;a href=&#34;https://en.wikipedia.org/wiki/Quasistatic_process&#34;target=&#34;_blank&#34;&gt;quasistatic process&lt;/a&gt;), the piston mass is slowly decreased so that the gas pressure and piston force opposing it always in balance.&lt;/p&gt;
&lt;p&gt;I tried running the same simulation where the piston mass is the following function of the container length: $M(L)=M_0\cdot\par{\frac{L_0}{L}}^\gamma$ where $\gamma=1$. I got this formula from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Isentropic_process#Table_of_isentropic_relations_for_an_ideal_gas&#34;target=&#34;_blank&#34;&gt;ideal gas isentropic relation&lt;/a&gt; between pressure and volume: $\frac{P_f}{P_i}=\par{\frac{V_i}{V_f}}^\gamma$. Pressure of a single particle applied to a point (end of the 1D container) is just its force, and the volume of the 1D container is its length. This resulted in very similar looking particle-piston trajectories as before, with oscillatory behavior. I suspect I would need to have the piston mass decrease as it is pushed up the potential slope, but not increase as it falls down the potential slope.&lt;/p&gt;
&lt;p&gt;At any rate, a quick workaround is to fix the piston in place once it reaches its maximally expanded position. Like this:&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220215103320.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
Like in &lt;a href=&#34;https://danabo.github.io/blog/posts/reversible-szilard-cycle-problem/#part-ii-information-is-never-lost&#34;&gt;Reversible Szilard Cycle Problem#part-ii-information-is-never-lost&lt;/a&gt;, I sampled a thousand initial particle states on each side of the container - left side as red and right side as blue.&lt;/p&gt;
&lt;p&gt;&lt;video controls autoplay loop src=&#34;../../szilard_inertial_piston.mp4&#34; caption=&#34;&#34; width=&#34;100%&#34;&gt;&lt;/video&gt;&lt;br&gt;
It seems that this too results in disjoint state regions, and so the which-side information is again preserved. What&amp;rsquo;s also apparent is that the state regions are shrinking. &lt;a href=&#34;https://en.wikipedia.org/wiki/Liouville%27s_theorem_%28Hamiltonian%29&#34;target=&#34;_blank&#34;&gt;Liouville&amp;rsquo;s theorem&lt;/a&gt; guarantees that state volume will be conserved in a closed system. However, here there is energy being lost to the piston. If we plotted the joint state space of the particle and piston we would see that the total state region does not shrink.&lt;/p&gt;
&lt;p&gt;Since the particle&amp;rsquo;s state region is shrinking, that implies there is state uncertainty being moved into the piston dimension. What does that imply about the reversibility of this process? A process is thermodynamically reversible if both the system undergoing the process and its environment can be reset to their joint initial state. If uncertainty is transferred from the particle to the piston (piston&amp;rsquo;s state region has increased in volume), is that reversible? Since all of the transferred uncertainty is accumulating in a single degree of freedom (the total energy absorbed from the particle), it should be possible in principle to transfer that uncertainty back to the particle. It is only when uncertainty becomes spread out among many degrees of freedom (like heat transfer from many particles to many particles) that this transfer becomes irreversible (why? - An exercise left to the reader).&lt;/p&gt;
&lt;h1 id=&#34;controlled-piston-model&#34;&gt;Controlled Piston Model&lt;/h1&gt;
&lt;h2 id=&#34;particles-colliding-with-moving-walls&#34;&gt;Particles colliding with moving walls&lt;/h2&gt;
&lt;p&gt;When you forcibly move a wall into particles, you transfer KE to them. This is why compressing a gas adds heat energy (average KE) to the gas.&lt;br&gt;
The time reversal of this process is forcibly expanding a gas by pulling the wall away from the particles. This must result in KE extraction from the particles.&lt;/p&gt;
&lt;p&gt;We see this bear out in the low-level Newtonian mechanics of collision with the formula $v_f = 2u-v_i$, where $v_i$ is the incoming (initial) velocity of the particle before wall collision, $v_f$ is the outgoing (final) velocity of the particle after wall collision, and $u$ is the fixed velocity of the wall.&lt;/p&gt;
&lt;p&gt;This formula can be derived from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Elastic_collision#One-dimensional_Newtonian&#34;target=&#34;_blank&#34;&gt;one-dimensional elastic collision formula&lt;/a&gt; (see &lt;a href=&#34;#inertial-piston-model&#34;&gt;#Inertial Piston Model&lt;/a&gt;) by taking the mass of the wall to infinity (&lt;a href=&#34;https://www.physicsforums.com/threads/elastic-collision-against-a-moving-wall.236652/#post-2347189&#34;target=&#34;_blank&#34;&gt;reference&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;Taking the limit as $m_u \to \infty$, we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\lim_{M\to\infty}\frac{1}{M+m}\pmatrix{M-m &amp;amp; 2m \\ 2M &amp;amp; m-M} = \pmatrix{1 &amp;amp; 0 \\ 2 &amp;amp; -1}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;giving us&lt;br&gt;
$$&lt;br&gt;
\pmatrix{u_f\\v_f}=\pmatrix{1 &amp;amp; 0 \\ 2 &amp;amp; -1}\pmatrix{u_i\\v_i} = \pmatrix{u_i\\2u_i-v_i}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $u=u_i=u_v$.&lt;/p&gt;
&lt;h2 id=&#34;simulation&#34;&gt;Simulation&lt;/h2&gt;
&lt;p&gt;In this simulation the piston has infinite mass and moves along a predefined path, representing an external operator controlling the movement of the piston. The particle collides elastically with the piston using the formula $v_f = 2u-v_i$, where $u$ is the velocity of the piston. If the piston is moving away from the particle (in the same direction as $v_i$), we see that $\abs{v_f}&amp;lt;\abs{v_i}$ and so the particle loses KE.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220217150254.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;An example particle trajectory (blue) with a piston (orange) moving along a predefined path. When the particle collides with the moving piston it loses KE.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Here I sample an ensemble of initial particles. The blue particles bounce off the blue piston and the red particles bounce off the red piston. Since the blue and red pistons follow the same path for all particles (of the same color), I can visualize the pistons superimposed on the ensemble. Since the piston&amp;rsquo;s predefined movement depends on which side (which color) the particle is on, this controll &amp;ldquo;program&amp;rdquo; requires the which-side bit stored in memory.&lt;br&gt;
&lt;video controls autoplay loop src=&#34;../../szilard_piston_fixed_movement.mp4&#34; caption=&#34;&#34; width=&#34;100%&#34;&gt;&lt;/video&gt;&lt;br&gt;
Clearly the state regions overlap over time, and so the which-side information is no longer present in the particle system at the end of the piston expansion.&lt;/p&gt;
&lt;p&gt;Question: Why do some interaction models preserve which-side information, while other interaction models do not?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Why Doesn&#39;t Uncopying Defeat The 2nd Law?</title>
      <link>https://danabo.github.io/blog/posts/why-doesnt-uncopying-defeat-the-2nd-law/</link>
      <pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/why-doesnt-uncopying-defeat-the-2nd-law/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;https://danabo.github.io/blog/posts/reversible-szilard-cycle-problem/&#34;&gt;Reversible Szilard Cycle Problem&lt;/a&gt; I pondered whether uncopying a bit of information at the end of the Szilard cycle makes the full cycle reversible, apparently getting around the 2nd law. This &amp;ldquo;loophole&amp;rdquo; is more much pervasive to thermodynamics than the Szilard engine. I will go through its generalization in &lt;a href=&#34;#maxwell%27s-superdemon&#34;&gt;#Maxwell&amp;rsquo;s Superdemon&lt;/a&gt;. I assume the 2nd law holds, so in &lt;a href=&#34;#slaying-the-superdemon&#34;&gt;#Slaying The Superdemon&lt;/a&gt; I consider some possible reasons why this loophole doesn&amp;rsquo;t work.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\ms}{\mathscr}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\es}{\emptyset}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\d}{\delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\L}{\Lambda}&lt;br&gt;
\newcommand{\G}{\Gamma}&lt;br&gt;
\newcommand{\g}{\gamma}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\N}{\mb{N}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\H}{\mc{H}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\s}{\sigma}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[1]{_{\mid #1}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Dt}{{\Delta t}}&lt;br&gt;
\newcommand{\tr}{\rightarrowtail}&lt;br&gt;
\newcommand{\qed}{\ \ \blacksquare}&lt;br&gt;
\newcommand{\c}{\overline}&lt;br&gt;
\newcommand{\dg}{\dagger}&lt;br&gt;
\newcommand{\dd}{\mathrm{d}}&lt;br&gt;
\newcommand{\pd}{\partial}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Note: I will use the term &amp;ldquo;system&amp;rdquo; to refer to a state space, and &amp;ldquo;process&amp;rdquo; to refer to a particular time-evolution (i.e. propagator) that state undergoes. In other words, a system undergoes a process.&lt;/p&gt;
&lt;h1 id=&#34;maxwells-superdemon&#34;&gt;Maxwell&amp;rsquo;s Superdemon&lt;/h1&gt;
&lt;h2 id=&#34;the-reversibility-game&#34;&gt;The Reversibility Game&lt;/h2&gt;
&lt;p&gt;We can treat the general reversibility question in thermodynamics as a game. Player 1 provides a process to be reversed, and the goal for player 2 is to reverse the process back to its initial state without any net change to the environment. Player 2 is allowed to interact with and modify the system in question in any way they wish. Though this seems like it gives player 2 too much power (making this a rather easy game), player 2&amp;rsquo;s task should be impossible for a certain class of processes by the 2nd law of thermodynamics.&lt;/p&gt;
&lt;p&gt;To analyze this game formally, we need to make the game and its rules well defined. Though we can use classical mechanics to describe processes to be reversed, the question remains: what kinds of actions can player 2 take on any given process represented in classical mechanics?&lt;/p&gt;
&lt;p&gt;An answer I&amp;rsquo;ve been toying with is motivated by the idea that interactions between any two systems are ultimately mediated by force fields (e.g. gravity and the EM field). So classical mechanics already comes packaged with a general purpose interaction formalism: the potential field.&lt;/p&gt;
&lt;p&gt;If we wanted to keep the space of possible player 2 actions as broad as possible, we could specify that player 2 can arbitrarily manipulate a (time-dependent) external potential field that the process exists on top of (one which the components of the system interact with). &amp;ldquo;Time-dependent&amp;rdquo; means the state of the potential field may be a function of some absolute time (player 2 decides how it changes and when). &amp;ldquo;External&amp;rdquo; means it is not considered part of the system in question, but is generated by an external source. In this external potential field, player 2 can manifest walls and potential slopes that push/pull parts of the system around. By looking at the total change in the system&amp;rsquo;s energy, we can infer how much energy player 2 had to have spent to get there.&lt;/p&gt;
&lt;p&gt;The full action space of player 2 is then the choice of any potential field that is a function of time (may change over time any way player 2 wishes) overlaid on top of the system. This &amp;ldquo;interaction via potential field&amp;rdquo; framework allows for a very general class of interventions on physical systems, though it may be too general. As we shall see, some field manipulations player 2 can make may not be realistically achievable. However, I would not expect the validity of the 2nd law to hinge on the mere intractability of engineering what is needed to instantiate some potential field. Instead I would expect there to be some fundamental reason the specific fields needed to violate the 2nd law in some instance of this game are impossible to realize.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll make heavy use of external potential fields that contain &amp;ldquo;walls&amp;rdquo;, which are steep potential hills. So when I talk about a gas in a box, the gas particles make up the system and the walls of the box make up the environment of the gas. Those walls are potential hills in the external potential field. Player 2 is allowed to manipulate that external potential anyway they please, e.g. by modifying, adding and removing walls, among other manipulations.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/gas_container_potential.jpg&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;Steep potential hills make up the walls of the box holding a gas.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/potential_wall.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;An idealized wall is an infinitely steep and infinitely high potential hill (depicted on the right). This can be constructed by taking the limit of a finite hill (left) as its height goes to infinity and its width goes to zero.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;measurement&#34;&gt;Measurement&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;ve specified how player 2 can affect the target system in this game, but we also need to specify how player 2 can be effected by the system.&lt;/p&gt;
&lt;p&gt;Player 2 acts like the environment of the system by manipulating the external potential field the system lies over. But the system may also produce its own potential field(s) which affect the environment. In this way the system may leak information about its state into the environment (any environment state whose trajectory depends in part on the system&amp;rsquo;s state will gain information about the system).&lt;/p&gt;
&lt;p&gt;Below I will consider cases when player 2 does not have complete information about the system or the environment. In those situations, player 2 is allowed to perform measurements on the system to gain information. A measurement apparatus is a system within the environment whose state evolution depends on the system&amp;rsquo;s state evolution.&lt;/p&gt;
&lt;p&gt;Using the data (un)copying process from &lt;a href=&#34;https://danabo.github.io/blog/posts/reversible-szilard-cycle-problem/#uncopying&#34;&gt;Reversible Szilard Cycle Problem#uncopying&lt;/a&gt; as an intuition pump, we can suppose that the target system&amp;rsquo;s state determines some potential field which the measurement apparatus sits upon. As the system&amp;rsquo;s state changes over time, that potential field changes over time, which may guide the measurement apparatus&amp;rsquo;s state.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/potential_field_measurement.jpg&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;The measurement apparatus state has a degree of freedom $x$, which is guided by the potential. The potential is produced by the system being measured (the target system). Whether $x$ is guided into the left or right potential well depends on how the potential changes over time, which is determined by how the state of the target system  changes over time.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In this way, any potential fields the target system emits can be used to perform measurements on the target system, which amounts to correlating environment state with the state of the target system.&lt;/p&gt;
&lt;h2 id=&#34;example-free-expansion&#34;&gt;Example: Free Expansion&lt;/h2&gt;
&lt;p&gt;A canonical example of an irreversible process is the free expansion of a gas, a.k.a. &lt;a href=&#34;https://en.wikipedia.org/wiki/Joule_expansion&#34;target=&#34;_blank&#34;&gt;Joule expansion&lt;/a&gt;. This is where a gas is allowed to expand into a larger region of space unimpeded. The gas does no work in the process (e.g. does not push a piston), and so its thermodynamic potential to do work is lost.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220217152946.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;\&amp;#34;A free expansion of a gas can be achieved by moving the piston out faster than the fastest molecules in the gas.\&amp;#34; Source: [Wikipedia](https://upload.wikimedia.org/wikipedia/commons/5/5e/Before_during_after_sudden_expansion.jpg).&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;A summary of the free expansion process:&lt;br&gt;
(a) There is a gas in a box at equilibrium.&lt;br&gt;
(b) The box is made rapidly larger so that the gas expands into the resulting vacuum (e.g. by removing a barrier to a larger container, or by moving a piston).&lt;br&gt;
(c) The gas returns to equilibrium in the larger container.&lt;/p&gt;
&lt;p&gt;We can represent the state of an N-particle gas with the vectors $\vec{x},\vec{v}$ of the combined positions and velocities of the particles respectively (in one, two or three spatial dimensions). The process (how this state changes over time) is fully determined by a Lagrangian (or Hamiltonian), which describe the total energy of the system (kinetic and potential). Specifically, the Lagrangian/Hamiltonian is the difference/sum of the total kinetic energy $V(\vec{x},\vec{v})$ and total potential energy $U(\vec{x},\vec{v})$ of the system, as functions of its state. There may also be an external potential term $U_\text{ext}$ which is a function of the system state and some environment state. The external potential defines the interaction between the system and the environment (e.g. collisions with container walls). Player 2 interacts with the system by modifying $U_\text{ext}$ over time.&lt;/p&gt;
&lt;p&gt;From the given Lagrangian/Hamiltonian, we can derive the &lt;em&gt;propagator&lt;/em&gt;, $\t_\Dt$, for the time interval $\Dt$. This $\t_\Dt$ is a function that propagates state through time, i.e. $\vec{x}_{t+\Dt},\vec{v}_{t+\Dt}=\t_\Dt(\vec{x}_t,\vec{v}_t)$ where $\vec{x}_t,\vec{v}_t$ is the state of the gas at time $t$, and $\vec{x}_{t+\Dt},\vec{v}_{t+\Dt}$ is the state of the gas at time $t+\Dt$. This relationship holds for all $t\in\R$ and for all $\Dt\in\R$ (including negative intervals).&lt;/p&gt;
&lt;p&gt;Note that I assume the system and its environment are time-independent, meaning that $V$, $U$ and $U_\text{ext}$ are not functions of some absolute time variable $t$. That makes the Lagrangian/Hamiltonian time-independent, and thus the propagator time-independent (it only depends on state and time interval). However, player 2 may modify $U_\text{ext}$ to be time-dependent, which results in a time-dependent propagator, i.e. $\t_\Dt$ becomes a function of the state at time $t=0$ only.&lt;/p&gt;
&lt;p&gt;If the gas starts at state $\vec{x}_0,\vec{v}_0$ at time $t=0$, then the entire trajectory of the gas through time is given by $\t_t(\vec{x}_0,\vec{v}_0)$ for all $t \in\R$.&lt;/p&gt;
&lt;p&gt;Suppose player 1 provides a freely expanding gas as the process that player 2 is tasked with reversing. Specifically, the gas starts in state $\vec{x}_0,\vec{v}_0$, occupying the small container. By time $T$, the gas occupies the large container represented by the state $\vec{x}_T,\vec{v}_T=\t_T(\vec{x}_0,\vec{v}_0)$. How does player 2 intervene on this gas starting at state $\vec{x}_T,\vec{v}_T$ to return it to state $\vec{x}_0,\vec{v}_0$ at some later time?&lt;/p&gt;
&lt;p&gt;Physics obeys time-reversal symmetry, meaning that time-inverted trajectories are physically valid. That is to say, the system traveling in reverse (but forward in time) along its historical trajectory is a valid process for it to undergo. We need only negate the velocities at some moment in time to put the system on its time-reversed trajectory. To be specific, if player 2 could somehow make it so that $\vec{v}_{T+\e}=-\vec{v}_{T}$ and $\vec{x}_{T+\e}=\vec{x}_T$ for some time-interval $\e&amp;gt;0$, then $\vec{x}_{T+\e+t},\vec{v}_{T+\e+t}=\vec{x}_{T-t},\vec{v}_{T-t}$ for all $t\geq0$. That means $\vec{x}_{2T+\e},\vec{v}_{2T+\e}=\vec{x}_{0},\vec{v}_{0}$ at which point the system is returned to its initial state.&lt;/p&gt;
&lt;p&gt;Player 2 can achieve this with micro-walls, i.e. very small, localized walls in the potential field. As I mentioned, a wall is essentially a very steep (or infinitely steep) hill in the external potential field. Walls deflect particles (are repulsive). A micro-wall takes up very little space.&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/microwall.jpg&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;A micro-wall is a spatially small (localized) wall in the potential field.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Assuming player 2 can create and remove these micro-walls for free (when there is no active collision between them and the particles), then player 2 can manifest these micro-walls just during the time interval from $T$ to $T+\e$. If a micro-wall is placed in front of every particle in just the right orientation, then each particle will be deflected in the opposite direction, i.e. its velocity will be negated.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../gas_reversal_1.jpg&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../gas_reversal_1.jpg&#34; 
         alt=&#34;State of the gas at time $T$. Blue lines are walls (steep thin hills) in the external potential. Orange lines are velocity vectors of the particles.&#34; width=&#34;308&#34;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;span class=&#34;caption&#34;&gt;
            &lt;p&gt;State of the gas at time $T$. Blue lines are walls (steep thin hills) in the external potential. Orange lines are velocity vectors of the particles.&lt;/p&gt;
        &lt;/span&gt;
&lt;/span&gt; &lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../gas_reversal_2.jpg&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../gas_reversal_2.jpg&#34; 
         alt=&#34;Microwalls placed between time $T$ and $T&amp;#43;\e$. Gas particles are about to collide with their respective microwalls.&#34; width=&#34;300&#34;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;span class=&#34;caption&#34;&gt;
            &lt;p&gt;Microwalls placed between time $T$ and $T+\e$. Gas particles are about to collide with their respective microwalls.&lt;/p&gt;
        &lt;/span&gt;
&lt;/span&gt; &lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../gas_reversal_3.jpg&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../gas_reversal_3.jpg&#34; 
         alt=&#34;State of the gas at time $T&amp;#43;\e$. Microwalls are removed.&#34; width=&#34;310&#34;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;span class=&#34;caption&#34;&gt;
            &lt;p&gt;State of the gas at time $T+\e$. Microwalls are removed.&lt;/p&gt;
        &lt;/span&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since the microwalls are present between the absolute times $T$ and $T+\e$, the external potential $U_\text{ext}$ becomes time-dependent.&lt;/p&gt;
&lt;p&gt;Note that I assume that manipulations of the potential field which do not lift or lower matter, or change the gradient (slope) of the field under matter (changing the force felt by the matter, and thus changing the system&amp;rsquo;s total energy), cost no energy to perform (this is an idealization). So the manifestation and dissolution of walls and other shapes in the potential landscape can be done for free so long as there is not matter directly on top of these shapes as they are modified.&lt;/p&gt;
&lt;h2 id=&#34;the-role-of-uncertainty&#34;&gt;The Role of Uncertainty&lt;/h2&gt;
&lt;p&gt;The above example demonstrates that player 2 can reverse an isolated process given perfect knowledge of its state. Let&amp;rsquo;s see what happens if player 2 lacks state information.&lt;/p&gt;
&lt;p&gt;Suppose that player 2 does not know the initial state of the gas, but only that the gas starts off inside the smaller container (and maybe that its at equilibrium at a certain temperature). Player 2 will have to look at the state of the gas (perform a measurement) at time $T$ in order to pull the same trick as before. But like with the Szilard engine, whether player 2 can do this reversal for free hinges on whether the gas measurement can be reset for free (remember that reversal requires the environment, i.e. physical memory, to be reset as well).&lt;/p&gt;
&lt;p&gt;Note that player 2&amp;rsquo;s state uncertainty is propagated down to any device player 2 employs. For example, if player 2 builds a device that creates the micro-walls needed in the external potential to reverse the gas, how does this device know the correct placement and orientation of the micro-walls? No matter what, the way in which the external potential changes over time needs to be a function of the state of the gas, i.e. is conditional on the gas. For the external potential to be conditioned on the state of the system, some environment state needs to become correlated with the state of the system in the way described earlier: &lt;a href=&#34;#measurement&#34;&gt;#Measurement&lt;/a&gt;. This is how the intervention on the system needed to reverse it depends, fundamentally at a physical level, on information about the system&amp;rsquo;s state.&lt;/p&gt;
&lt;p&gt;Since the gas evolved deterministically according to the propagator $\t_\Dt$ (for every $\Dt\in\R$), its state information (positions and velocities of the particles) is preserved through time. Suppose the state of the gas can be recorded with a special camera (an infinite resolution camera). One photo captures the positions of all the particles, and two rapidly sequential photos to capture their velocities. As discussed, player 2 can use this information to reverse the free expansion of the gas.&lt;/p&gt;
&lt;p&gt;But player 2 might be able to do more than that. Suppose player 2 takes two rapidly sequential photos at time $T$, and stores these photos in some physical medium. Since player 2 knows the dynamics of the system (i.e. knows $\t_\Dt$), then in principle player 2 can predict what the photos taken at time $T+\e$ would look like. We might suppose player 2 can even apply $\t_{\e}$ to the photos, replacing them in memory with the output of $\t_{\e}$. This should be in principle a reversible process since $\t_{\e}$ is a bijection (no information is lost by applying this function). If we suppose that the process of taking these photos is reversible and costs no energy (like the copy process from the Szilard engine discussion), then player 2 can apply the reverse of the camera process, i.e. the &amp;ldquo;uncamera&amp;rdquo; process, to the time $T+\e$ photos in memory at time $T+\e$, which would reset the state of the photo storage to its default state at no energy cost. Player 2 is performing an uncopy.&lt;/p&gt;
&lt;h2 id=&#34;the-general-uncopy-loophole&#34;&gt;The General Uncopy Loophole&lt;/h2&gt;
&lt;p&gt;Classical mechanics allows us to consider an arbitrary system described with &lt;a href=&#34;https://en.wikipedia.org/wiki/Generalized_coordinates&#34;target=&#34;_blank&#34;&gt;generalized coordinates&lt;/a&gt;, $\vec{q}$ and $\dot{\vec{q}}$, a vector of parameters and their time-derivatives, which fully specifies the state of the system. These parameters can be positions in some reference frame, but can represent other degrees of freedom such as rotations or distances between parts within the system. As before, a Lagrangian (or Hamiltonian) is provided that fully determines the trajectory the system takes through time given any initial state.&lt;/p&gt;
&lt;p&gt;Let $\t_\Dt$ be the propagator induced by the given Lagrangian/Hamiltonian and let $\vec{q}_t,\dot{\vec{q}}_t = \t_t(\vec{q}_0,\dot{\vec{q}}_0)$ for some initial state $\vec{q}_0,\dot{\vec{q}}_0$.  Assuming player 2&amp;rsquo;s potential field interacts with every degree of freedom in $\vec{q}$, then player 2 can construct generalized micro-walls in the potential field that has the effect of negating all of the velocity coordinates so that $\dot{\vec{q}}_{T+\e}=\dot{\vec{q}}_T$ for some time $T$. Then the system will proceed to run in reverse until it returns to its initial state $\t_t(\vec{q}_0,\dot{\vec{q}}_0)$.&lt;/p&gt;
&lt;p&gt;For a system with initial state unknown to player 2, this is the general reversal procedure:&lt;/p&gt;
&lt;p&gt;(a) The system progresses from time 0 to time $T$ (player 2 does not yet intervene).&lt;/p&gt;
&lt;p&gt;(b) At time $T$, player 2 takes two &amp;ldquo;pictures&amp;rdquo; of the states $\vec{q}_T$ and $\vec{q}_{T+\d}$ (for very small $\d&amp;gt;0$) in quick succession. These state pictures are saved to physical memory (initial in a known default state).&lt;/p&gt;
&lt;p&gt;(c) Player 2 transforms its saved pictures by applying $\t_\e$ (using their own computational or simulation apparatus), resulting in pictures of the states $\vec{q}_{T+\e}$ and $\vec{q}_{T+\e+\d}$ in memory, all done in the time span between $T$ and $T+\e$.&lt;/p&gt;
&lt;p&gt;(d) Player 2 performs the reverse of the camera process which takes the state $\vec{q}_{T+\e}$ of the gas and its duplicated representation in memory and results in the memory being returned to its default state. Same is done for the second picture of $\vec{q}_{T+\e+\d}$ a moment later.&lt;/p&gt;
&lt;p&gt;(e) Player 2 waits another time interval of $T$ for the system to return to its initial state.&lt;/p&gt;
&lt;p&gt;Call this procedure the &lt;em&gt;uncopy loophole&lt;/em&gt;. A loophole in physics is a potential way around some proposed &lt;a href=&#34;https://en.wikipedia.org/wiki/No-go_theorem&#34;target=&#34;_blank&#34;&gt;no-go theorem&lt;/a&gt; (a theorem that says you can&amp;rsquo;t do something). A famous example are the &lt;a href=&#34;https://en.wikipedia.org/wiki/Loopholes_in_Bell_tests&#34;target=&#34;_blank&#34;&gt;loopholes in Bell&amp;rsquo;s theorem&lt;/a&gt;. All these loopholes (except &lt;a href=&#34;https://en.wikipedia.org/wiki/Loopholes_in_Bell_tests#Superdeterminism_loopholehttps://en.wikipedia.org/wiki/Loopholes_in_Bell_tests#Superdeterminism_loophole&#34;target=&#34;_blank&#34;&gt;superdeterminism&lt;/a&gt;) have been &lt;em&gt;closed&lt;/em&gt;, meaning its been shown that these tricks don&amp;rsquo;t invalidate Bell&amp;rsquo;s theorem (in this case experimentally, but theoretical proof could also be sufficient).&lt;/p&gt;
&lt;p&gt;Some other entropy increasing processes which could be reversed in this way (if the loophole can&amp;rsquo;t be closed) include the &lt;a href=&#34;https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Supplemental_Modules_%28Physical_and_Theoretical_Chemistry%29/Thermodynamics/Ideal_Systems/Thermodynamics_of_Mixing&#34;target=&#34;_blank&#34;&gt;mixing of two kinds of gases&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Thermal_equilibrium&#34;target=&#34;_blank&#34;&gt;heat diffusion&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;superdemons&#34;&gt;Superdemons&lt;/h3&gt;
&lt;p&gt;What I&amp;rsquo;ve constructed is a much more beefed up version of &lt;a href=&#34;https://en.wikipedia.org/wiki/Maxwell%27s_demon&#34;target=&#34;_blank&#34;&gt;Maxwell&amp;rsquo;s demon&lt;/a&gt;. While pondering the recently formulated laws of thermodynamics, Maxwell (of &lt;a href=&#34;https://en.wikipedia.org/wiki/Maxwell%27s_equations&#34;target=&#34;_blank&#34;&gt;Maxwell&amp;rsquo;s equations&lt;/a&gt; fame) conceived of a thought experiment where a tiny &amp;ldquo;demon&amp;rdquo; selectively allows particles through a partition in a box containing a gas - specifically allowing high velocity particles through and blocking low velocity particles from passing through. As time passes, one side will be increasingly hotter than the other side. If the demon can carry out this discrimination without energy cost (or low energy cost), then the diffusion of heat between two gasses (one initially hot and one initially cold) can be reversed without energy cost, seemingly violating the 2nd law.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220216190805.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;\&amp;#34;Schematic figure of Maxwell&amp;#39;s demon thought experiment\&amp;#34;. Source: [Wikipedia](https://en.wikipedia.org/wiki/Maxwell%27s_demon#/media/File:Maxwell&amp;#39;s_demon.svg)&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;I want a term for a very powerful player 2 that can perform any of the potential field manipulations allowed for by the game specified above, such as micro-walls (for negating velocity). Let&amp;rsquo;s call this a &lt;em&gt;superdemon&lt;/em&gt;. Think of a superdemon as a maximally adversarial Maxwellian demon which, welding an arbitrarily manipulable potential field, will pull any trick it can to reverse any process you give it without energy cost to itself.&lt;/p&gt;
&lt;h1 id=&#34;slaying-the-superdemon&#34;&gt;Slaying The Superdemon&lt;/h1&gt;
&lt;p&gt;How can the uncopy loophole be closed? What prevents it from being carried out in practice?&lt;/p&gt;
&lt;p&gt;One possible reason is that copy and uncopy are processes that take time. For chaotic and fast moving systems like gasses, the target data to be copied/uncopied is nonstationary, and changing quickly at that. On the other hand, is this even a problem in practice? There are experimental &lt;a href=&#34;https://en.wikipedia.org/wiki/Femto-photography&#34;target=&#34;_blank&#34;&gt;femtosecond cameras&lt;/a&gt; that capture images within the span of one ten-trillionths of a second ($10^{-13}$ s). Presumably that is fast enough to accurately capture the state of a room temperature gas (including velocities).&lt;/p&gt;
&lt;h2 id=&#34;copying-takes-time&#34;&gt;Copying Takes Time&lt;/h2&gt;
&lt;p&gt;In theory, the time duration of the copy and uncopy processes can be made as short as desired. The question remains - however brief the process is, because the state being copied is changing quickly, can the copy process have infinite fidelity (copy at infinite resolution)? I am not currently sure what the answer is, assuming there is no environmental noise.&lt;/p&gt;
&lt;p&gt;The processes thermodynamics is concerned about, where the question of irreversibility comes up, are likely all chaotic. For a gas, even slight changes to their state at time $t$ will result in a very large change in future states over long time spans. Then it also is the case that the smallest of errors in the reversal of a gas&amp;rsquo;s trajectory would result in the gas&amp;rsquo;s state not being reversed. That is to say, if the micro-walls created by a superdemon are even slightly off in their position and orientation, so that the velocity vectors are not perfectly negated, then the gas will not return to its initial state. That means a superdemon with finite copy and uncopy precision will likely not be able to reverse the free expansion of a gas (or the mixing of two gasses, or the diffusion of heat), because so many particle collisions have to happen exactly right for all the particles in the gas to return to their smaller container. (or for two gasses to be become unmixed, etc.)&lt;/p&gt;
&lt;p&gt;This brings me to the more pervading reason the uncopy loophole won&amp;rsquo;t work: environmental noise.&lt;/p&gt;
&lt;h2 id=&#34;environment-noise&#34;&gt;Environment noise&lt;/h2&gt;
&lt;p&gt;Environmental noise makes carrying out the uncopy loophole intractable. Why?&lt;/p&gt;
&lt;p&gt;A more realistic model of a gas includes the interaction between the gas particles and the particles of its container. This interaction makes the future states of the gas dependent, in part, on the state of those container particles, i.e. environment state. For a superdemon to reverse the trajectory of a gas, it would need to also reverse the trajectories of all the particles in its container as well. Now we&amp;rsquo;ve expanded the scope of what needs to be reversed to include the immediate environment the system interacts with. But that immediate environment also interacts with things beyond it. In practice no system is perfectly isolated. There is endless chain of systems interacting with systems so that one can never take into account enough state to perfectly reverse a gas (or any other chaotic system).&lt;/p&gt;
&lt;p&gt;Supposing the superdemon has perfect information about the state of the entire universe, but cannot alter the trajectory of the environment outside the system, can the superdemon reverse a chaotic system like a gas? Maybe it is possible to determine an intricate sequence of interventions on the system that guide it back to its reversed state given the forward-trajectory of the environment on which it depends.&lt;/p&gt;
&lt;p&gt;Now consider what happens when the superdemon does not know the state of the entire universe. The superdemon either has to measure that unknown state (by interacting), which consumes physical memory storage, or has to perform an intervention on the system that does not depend on that unknown state.&lt;/p&gt;
&lt;p&gt;If we limit the power of the superdemon to potential field manipulations that are finite (either finite in energy changes or finite in the spatial region of the change), then the superdemon cannot use the uncopy trick to reset its physical memory. That physical memory is itself interacting with more of the environment with unknown state, and the superdemon would need to take that unknown state into account to uncopy the memory, and we have an infinite regress.&lt;/p&gt;
&lt;h3 id=&#34;defining-environmental-noise&#34;&gt;Defining Environmental Noise&lt;/h3&gt;
&lt;p&gt;I define environment noise as environmental uncertainty - i.e. environment state that is unknown (i.e. unknown to player 2) - represented as a state region (the set of possible states it could take on).&lt;/p&gt;
&lt;p&gt;If the system in question starts off in a known state, as it interacts with the part of the environment which is uncertain, the system&amp;rsquo;s state will also become uncertain over time. One could think of the system&amp;rsquo;s time-evolution as being nondeterministic, in the sense that the system&amp;rsquo;s future state is a function of both the system&amp;rsquo;s current state and environmental state which is literally not determined in the model (it takes on a set of possibilities).&lt;/p&gt;
&lt;p&gt;Some example forms that environmental noise takes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thermal motion of wall particles.&lt;/li&gt;
&lt;li&gt;Irregular shape of containing walls.&lt;/li&gt;
&lt;li&gt;Measurement error (includes time uncertainty).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;thermal-noise&#34;&gt;Thermal Noise&lt;/h3&gt;
&lt;p&gt;We could model the thermal activity of a container in the following way:&lt;br&gt;
Instead of fixed walls, we divide the container walls up into small slices. Each slice is given mass and placed on the end of a spring. A collision between this &amp;ldquo;springed wall-slice&amp;rdquo; slice and a particle disturbs the spring and the springed wall-slice will oscillate. To model the wall having thermal noise, initialize the springed wall-slices with some KE. The average KE across all the slices is the temperature of the wall.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/wall_springs.jpg&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
We can model thermal diffusion in the wall by connecting the wall-slices to their neighbors with springs as well. To simulate the container being connected to an infinite heat reservoir, we could suppose the springed wall-slices are themselves connected by springs to more masses on springs, going on forever. (or just a very large but finite number of masses on springs). Alternatively we could have &amp;ldquo;injection sites&amp;rdquo; in the wall slices where we add or subtract KE as a function of the average KE across all the slices.&lt;/p&gt;
&lt;p&gt;When gas particles collide with the springed wall-slices, they exchange KE depending on their respective velocities. The the return velocity of the particle after the collision depends on the incoming velocity of the wall-slice - something that is unknown to us. This is how the gas&amp;rsquo;s trajectory becomes more uncertain due to this thermal noise as time progresses.&lt;/p&gt;
&lt;h3 id=&#34;wall-irregularity&#34;&gt;Wall Irregularity&lt;/h3&gt;
&lt;p&gt;Shape uncertainty has a similar effect as thermal uncertainty. I want to note the difference between an irregular wall shape and an unknown wall shape.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/irregular_walls.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;Set of irregularly shaped walls.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In principle if we knew the exact shape of the container of a gas, no matter how irregular, we could model the time-evolution of the gas (also in known state) deterministically. Then if the gas undergoes free expansion, a superdemon can reverse that process as described above.&lt;/p&gt;
&lt;p&gt;However, if we model the wall as a set of possible walls (each with some irregularity in shape), then the trajectory of the gas is non-deterministic (literally, depends partly on non-determined state), since it depends on the unknown orientation of the local region of the wall at collisions.&lt;/p&gt;
&lt;p&gt;This is an example of Bayesian uncertainty, where what we are uncertain about is not changing, but fixed for all time - i.e. we are not sampling a different wall on each interaction. This gives us the ability to, in principle, gain information, i.e. narrow down possibilities via observation, direct or indirect, about which wall is the case.&lt;/p&gt;
&lt;h3 id=&#34;measurement-error&#34;&gt;Measurement Error&lt;/h3&gt;
&lt;p&gt;Finally the nail in the coffin for the uncopy loophole: measurement error is inevitable and results in effectively finite measurement precision.&lt;/p&gt;
&lt;p&gt;Measurement error is another form of environmental noise - specifically due to our uncertainty about the state of the measurement apparatus (or the state of physical memory).&lt;/p&gt;
&lt;p&gt;Returning to the model of generalized measurement, the physical memory itself would realistically have thermal noise or other state uncertainty. If we are storing analog data like the image taken by a camera, the thermal noise in the storage medium creates a precision limit.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Is The Szilard Cycle Reversible?</title>
      <link>https://danabo.github.io/blog/posts/reversible-szilard-cycle-problem/</link>
      <pubDate>Wed, 09 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/reversible-szilard-cycle-problem/</guid>
      <description>&lt;p&gt;This is a long-winded attempt at formulating a question about thermodynamics. I will first give a high level &lt;a href=&#34;#overview&#34;&gt;#Overview&lt;/a&gt; of what this post is about, and then go through the technical details in the subsequent sections. Feel free to otherwise skip directly to &lt;a href=&#34;#part-i-uncopying&#34;&gt;#Part I Uncopying&lt;/a&gt; if you&amp;rsquo;d rather jump right in. The question is stated at the bottom: &lt;a href=&#34;#question&#34;&gt;#Question&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
$$&lt;/p&gt;
&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Landauer%27s_principle&#34;target=&#34;_blank&#34;&gt;Landauer&amp;rsquo;s principle&lt;/a&gt; is the conjecture that erasing physically stored data costs a minimum amount of energy, proportional to the number of bits being erased. &lt;em&gt;Erasure&lt;/em&gt; here means subjecting the data storage medium (a physical system) to some process that maps all of its possible memory states to one single known state. For example, an array of computer bits might be mapped to the &amp;ldquo;all zero&amp;rdquo; state, 0000000&amp;hellip; This process is performing a many-to-one mapping, i.e. many different physical states of the data storage medium have trajectories under this process that result in the same end state.&lt;/p&gt;
&lt;p&gt;The known laws of physics obey time-symmetry, meaning that trajectories starting in different states don&amp;rsquo;t collide, i.e. given any current state, you can in principle determine what states the system occupied on any past or future time - at least given complete state information. To have a many-to-one process, the &amp;ldquo;which state&amp;rdquo; information being lost must actually have been moved somewhere else. In practice, when computer memory is reset, the information it had stored is dispersed into the environment. Landauer&amp;rsquo;s principle states that this dispersion necessarily accompanies a minimum amount of energy dispersion, which is the energy required to reset the bits. This dispersion is practically irreversible.&lt;/p&gt;
&lt;p&gt;In general, thermodynamically irreversable processes, i.e. entropy increasing processes, have this same sort of many-to-one mapping that results in information loss (which is really information leakage).&lt;/p&gt;
&lt;p&gt;This made me wonder whether it is possible to erase redundantly stored data without a thermodynamic cost. C. H. Bennett in his article, &lt;a href=&#34;https://link.springer.com/article/10.1007/BF02084158&#34;target=&#34;_blank&#34;&gt;&lt;em&gt;The thermodynamics of computation - a review&lt;/em&gt;&lt;/a&gt; (&lt;a href=&#34;https://www.cc.gatech.edu/computing/nano/documents/Bennett%20-%20The%20Thermodynamics%20Of%20Computation.pdf&#34;target=&#34;_blank&#34;&gt;alt link&lt;/a&gt;), discusses situations when data redundancy can and cannot be reduced &amp;ldquo;for free&amp;rdquo;, as in, without an energy cost. He uses a toy system, called the &lt;a href=&#34;https://en.wikipedia.org/wiki/Entropy_in_thermodynamics_and_information_theory#Szilard%27s_engine&#34;target=&#34;_blank&#34;&gt;Szilard engine&lt;/a&gt;, to construct an example where memory can be erased for free (no energy cost in the ideal limit). The Szilard engine runs repetitive cycles, just as the Carnot engine (a canonical thermodynamics example) runs repetitions of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Carnot_cycle&#34;target=&#34;_blank&#34;&gt;Carnot cycle&lt;/a&gt;. So from here on I&amp;rsquo;ll refer to the Szilard cycle as the process being carried out in the Szilard engine.&lt;/p&gt;
&lt;p&gt;The Szilard cycle extracts heat from a one-particle gas to do work on a piston. To do this, a bit of physical memory is used to store the outcome of a measurement. This thought experiment is useful for drilling down into some of the connections between thermodynamics reversibility and information.&lt;/p&gt;
&lt;p&gt;In his article, Bennett shows that the process which performs the measurement and stores the outcome in a physical bit is, on its own, reversible. If that process is a copy operation, then its reverse is an &lt;em&gt;uncopy&lt;/em&gt; operation, which puts the bit back in its known default state without energy cost (in the ideal setting). However, we cannot extract work from the one-particle gas if we uncopy the bit. The end of a full Szilard cycle results in the physical bit being cleared in the thermodynamically wasteful way that costs energy (at least as much energy as was extracted from the gas). Thus, we cannot extract free work from this gas, and the 2nd law of thermodynamics holds. It is only the memory erasing step which is irreversible (different from uncopying which is reversible).&lt;/p&gt;
&lt;p&gt;However, I don&amp;rsquo;t see why the last step of the Szilard cycle cannot perform a different sort of uncopy process - one that is different from the copy process which wrote the bit, so that the work done by the gas is not undone. This appears to be a possibility because the information extracted from the gas into the bit is never lost during the Szilard cycle (see &lt;a href=&#34;#part-ii-information-is-never-lost&#34;&gt;#Part II Information Is Never Lost&lt;/a&gt;), and so in principle, there is still redundant information between the gas and bit. Then for what reason can&amp;rsquo;t an uncopy be performed?&lt;/p&gt;
&lt;p&gt;This post lays out the technical setup for my question in &lt;a href=&#34;#part-i-uncopying&#34;&gt;#Part I Uncopying&lt;/a&gt; and &lt;a href=&#34;#part-ii-information-is-never-lost&#34;&gt;#Part II Information Is Never Lost&lt;/a&gt;. At the bottom I am able to pose this &lt;a href=&#34;#question&#34;&gt;#Question&lt;/a&gt; rigorously. I don&amp;rsquo;t think I&amp;rsquo;ve discovered a loophole in the 2nd law. I fully expect that reversing the Szilard cycle is impossible, but I don&amp;rsquo;t understand why. I would love for someone to provide me an answer. I would find that very insightful and use it to improve my understanding of thermodynamics.&lt;/p&gt;
&lt;h1 id=&#34;part-i-uncopying&#34;&gt;Part I: Uncopying&lt;/h1&gt;
&lt;p&gt;The following images are taken from C. H. Bennett&amp;rsquo;s article, &lt;a href=&#34;https://link.springer.com/article/10.1007/BF02084158&#34;target=&#34;_blank&#34;&gt;&lt;em&gt;The thermodynamics of computation - a review&lt;/em&gt;&lt;/a&gt;, section 5.&lt;/p&gt;
&lt;h2 id=&#34;szilard-cycle&#34;&gt;Szilard cycle&lt;/h2&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220207112905.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;Szilard cycle&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The Szilard cycle depicted above extracts kinetic energy (KE) from a particle in a box (which you could think of as a gas containing one particle) with unknown position and velocity, all the while without changing the size of the box on net (the start and end of the process have the same sized box).&lt;/p&gt;
&lt;p&gt;The steps of the Szilard cycle are:&lt;/p&gt;
&lt;p&gt;(a)&lt;br&gt;
The particle is initially somewhere in the box. The box has a piston on each end (a movable wall with resistance).&lt;/p&gt;
&lt;p&gt;(b)&lt;br&gt;
A barrier is placed that divides the box into two sections. We don&amp;rsquo;t know which section the particle occupies.&lt;/p&gt;
&lt;p&gt;(c)&lt;br&gt;
A measurement is taken which determines which section the particle is in. The measurement outcome is stored in a bit of physical memory depicted on the right. That bit is initialized in a known &amp;ldquo;standard&amp;rdquo; state S (what I previously called the default state). The measurement puts the bit into the left (L) or right (R) states, depending on which side of the box the particle occupies (from our perspective we don&amp;rsquo;t know which state the bit is in).&lt;/p&gt;
&lt;p&gt;(d)&lt;br&gt;
The which-side information, stored in our bit, is used to determine which piston to push towards the middle. If we push the piston into the particle we will transfer KE to it, thus costing us energy. We want to push the piston through a vacuum (the side without the particle), which is an energy-free operation (in the ideal limit). Then the barrier is removed. Whenever the particle collides with the piston, the piston will be pushed outwards toward the end of the box, but its resistance will cause the particle to lose some KE. The resistance is due to the piston being connected to something we care about transforming, e.g. like moving a mass up against gravity. In general, we say the piston is performing work, which is a useful application of energy.&lt;/p&gt;
&lt;p&gt;(e)&lt;br&gt;
The piston is pushed all the way to the end of the box until it cannot move any further, which is its initial state in step (a). The box is now returned to its initial state, and the particle is missing some KE which we converted into useful work. However, the bit of memory we used to store the which-side measurement still has that piece of information stored in it. The final step is to put the bit into the standard state S (erasure), bringing us to (f) and completing the cycle.&lt;/p&gt;
&lt;p&gt;(f)&lt;br&gt;
The physical memory is cleared (put back into the standard state S), and the cycle is complete. The only difference between (a) and (f) is the net KE extracted from the particle.&lt;/p&gt;
&lt;p&gt;The Szilard cycle steps (a) through (e) are all reversible processes. That is to say, those steps can be undone without any energy cost. However, the memory erasure from step (e) to (f) is an irreversible process, since the information contained in the external memory is effectively lost when it is cleared. &lt;a href=&#34;https://en.wikipedia.org/wiki/Landauer%27s_principle&#34;target=&#34;_blank&#34;&gt;Landauer&amp;rsquo;s principle&lt;/a&gt; states that this irreversible erasure costs a minimum amount of energy, compensating for the apparent reduction in overall entropy of the particle-box system, thus preserving the 2nd law of thermodynamics, which states that the entropy of a system cannot be reduced for free. Step (f) makes the whole Szilard cycle irreversible.&lt;/p&gt;
&lt;h2 id=&#34;gas-thermodynamics&#34;&gt;Gas Thermodynamics&lt;/h2&gt;
&lt;p&gt;In classical thermodynamics, the change in entropy of a gas (with N particles) in a box, due to some process acting on the gas, is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\D S = c_v\ln\frac{T_f}{T_i} + R\ln\frac{V_f}{V_i}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $c_v$ and $R$ are constants which depend on the kind of gas, $T_i$ and $T_f$ are respectively the initial and final temperature of the gas, and $V_i$ and $V_f$ are respectively the initial and final volumes of the gas (volumes of the box). Note that temperature and volume are equilibrium macrostates of the gas. They are not well defined when the gas is in a transitionary state, e.g. if it has uneven temperature or is not uniformly distributed across all of the free space in the box. Then the change in entropy of the gas is only well defined if the process starts and ends in equilibrium states where $T_i,T_f,V_i$ and $V_f$ are all well defined.&lt;/p&gt;
&lt;p&gt;In some sense a one-particle gas is always in equlibrium. Its temperature is just the particle&amp;rsquo;s KE times a constant, (temperature is defined as being proportional to the average KE across all the particles) and its volume is just the volume of space the particle can access.&lt;/p&gt;
&lt;p&gt;In the Szilard cycle, $V_i=V_f$, and $T_f = T_i - \frac{2}{3k}E$ where $E\geq0$ is the KE that was extracted from the particle and $k$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Boltzmann_constant&#34;target=&#34;_blank&#34;&gt;Boltzmann constant&lt;/a&gt;. Then the change in entropy from start to end of the cycle is proportional to $\ln\frac{T_f}{T_i}=\lg\par{1-\frac{2E}{3kT_i}} \leq 0$. The 2nd law of thermodynamics states that total entropy cannot decrease. Since we reduced the entropy of the gas, the entropy of some other system involved in the process must have gone up by at least the same amount. The entropy of the physical bit of memory is what must have increased.&lt;/p&gt;
&lt;p&gt;Before the memory bit is erased, we can still reverse the process and move the entropy of the bit back into the gas (see &lt;a href=&#34;#uncopying&#34;&gt;#Uncopying&lt;/a&gt;). After the bit is erased, the entropy of the bit is moved into the environment, dispersed as heat energy. This is analogous to compressing an N particle gas to half of its volume, which heats up the gas enough to make the total change in entropy nonnegative, and then allowing the gas to cool down to its initial temperature by leaking heat into the environment. The gas compression and heating is reversible (an &lt;a href=&#34;https://en.wikipedia.org/wiki/Isentropic_process&#34;target=&#34;_blank&#34;&gt;isentropic process&lt;/a&gt;; &lt;a href=&#34;https://www.youtube.com/watch?v=dQeCEqkE9eE&#34;target=&#34;_blank&#34;&gt;animation&lt;/a&gt;). What is irreversible is the loss of heat energy to the environment, just like our loss of our bit of information to the environment, which also implies a necessary loss of energy to the environment by Landauer&amp;rsquo;s principle.&lt;/p&gt;
&lt;h2 id=&#34;uncopying&#34;&gt;Uncopying&lt;/h2&gt;
&lt;p&gt;To serve as an intuition pump for how uncopying would work physically, Bennett uses a &lt;a href=&#34;https://en.wikipedia.org/wiki/Single_domain_%28magnetic%29&#34;target=&#34;_blank&#34;&gt;&amp;ldquo;one-domain ferromagnet&amp;rdquo;&lt;/a&gt;, which is a fancy way of saying an object with an intrinsic magnetic field (as opposed to electromagnet that requires an electric current) which is &amp;ldquo;simple&amp;rdquo; in its shape, specifically the magnetic field can be described by a single direction - an arrow oriented in space. I&amp;rsquo;ll refer to this object simply as &amp;ldquo;a magnet&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Bennett supposes that absent any external magnetic fields, the magent&amp;rsquo;s field direction is stable, as in it is stuck in the up or down position. This can be represented by a potential field as a function of the magent&amp;rsquo;s angle of rotation:&lt;/p&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020220207114500.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020220207114500.png&#34; 
         alt=&#34;Potential energy as a function of rotation angle. By default we assume there are two potential wells, centered around the up and down orientations. Getting over the diving hump requires some minimum amount of energy to be put into the magnet, in the form of angular momentum.&#34; width=&#34;250&#34;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;span class=&#34;caption&#34;&gt;
            &lt;p&gt;Potential energy as a function of rotation angle. By default we assume there are two potential wells, centered around the up and down orientations. Getting over the diving hump requires some minimum amount of energy to be put into the magnet, in the form of angular momentum.&lt;/p&gt;
        &lt;/span&gt;
&lt;/span&gt;
&lt;p&gt;This magnet is our bit of physical memory. The magnet&amp;rsquo;s orientation stores a bit when it is in the up/down state, and is indeterminate when it has a sideways orientation.&lt;/p&gt;
&lt;p&gt;There is a simple process for copying the state of one magnetic bit onto another. In the figure below we have three magnets at play: the reference bit, the movable bit, and the data bit. The reference bit&amp;rsquo;s state is known to us, and defines what we consider to be the default (i.e. cleared, reset, erased) state of the bit we want to write to. The data bit contains information we want to copy to the movable bit.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220207114316.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
The movable bit starts at the top nearby the reference bit. We require that the reference and movable bits start in the same orientation (otherwise we cannot perform this process &amp;ldquo;for free&amp;rdquo;). The diagram to the right depicts the region of state space (i.e. phase space) to which we know the movable bit occupies. Call this the state region of the movable bit (i.e. phase region).&lt;/p&gt;
&lt;p&gt;We then push the movable bit downward through a sideways oriented magnetic field which has the effect of canceling out the magnetic field of the reference bit, causing the two potential wells to merge into one well. This transition from two to one well is smooth as the movable bit moves through the sideways magnetic field. As it moves further down towards the data bit, the single well morphs smoothly into two wells again.&lt;/p&gt;
&lt;p&gt;Notice that during the transition the potential field from two to one wells, the field is isÂ lopsided and asymmetric:&lt;br&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020220207120258.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020220207120258.png&#34; width=&#34;75&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;br&gt;
Likewise as the movable bit approaches the data bit, the potential field becomes lopsided again, which is how the movable bit &amp;ldquo;knows&amp;rdquo; which of the two wells to fall into as they emerge. The orientation of the data bit determines to which direction the movable bit will fall. Thus when the movable bit is close to the data bit, they are aligned and the copy is complete.&lt;/p&gt;
&lt;p&gt;This copy process is entirely reversible. Its reverse process is called an &amp;ldquo;uncopy&amp;rdquo;, where the data bit (whose orientation is unknown to us) becomes the reference bit, and the reference bit (in the known default state) becomes the data bit.&lt;/p&gt;
&lt;p&gt;Without the reference bit, the transition from two to one potential wells is symmetric, and the state region &amp;ldquo;spills over&amp;rdquo; the hump (timeline C below), causing our uncertainty about the magnet&amp;rsquo;s orientation to increase (corresponding to an entropy increase). This is an irreversible process.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220209144607.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
Also, if the reference bit and movable bits start out with opposite orientations, then as the potential field becomes lopsided, it will raise up the potential well the movable bit is occupying (which is opposite the one the reference bit is occupying). Lifting up a potential field under an object implies transfer of energy to that object (as potential energy). That is to say, we spend energy moving the movable bit through the sideways magnetic field. On the other hand, when the movable bit is in the &amp;ldquo;correct&amp;rdquo; well to start with, the bottom of that well remains at the same potential level through out the copy process, just moving sideways to the center and then to which ever well the data bit occupies.&lt;/p&gt;
&lt;p&gt;To perform the which-side measurement in the Szilard cycle, Bennett supposes the particle is charged so that the which-side information is naturally converted into magnetic orientation information. That is to say, the particle in a partition box is used as the data bit for our copy process. That copy process can be reversed with the uncopy process where the particle-box system becomes the reference bit. Note that the particle-box system is unaltered by the copy and uncopy operations.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220209145122.png&#34; alt=&#34;&#34;&gt;
&lt;/p&gt;
&lt;h1 id=&#34;part-ii-information-is-never-lost&#34;&gt;Part II: Information Is Never Lost&lt;/h1&gt;
&lt;p&gt;(The following images and videos I made with &lt;a href=&#34;https://www.wolfram.com/mathematica/&#34;target=&#34;_blank&#34;&gt;Mathematica&lt;/a&gt; and &lt;a href=&#34;https://slides.google.com&#34;target=&#34;_blank&#34;&gt;Google Slides&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;The Szilard cycle is a deterministic process when modeled with classical mechanics (point particles following internal trajectories and colliding with rigid objects). Non-determinism enters the picture because we do not know the particle&amp;rsquo;s initial state. We can represent our uncertainty with the set of all initial states in which we think the particle might be, called a state region (usually &amp;ldquo;phase&amp;rdquo; region).&lt;/p&gt;
&lt;p&gt;This is the partitioned box and its particle as depicted by Bennett in &lt;a href=&#34;#szilard-cycle&#34;&gt;#Szilard cycle&lt;/a&gt;:&lt;br&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020220209152732.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020220209152732.png&#34; width=&#34;400&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;br&gt;
This is the same partitioned box with color-coded spatial regions which the particle could potentially be initialized to. Red is the left side and blue is the right side. Note that this depicts 2D space (as opposed to 2D state space below).&lt;br&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020220209152749.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020220209152749.png&#34; width=&#34;400&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here the which-side information is depicted with color: Initial states on the left are colored red and initial states on the right are colored blue.&lt;/p&gt;
&lt;p&gt;However, this visualization leaves out a part of the state space: velocity. To be more precise, we should plot state space (phase space) which includes a velocity dimension for every position dimension. We would need a 4D plot for a particle in two spatial dimensions, and that is hard to visualize. For simplicity, let&amp;rsquo;s work with a particle confined to a single spatial dimension, giving us a 2D state space plot.&lt;/p&gt;
&lt;p&gt;Here is shown all initial states (position and velocity) the particle could occupy. States are colored red or blue for the left and right sides of the box respectively.&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020220209152858.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;Phase space plot of the initial state regions, separating out positive (rightward) and negative (leftward) velocities onto the positive and negative sides of the velocity axis (vertical). This depicted state region implies we know the particle&amp;#39;s velocity magnitude is within a certain range.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;For simplicity, I will model the piston pushing phase (d) from the Szilard cycle as a single continuous process. That is to say, instead of having the particle bounce off the piston many times, moving it slightly in discrete jumps, I will model the collision of the particle with the piston as fully inelastic, i.e. the particle and piston stick together and move together until the piston has reached the end of the box, at which point the particle bounces off. The particle gradually loses KE and slows down as it moves with the piston.&lt;/p&gt;
&lt;p&gt;For example, the trajectory of a particle initialized on the right side with a rightward facing velocity:&lt;br&gt;
&lt;video controls autoplay loop src=&#34;../../Szilard_cycle_particle_right.mp4&#34; caption=&#34;&#34; width=&#34;100%&#34;&gt;&lt;/video&gt;&lt;br&gt;
The trajectory of a particle initialized on the right side with a leftward facing velocity:&lt;br&gt;
&lt;video controls autoplay loop src=&#34;../../Szilard_cycle_particle_left.mp4&#34; caption=&#34;&#34; width=&#34;100%&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;p&gt;To show how the initial state regions (left and right sides) evolve over time, I uniformly sampled an ensemble of initial particle states and animated their trajectories over time:&lt;br&gt;
&lt;video controls autoplay loop src=&#34;../../Szilard_cycle_ensemble.mp4&#34; caption=&#34;&#34; width=&#34;100%&#34;&gt;&lt;/video&gt;&lt;br&gt;
It is clear from this animation that none of the trajectories overlap at any point. That means, in principle, one could determine which side the particle started in at any point in time if they could measure which color region the particle is currently in. The red and blue regions become more mixed over time, but they are always disjoint.&lt;/p&gt;
&lt;p&gt;Here at a later point in time the red and blue regions are still interlaced in a striped pattern:&lt;br&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020220209114223.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020220209114223.png&#34; width=&#34;300&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;question&#34;&gt;Question&lt;/h1&gt;
&lt;p&gt;Is it possible to use the scrambled which-side information (striped red-blue pattern above) contained in step (e) of the &lt;a href=&#34;#szilard-cycle&#34;&gt;#Szilard cycle&lt;/a&gt; to induce a reference magnetic field for an &lt;a href=&#34;#uncopying&#34;&gt;uncopy process&lt;/a&gt;? That would allow us to uncopy the bit of memory in the Szilard cycle without undoing the work we extracted from the particle.&lt;/p&gt;
&lt;p&gt;The specific modification to the Szilard cycle I&amp;rsquo;m proposing is this: Step (f) irreversibly resets the memory bit, costing some minimum amount of energy. Instead, consider an alternative step (f&#39;) where the external memory is reset back to the standard (default) state S via an uncopy process - the reversal of the copy process. As we saw above, this can be done without energy cost. The Szilard cycle with step (f&#39;) replacing step (f) would be reversible throughout, seemingly violating the 2nd law because total entropy would have decreased (it is not obvious to me that this uncopying would result in an increase in entropy anywhere else).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020220210064848.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020220210064848.png&#34; width=&#34;300&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;br&gt;
It is safe to assume the 2nd law does hold. The question then becomes, what prevents us from using the scrambled which-side information in the &amp;ldquo;gas&amp;rdquo; to uncopy the memory bit? Is this operation fundamentally disallowed by physics for whatever reason? Or is it merely a matter of technologically intractability? For instance, as time progresses the interlacing of red and blue becomes finer and finer, requiring finer and finer device precision.&lt;/p&gt;
&lt;p&gt;We could tackle this question by asking instead, is it possible to perform an observation on the particle such that only its &amp;ldquo;color&amp;rdquo; (which side it came from) is recorded in one bit of memory? If so, then the reverse of this process is the uncopy operation we are seeking. We already know that we could measure the particle&amp;rsquo;s position and velocity precisely (assuming a classical particle) using, say, a camera. The &amp;ldquo;camera process&amp;rdquo; would write many bits to memory (including a lot more than the particle&amp;rsquo;s state). Note that we would need to take two pictures in quick succession to capture the particles velocity. To reverse THAT process, we would need to feed as input ALL of the bits of information the camera would output in the forward direction. Without that input information, we cannot uncopy just a single bit, even if its a subset of the information.&lt;/p&gt;
&lt;p&gt;Thus, the question becomes, can we create a process that converts only the particle&amp;rsquo;s &amp;ldquo;color&amp;rdquo; information into magnetic polarity for use in an uncopy process? If no such process exists, how would we prove it?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redundancy And Copying</title>
      <link>https://danabo.github.io/blog/posts/redundancy-and-copying/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/redundancy-and-copying/</guid>
      <description>&lt;p&gt;Information in our universe can be copied, as evidenced by the ubiquitous copying of computer memory, books and paper everywhere, and our ability to non-destructively see and hear everything around us. Information is &lt;strong&gt;copied&lt;/strong&gt; (or &lt;a href=&#34;https://en.wikipedia.org/wiki/No-cloning_theorem&#34;target=&#34;_blank&#34;&gt;cloned&lt;/a&gt;) when the state of one system, the target, becomes correlated with the state of another system, the source, without destructively altering the state of the source. Information is &lt;strong&gt;moved&lt;/strong&gt;, on the other hand, when the state of the source is transferred to the target in a way that leaves the source&amp;rsquo;s state erased or overwritten with something else. In general, information copying between two systems is a special case of increasing information redundancy between two systems.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\n}{\bar}&lt;br&gt;
\newcommand{\xor}{\oplus}&lt;br&gt;
\newcommand{\es}{\emptyset}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\b}{\beta}&lt;br&gt;
\newcommand{\s}{\sigma}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\N}{\mb{N}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\H}{\mb{H}}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\Env}{\mf{E}}&lt;br&gt;
\newcommand{\expt}[2]{\mb{E}_{#1}\left[#2\right]}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[1]{_{\mid #1}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Dt}{{\Delta t}}&lt;br&gt;
\newcommand{\tr}{\rightarrowtail}&lt;br&gt;
\newcommand{\tx}{\prec}&lt;br&gt;
\newcommand{\qed}{\ \ \blacksquare}&lt;br&gt;
\newcommand{\c}{\overline}&lt;br&gt;
\newcommand{\A}{\mf{A}}&lt;br&gt;
\newcommand{\cA}{\c{\mf{A}}}&lt;br&gt;
\newcommand{\fB}{\mf{B}}&lt;br&gt;
\newcommand{\dg}{\dagger}&lt;br&gt;
\newcommand{\do}[2]{\underset{#1\leadsto #2}{\mathrm{do}}}&lt;br&gt;
\newcommand{\lgfr}[2]{\lg\par{\frac{#1}{#2}}}&lt;br&gt;
\newcommand{\sys}[2]{\left[#2\right]_{#1}}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/&#34;&gt;Physical Information&lt;/a&gt;, I defined conservation of information as the property that given some set $R \subseteq \O$, the time-evolved set $\t_\Dt(R)$ is fully determined, and given $\t_\Dt(R)$, the original set $R$ is fully determined. This is only true for all $R$ if $\t_\Dt$ is a bijection. All of our theories of physics have bijective time-evolution, and so it would be reasonable to assume that information is conserved in our universe. That is to say, information is never lost through time-evolution.&lt;/p&gt;
&lt;p&gt;The redundancy between two systems with state spaces $\mf{A}$ and $\mf{B}$ (as partitions of $\O$) is quantified by their mutual information&lt;/p&gt;
&lt;p&gt;$$\I(\mf{A}, \mf{B}) = \mb{E}_{a\in\mf{A}, b\in\mf{B}}\Big[i(a, b)\Big]\,,$$&lt;/p&gt;
&lt;p&gt;where $i(a,b) = \lgfr{\mu(a\cap b)\mu(\O)}{\mu(a)\mu(b)}$ is the pointwise mutual information between $a$ and $b$ as calculated with the provided measure $\mu$ (see &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#mutual-information&#34;&gt;Physical Information#mutual-information&lt;/a&gt; for details), and $\O = \bigcup\mf{A} = \bigcup\mf{B}$ is the domain. Their mutual information $\I(\mf{A}, \mf{B})$ is 0 when $\mf{A}$ and $\mf{B}$ are orthogonal. Since in my formulation, the state spaces of systems don&amp;rsquo;t change over time, i.e. $\mf{A}, \mf{B}$ are fixed through time, then redundancy between systems does not change. If two systems are defined to be orthogonal, they remain orthogonal.&lt;/p&gt;
&lt;p&gt;Given the constant redundancy between systems through time, it is surprising that information redundancy appears to change over time in our universe. Furthermore, you might naively conclude that redundancy cannot change over time in a universe that conserves information. How can changing information redundancy coexist with conservation of information?&lt;/p&gt;
&lt;p&gt;It is interesting to note that in quantum physics information copying is not possible (see the &lt;a href=&#34;https://en.wikipedia.org/wiki/No-cloning_theorem&#34;target=&#34;_blank&#34;&gt;no-cloning theorem&lt;/a&gt;), i.e. quantum information can only be moved around but not duplicated. If our universe is fundamentally quantum and information cannot be copied, then again, why does information appear to be copied everywhere? The answer lies in the distinction between quantum information, which cannot be copied, and classical information, which can be (this is out of scope for this post, but I might delve into quantum information theory in future posts).&lt;/p&gt;
&lt;h1 id=&#34;intuition-pumps&#34;&gt;Intuition Pumps&lt;/h1&gt;
&lt;p&gt;Information can be copied under bijective time evolution if we restrict ourselves to a subset of the state space. That is to say, some initial states of the universe appear to time-evolve into redundant states, while other initial states, by necessity do not (for time-evolution to be bijective). Let&amp;rsquo;s get a feel for how information copying under bijective time-evolution works by looking at a few toy universes in which information gets copied between systems over time.&lt;/p&gt;
&lt;p&gt;For simplicity, I&amp;rsquo;ll work with binary systems (two-state systems). We can create bigger systems by grouping many binary systems together into super-systems (each binary system is a sub-system). That is to say, the state spaces of these super-systems are binary tuples.&lt;/p&gt;
&lt;p&gt;Formally, let $\B = \set{0,1}$ be the binary alphabet.&lt;br&gt;
When I define system A to have the state space $A = \B^k$, then a state of system A is $a \in A$ where $a$ is a binary tuple. For example, $a = 001010\dots0$.&lt;br&gt;
When I define the state spaces for a few systems, say $A = \B^n,\ B=\B^m,\ C=\B^p$, then the state space of the universe is the Cartesian product, $\O = A\times B\times C$, and the state of the universe is the state tuple $\o = (a,b,c) \in \O$, which can also regarded as one big binary tuple of length $n+m+p$.&lt;/p&gt;
&lt;p&gt;Regarding time-evolution, here I&amp;rsquo;ll work in discrete time, i.e. $t \in \mb{Z}$.&lt;br&gt;
Then the family of bijective time-evolution functions on $\O$ form the discrete group, $(\set{\t_\Dt\mid t\in\mb{Z}},\circ)$, where $\t_1$ is the group generator, i.e.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_t = \begin{cases}&lt;br&gt;
\underbrace{\t_1\circ\dots\circ\t_1}_{t\ \mathrm{times}} &amp;amp; t &amp;gt; 0 \\&lt;br&gt;
\o\mapsto\o &amp;amp; t = 0 \\&lt;br&gt;
\underbrace{\t^{-1}_1\circ\dots\circ\t^{-1}_1}_{t\ \mathrm{times}} &amp;amp; t &amp;lt; 0&lt;br&gt;
\end{cases}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Thus, it&amp;rsquo;s sufficient to define $\t_1$ in order to specify the entire family $\set{\t_\Dt\mid t\in\mb{Z}}$.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define some notation that will make it easy to define time-evolution functions.&lt;br&gt;
For binary values $\alpha,\beta\in\B$,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\alpha\ \beta \in \B^2$ is tuple concatenation&lt;/li&gt;
&lt;li&gt;$\n{\beta}$ is the NOT operation&lt;/li&gt;
&lt;li&gt;$\alpha\cdot \beta$ is the AND operation&lt;/li&gt;
&lt;li&gt;$\alpha + \beta$ is the OR operation&lt;/li&gt;
&lt;li&gt;$\alpha \xor \beta$ is the XOR operation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For binary $k$-tuples $a, b \in \B^k$,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a_1$ is the first bit&lt;/li&gt;
&lt;li&gt;$a_k$ is the last bit&lt;/li&gt;
&lt;li&gt;$a_{i:j}$ is the slice $a_i\ a_{i+1}\ \dots\ a_{j-1}\ a_j$&lt;/li&gt;
&lt;li&gt;$a_{i:j}\ b_{k:\ell}$ is tuple concatenation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;simple-copier---style-1&#34;&gt;Simple Copier - style 1&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s take a look at the simplest possible copier, where the state one one system is copied to the state of another system in one time-step. There are actually two different copiers of this size. I&amp;rsquo;ll give them both.&lt;/p&gt;
&lt;p&gt;We have two systems, A and B, with state spaces&lt;br&gt;
$A = \B$&lt;br&gt;
$B = \B$&lt;/p&gt;
&lt;p&gt;The one-step time-evolution function is defined as&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\t_1(a, b) &amp;amp;= \begin{cases}(a,a) &amp;amp; b = 0 \\ (\n{a}, a) &amp;amp; b = 1\end{cases} \\&lt;br&gt;
&amp;amp;= (a \xor b,\ a)&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;If $b=0$ initially, then $\t_1$ copies A&amp;rsquo;s state to B&amp;rsquo;s state. If $b=1$ initially, then $\t_1$ also copies A&amp;rsquo;s state to B&amp;rsquo;s state and additionally flips A&amp;rsquo;s state.&lt;/p&gt;
&lt;p&gt;To sanity check that this is indeed a bijection, here is its inverse:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_{-1}(a, b) = (b,\ a\xor b)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;And here is the full I/O table for this function&lt;/p&gt;
&lt;p&gt;$(0,0)\mapsto(0,0)$&lt;br&gt;
$(0,1)\mapsto(1,0)$&lt;br&gt;
$(1,0)\mapsto(1,1)$&lt;br&gt;
$(1,1)\mapsto(0,1)$&lt;/p&gt;
&lt;p&gt;Bijective time-evolution on finite state spaces necessarily creates cycles. Here are the cycles for $\t_1$:&lt;br&gt;
$(0,0) \to (0,0)$&lt;br&gt;
$(0,1) \to (1,0) \to (1,1) \to (0,1)$&lt;/p&gt;
&lt;h2 id=&#34;simple-copier---style-2&#34;&gt;Simple Copier - style 2&lt;/h2&gt;
&lt;p&gt;This is another simplest copier that is almost the same as the first, save one difference.&lt;/p&gt;
&lt;p&gt;$A = \B$&lt;br&gt;
$B = \B$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_1(a, b) = (a,\ a\xor b)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_{-1}(a, b) = (a,\ a\xor b)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;(This function is it&amp;rsquo;s own inverse.)&lt;/p&gt;
&lt;p&gt;The full I/O table for this function:&lt;/p&gt;
&lt;p&gt;$(0,0)\mapsto(0,0)$&lt;br&gt;
$(0,1)\mapsto(0,1)$&lt;br&gt;
$(1,0)\mapsto(1,1)$&lt;br&gt;
$(1,1)\mapsto(1,0)$&lt;/p&gt;
&lt;p&gt;Bijective time-evolution on finite state spaces necessarily creates cycles. Here are the cycles for $\t_1$:&lt;br&gt;
$(0,0) \to (0,0)$&lt;br&gt;
$(0,1) \to (0,1)$&lt;br&gt;
$(1,0) \to (1,1) \to (1,0)$&lt;/p&gt;
&lt;h2 id=&#34;repeating-copier&#34;&gt;Repeating Copier&lt;/h2&gt;
&lt;p&gt;This universe operates on the same principle as our simplest copier, but scaled up. Now system A is a $k$-tuple of binary states, and the second system is called E (for environment), which is an $m$-tuple presumed to be much bigger than A, i.e. $m &amp;raquo; k$. System A will continuously duplicate its state into the environment until the environment &amp;ldquo;fills up&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Define this universe:&lt;/p&gt;
&lt;p&gt;$A  = \B^k$&lt;br&gt;
$E = \B^m$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_1(a,e) = ((a_{k}\xor e_{m})\ a_{1:k-1},\ a_{k}\ e_{1:m-1})&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_{-1}(a,e) = (a_{2:k}\ e_1,\ e_{2:m}\ (a_1\xor e_1))&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example of a time evolution, where $k=4$ and $m=8$, and the initial state of the universe is $(a,\ e) = (1011,\ 00000000)$:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;A&lt;/th&gt;
&lt;th&gt;E&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;00000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;10000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;11000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;01100000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;10110000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;11011000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;11101100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;01110110&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;10111011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0101&lt;/td&gt;
&lt;td&gt;11011101&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0010&lt;/td&gt;
&lt;td&gt;11101110&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0001&lt;/td&gt;
&lt;td&gt;01110111&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0000&lt;/td&gt;
&lt;td&gt;10111011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;00111011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1100&lt;/td&gt;
&lt;td&gt;00011101&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;00001110&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;00000111&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0011&lt;/td&gt;
&lt;td&gt;10000011&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we can see, system A keeps copying its state into system E so long as the last bit of E&amp;rsquo;s state remains zero. When that ceases to be true, system A&amp;rsquo;s state is corrupted, and this time-evolution is no longer performing a copy operation, but a move operation, which is destructive.&lt;/p&gt;
&lt;p&gt;If the environment is initialized to be &amp;ldquo;empty&amp;rdquo;, i.e. contain all zeros, and $m$ is incredibly large, then system A will copy itself for &lt;em&gt;virtually&lt;/em&gt; forever. We do not know whether our own universe has boundaries beyond what we can observe. Though empty space does appear to be empty, we do not know if it may fill up on long enough time scales, or if everything will continue to spread out forever. That is the difference between a finite and infinite $m$ in this example. (Though technically $m$ cannot be infinite here because then there would not be a last bit. I define some infinite environments below which fix this issue.)&lt;/p&gt;
&lt;h2 id=&#34;mover&#34;&gt;Mover&lt;/h2&gt;
&lt;p&gt;In contrast to copiers, movers do not preserve the state of system A. Here, we have two systems which swap their respective states over time.&lt;/p&gt;
&lt;p&gt;$A = B = \B^k$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_1(a, b) = (a_{2:k}\ b_1,\ b_{2:k}\ a_1)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_{-1}(a,b) = (b_k\ a_{1:k-1},\ a_k\ b_{1:k-1})&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;A&lt;/th&gt;
&lt;th&gt;B&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0000&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0001&lt;/td&gt;
&lt;td&gt;0110&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0010&lt;/td&gt;
&lt;td&gt;1100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0101&lt;/td&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0110&lt;/td&gt;
&lt;td&gt;0001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1100&lt;/td&gt;
&lt;td&gt;0010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;0101&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0000&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;scrambler&#34;&gt;Scrambler&lt;/h2&gt;
&lt;p&gt;$A = B = \set{0,\dots,k-1}$ are integer sets where $k$ is odd.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_1(a,b) = \Big(a+b \pmod{k},\ b-a \pmod{k}\Big)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_{-1}(a,b) = \Big(\frac{1}{2}(a-b) \pmod{k},\ \frac{1}{2}(a+b) \pmod{k}\Big)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;(Addition and subtraction here mean integer arithmetic, rather than boolean operations.)&lt;/p&gt;
&lt;p&gt;For example when $k=3$, the I/O table is&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$(a,b)$&lt;/th&gt;
&lt;th&gt;$\t_1(a,b)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$(0,0)$&lt;/td&gt;
&lt;td&gt;$(0,0)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(0,1)$&lt;/td&gt;
&lt;td&gt;$(1,1)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(0,2)$&lt;/td&gt;
&lt;td&gt;$(2,2)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(1,0)$&lt;/td&gt;
&lt;td&gt;$(1,2)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(1,1)$&lt;/td&gt;
&lt;td&gt;$(2,0)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(1,2)$&lt;/td&gt;
&lt;td&gt;$(0,1)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(2,0)$&lt;/td&gt;
&lt;td&gt;$(2,1)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(2,1)$&lt;/td&gt;
&lt;td&gt;$(0,2)$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$(2,2)$&lt;/td&gt;
&lt;td&gt;$(1,0)$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We will see later why I call this a scrambler.&lt;/p&gt;
&lt;h2 id=&#34;infinite-repeating-copier---style-1&#34;&gt;Infinite repeating copier - style 1&lt;/h2&gt;
&lt;p&gt;Here is an example of a copier with an infinite environment. I define a third system, X, which stores a &amp;ldquo;control bit&amp;rdquo;. When the state of X is 0, forward time-evolution performs copy operations. Otherwise, something else happens. This control bit is needed to maintain $\t_1$ as a bijection.&lt;/p&gt;
&lt;p&gt;$X = \B$&lt;br&gt;
$A  = \B^k$&lt;br&gt;
$E = \B^\infty$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\t_1(x, a, e) &amp;amp;= \begin{cases}&lt;br&gt;
(0,\ a_{k}\ a_{1:k-1},\ a_k\ e) &amp;amp; x = 0 \\&lt;br&gt;
(0,\ a,\ e) &amp;amp; x = 1 \and a_1 \neq e_1 \\&lt;br&gt;
(1,\ a_{2:k}\ a_1,\ e_{2:\infty})  &amp;amp; x = 1 \and a_1 = e_1&lt;br&gt;
\end{cases}&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\t_{-1}(x, a, e) &amp;amp;= \begin{cases}&lt;br&gt;
(0,\ a_{2:k}\ a_1,\ e_{2:\infty}) &amp;amp; x = 0  \and a_1 = e_1 \\&lt;br&gt;
(1,\ a,\ e) &amp;amp; x = 0 \and a_1 \neq e_1 \\&lt;br&gt;
(1,\ a_{k}\ a_{1:k-1},\ a_k\ e)  &amp;amp; x = 1&lt;br&gt;
\end{cases}&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;We can see that in reverse time, the universe performs copy operations when the state of X is one. Thus in forward time, when $x=1$, an &amp;ldquo;uncopy&amp;rdquo; operation is performed. This can be thought of as reversing a copy operation, but if there was no previous copy and systems A and E just happen to be redundant in the right way, then this time-evolution is simply making A and E less redundant.&lt;/p&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;X&lt;/th&gt;
&lt;th&gt;A&lt;/th&gt;
&lt;th&gt;E&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;0000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;1000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;1100000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;0110000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;1011000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;1101100â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;1110110â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;0111011â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;1011101â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;X&lt;/th&gt;
&lt;th&gt;A&lt;/th&gt;
&lt;th&gt;E&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;1011000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;0110000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;1100000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;1000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;0000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;0000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;1000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;1100000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;0110000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;1011000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To recap:&lt;br&gt;
X is a switch that determines the &amp;ldquo;direction&amp;rdquo; of this system.&lt;br&gt;
$x=0$ means copy A to E&lt;br&gt;
$x=1$ means &amp;ldquo;undo&amp;rdquo; the copy from A to E&lt;br&gt;
If $x=1$ and $a_1\neq e_1$, then an undo copy cannot be performed, and the state of X is flipped (the operating mode is changed from uncopy to copy).&lt;/p&gt;
&lt;p&gt;The point of having two modes of operation is so that any combined state of A and E has a history that produces it, i.e. that $\t_1$ is surjective. If A and E are redundant in the right way, then their immediate history is a sequence of copy steps. However, if they are not redundant (in the right way), then their history is a sequence of uncopy steps which just happened to culminate with the current states.&lt;/p&gt;
&lt;h2 id=&#34;infinite-repeating-copier---style-2&#34;&gt;Infinite repeating copier - style 2&lt;/h2&gt;
&lt;p&gt;In this universe, the environment is infinite from the left and the right, i.e. states are $e_{-\infty:\infty} \in E$. I&amp;rsquo;ll break up the environment into two halves, $E_+$ containing indices $1$ to $\infty$, and $E_-$ containing indices $-\infty$ to $0$.&lt;/p&gt;
&lt;p&gt;$A  = \B^k$&lt;br&gt;
$E_+ = \B^\infty$&lt;br&gt;
$E_- = \B^\infty$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_1(e_{-\infty:0}, a, e_{1:\infty}) = (e_{-\infty:-1},\ (e_0\xor a_k)\ a_{1:k-1},\ a_k\ e_{1:\infty})&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_{-1}(e_{-\infty:0}, a, e_{1:\infty}) = (e_{-\infty:0}\ (e_1\xor a_1),\ a_{2:k}\ e_1,\ e_{2:\infty})&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This time-evolution passes the left-side environment through A and copies A into the right-side environment. So long as the left-side environment&amp;rsquo;s last bit is always zero, system A&amp;rsquo;s state is preserved. Otherwise, system A is corrupted.&lt;/p&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$E_-$&lt;/th&gt;
&lt;th&gt;$A$&lt;/th&gt;
&lt;th&gt;$E_+$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;0000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;1000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;1100000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;0110000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;1011000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;1101&lt;/td&gt;
&lt;td&gt;1101100â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;1110110â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦0000000&lt;/td&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;0111011â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$E_-$&lt;/th&gt;
&lt;th&gt;$A$&lt;/th&gt;
&lt;th&gt;$E_+$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;â¦1110111&lt;/td&gt;
&lt;td&gt;1011&lt;/td&gt;
&lt;td&gt;0000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦1111011&lt;/td&gt;
&lt;td&gt;0101&lt;/td&gt;
&lt;td&gt;1000000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦1111101&lt;/td&gt;
&lt;td&gt;0010&lt;/td&gt;
&lt;td&gt;1100000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦1111110&lt;/td&gt;
&lt;td&gt;1001&lt;/td&gt;
&lt;td&gt;0110000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦1111111&lt;/td&gt;
&lt;td&gt;1100&lt;/td&gt;
&lt;td&gt;1011000â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦1111111&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;0101100â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦1111111&lt;/td&gt;
&lt;td&gt;1111&lt;/td&gt;
&lt;td&gt;0010110â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;â¦1111111&lt;/td&gt;
&lt;td&gt;0111&lt;/td&gt;
&lt;td&gt;1001011â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;definition-of-copying&#34;&gt;Definition of copying&lt;/h1&gt;
&lt;p&gt;In all of the &amp;ldquo;copier&amp;rdquo; examples above, what about their time evolution makes them copiers? What exactly do we mean when we say that they copy the information contained in system A to system E?&lt;/p&gt;
&lt;p&gt;Ultimately, when information has been copied from A to E, then we can look at the state of E to gain information about the state of A. That implies the state spaces of A and E have become redundant (given that they were not to begin with). To understand how these systems can change in redundancy over time without actually altering definitions of their state spaces over time, let&amp;rsquo;s go through the simple copier example again.&lt;/p&gt;
&lt;h2 id=&#34;simple-copier-revisited&#34;&gt;Simple copier revisited&lt;/h2&gt;
&lt;p&gt;Recall that $\t_1$ is fully specified by this list of mappings:&lt;br&gt;
$00\mapsto00$&lt;br&gt;
$01\mapsto10$&lt;br&gt;
$10\mapsto11$&lt;br&gt;
$11\mapsto01$&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m using binary strings in place of explicit tuples of digits for visual simplicity. I&amp;rsquo;ll also start working in the partition-as-state-space framework (see &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#information-theory-of-systems&#34;&gt;Physical Information#information-theory-of-systems&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Let $\O = \set{00,01,10,11}$ be the universe&amp;rsquo;s state space.&lt;br&gt;
Let $\mf{A} = \set{\set{00, 01}, \set{10,11}}$ be the state space of system A. So A&amp;rsquo;s state is the first bit.&lt;br&gt;
Let $\mf{B} = \set{\set{00, 10}, \set{01, 11}}$ be the state space of system B. So B&amp;rsquo;s state is the second bit.&lt;br&gt;
Any state $a\in\mf{A}$ is the set of all states in $\O$ for which system A is in the same state $a$, and likewise for $b\in\mf{B}$.&lt;/p&gt;
&lt;p&gt;Notice that A and B are orthogonal, i.e.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\I(\mf{A}, \mf{B}) &amp;amp;= \sum_{a\in\mf{A}}\sum_{b\in\mf{B}} \frac{\abs{a\cap b}}{\abs{\O}}i(a, b) \\&lt;br&gt;
&amp;amp;= \sum_{a\in\mf{A}}\sum_{b\in\mf{B}} \frac{\abs{a\cap b}}{\abs{\O}}\lgfr{\abs{a\cap b}\abs{\O}}{\abs{a}\abs{b}} \\&lt;br&gt;
&amp;amp;= \sum_{a\in\mf{A}}\sum_{b\in\mf{B}} \frac{1}{4}\lgfr{1\cdot 4}{2\cdot 2} \\&lt;br&gt;
&amp;amp;= 0\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $\O = \bigcup\mf{A} = \bigcup\mf{B}$.&lt;/p&gt;
&lt;p&gt;(Here I am using the counting measure, $\mu(R) = \abs{R}$ for $R\subseteq\O$).&lt;/p&gt;
&lt;p&gt;This is a way of quantifying how decoupled the two systems are, where 0 is maximum decoupling, meaning that A can be in any state and B can be in any state.&lt;/p&gt;
&lt;p&gt;I believe that what intuitively makes this universe a copier is that if we vary A&amp;rsquo;s initial state, then the state of both A and B vary together later in time. To see what I mean, choose the intervention set $J = \set{00, 10}$, which varies A&amp;rsquo;s state while keeping B&amp;rsquo;s state at zero (this is just a state of B). The effect set one step into the future is $\t_1(J) = \set{00, 11}$. In our representation of A&amp;rsquo;s state as the first bit and B&amp;rsquo;s state as the second bit, all the outcomes in the effect set are ones where A and B have equal states, i.e. $00$ and $11$.&lt;/p&gt;
&lt;p&gt;Consider the state spaces of A and B restricted to the sets $J$ and $\t_1(J)$:&lt;br&gt;
$\mf{A}\dom{J} = \set{\set{00}, \set{10}},\ \mf{B}\dom{J} = \set{\set{00, 10}, \set{}}$.&lt;br&gt;
$\mf{A}\dom{\t_1(J)} = \mf{B}\dom{\t_1(J)} = \set{\set{00}, \set{11}}$.&lt;/p&gt;
&lt;p&gt;(For any partition $\mf{P}$ and set $R$, the notation $\mf{P}\dom{R} \df \set{p \cap R \mid p \in \mf{P}}$ is the sub-partition restricted to the domain $R$.)&lt;/p&gt;
&lt;p&gt;How redundant are these state spaces? It is straight forward to calculate:&lt;br&gt;
$\I(\mf{A}\dom{J}, \mf{B}\dom{J}) = \I(\mf{A}, \mf{B} \mid J) = 0$.&lt;br&gt;
$\I(\mf{A}\dom{\t_1(J)}, \mf{B}\dom{\t_1(J)}) = \I(\mf{A}, \mf{B} \mid \t_1(J)) = \H(\mf{A}\dom{\t_1(J)}) = 1$.&lt;/p&gt;
&lt;p&gt;($\I(\mf{A}, \mf{B} \mid R) = \I(\mf{A}\dom{R}, \mf{B}\dom{R})$ because $\O$ in $\I(\cdot, \cdot)$ is determined by the arguments, i.e. $\O = \bigcup\mf{A}\dom{R} = \bigcup\mf{B}\dom{R} = R$.)&lt;/p&gt;
&lt;p&gt;An example of calculating conditional mutual information:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\I(\mf{A}, \mf{B} \mid J) &amp;amp;= \sum_{a\in\mf{A}}\sum_{b\in\mf{B}} \frac{\abs{a\cap b\cap J}}{\abs{J}}i(a, b \mid J) \\&lt;br&gt;
&amp;amp;= \sum_{a\in\mf{A}}\sum_{b\in\mf{B}} \frac{\abs{a\cap b\cap J}}{\abs{J}}\lgfr{\abs{a\cap b\cap J}\abs{J}}{\abs{a\cap J}\abs{b\cap J}} \\&lt;br&gt;
&amp;amp;= \frac{1}{2}\lgfr{1\cdot 2}{1\cdot 2} +  \frac{1}{2}\lgfr{1\cdot 2}{1\cdot 2} + 0 + 0 \\&lt;br&gt;
&amp;amp;= 0\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;We can see that the redundancy has increased from time 0 to time 1.&lt;br&gt;
At time 0, system B can only be in the state $\set{00, 10}$, while system A can be in either state $\set{00}$ or $\set{10}$. In this sense, A&amp;rsquo;s state is independent of B.&lt;br&gt;
Meanwhile, at time 1, if A is in state $\set{00}$ then B must be in state $\set{00}$, and if A is in state $\set{11}$ then B must be in state $\set{11}$. This is maximal redundancy. Hence, system A&amp;rsquo;s state is duplicated in system B.&lt;/p&gt;
&lt;p&gt;$\t_1$ copies the state of A to B, but information is conserved overall. This apparent contradiction is explained by the assumption that $\O$ is restricted to $J$. Though $\t_1$ is bijective on $\O$, the image $\t_1(J)$ does not equal $J$.&lt;/p&gt;
&lt;h3 id=&#34;uncopying&#34;&gt;Uncopying&lt;/h3&gt;
&lt;p&gt;Because $\t_1$ is cyclic, the universe must eventually return to its initial state. That means any copying done will eventually be undone. We can see this if we compute two-step time-evolution:&lt;/p&gt;
&lt;p&gt;$J = \set{00, 10}$ as before.&lt;br&gt;
$\t_1(J) = \set{00, 11}$&lt;br&gt;
$\t_2(J) = \set{00, 01}$&lt;br&gt;
==&amp;gt; $\mf{A}\dom{\t_2(J)} = \set{\set{00, 01}, \set{}},\ \mf{B}\dom{\t_2(J)} = \set{\set{00}, \set{01}}$&lt;br&gt;
$\I(\mf{A}\dom{\t_2(R)}, \mf{B}\dom{\t_2(R)}) = \I(\mf{A}, \mf{B} \mid \t_2(R)) = 0$&lt;/p&gt;
&lt;p&gt;So $\I(\mf{A}, \mf{B} \mid \t_2(R)) - \I(\mf{A}, \mf{B} \mid \t_1(R)) = -1$.&lt;br&gt;
Time-step 1 to 2 &amp;ldquo;uncopies&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;relativity-of-redundancy&#34;&gt;Relativity of redundancy&lt;/h3&gt;
&lt;p&gt;The analysis above uses the intervention set $J$ that varies system A. What if we use the intervention set that varies system B?&lt;/p&gt;
&lt;p&gt;Let $J = \set{00, 01}$, which varies system B while holding system A fixed. This intervention set gives us the causal effect of system B from system A&amp;rsquo;s perspective. Then we have&lt;br&gt;
$\t_1(J) = \set{00, 10}$.&lt;br&gt;
$\mf{A}\dom{J} = \set{\set{00, 01}, \set{}},\ \mf{B}\dom{J} = \set{\set{00}, \set{01}}$.&lt;br&gt;
$\mf{A}\dom{\t_1(J)} = \set{\set{00}, \set{10}}$.&lt;br&gt;
$\mf{B}\dom{\t_1(J)} = \set{\set{00, 10}, \set{}}$.&lt;br&gt;
Thus $\I(\mf{A}, \mf{B} \mid J) = \I(\mf{A}, \mf{B} \mid \t_1(J)) = 0$.&lt;/p&gt;
&lt;p&gt;Now it appears that the redundancy between A and B doesn&amp;rsquo;t change over time! In fact, from A&amp;rsquo;s perspective, information is being moved from A to B (but not duplicated), as evidenced by $\I(\mf{B}, \t_1(J)) = 1$, which is maximal.&lt;/p&gt;
&lt;p&gt;So from A&amp;rsquo;s perspective information is being moved to B (while also moving B to A), and simultaneously from B&amp;rsquo;s perspective, information is being copied to B (destroying B&amp;rsquo;s initial state). How peculiar.&lt;/p&gt;
&lt;h2 id=&#34;copying-vs-redundancy&#34;&gt;Copying vs redundancy&lt;/h2&gt;
&lt;p&gt;In general, I define the &lt;strong&gt;redundancy&lt;/strong&gt; between $\A$ and $\fB$ due to domain restriction $J\subseteq\O$ as&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\rho \df \I(\mf{A}, \mf{B} \mid J)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;(rho for &amp;ldquo;redundancy&amp;rdquo;) and the &lt;strong&gt;change in redundancy&lt;/strong&gt; due to domain restriction $J \subseteq \O$ over time period $\Dt$ as&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\D\rho = \I(\mf{A}, \mf{B} \mid \t_\Dt(J)) - \I(\mf{A}, \mf{B} \mid J)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;If $\D\rho &amp;gt; 0$ then redundancy between systems A and B has increased in the time interval $\Dt$. Likewise, if $\D\rho &amp;lt; 0$ then redundancy has decreased, and if $\D\rho = 0$ there is no change in redundancy.&lt;/p&gt;
&lt;p&gt;For arbitrary systems A and B, I say that information has been copied from system A to system B in the time interval $\Dt$ when system A (in the past) causally effects both system A in the future and system B in the future. Formally, let $J$ be an intervention set varying the state of system A while holding system A&amp;rsquo;s environment fixed, i.e. $J \in \cA$ where $\cA$ is a partition complement of A. Then system A has copied some of its information to system B iff&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\H(\A \mid \t_\Dt(J)) &amp;gt; 0\quad\mathrm{and}\quad\H(\fB \mid \t_\Dt(J)) &amp;gt; 0\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Recall from &lt;a href=&#34;https://danabo.github.io/blog/posts/causality-and-information/#effect-on&#34;&gt;Causality And Information#effect-on&lt;/a&gt;, that $\H(\A \mid \t_\Dt(J))$ is the quantity of causal effect that system A has on system A in the future, and $\H(\fB \mid \t_\Dt(J))$ is the quantity of causal effect that system A has on system B in the future (assuming that $J$ varies system A).&lt;/p&gt;
&lt;p&gt;Using the identities&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\H(\A\otimes\fB \mid \t_\Dt(J)) = \H(\A \mid \t_\Dt(J)) + \H(\fB \mid \t_\Dt(J)) - \I(\A,\fB \mid \t_\Dt(J))&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;(This is just one way of defining conditional mutual information, e.g. &lt;a href=&#34;https://en.wikipedia.org/wiki/Conditional_mutual_information#Some_identities&#34;target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\A\otimes\mf{B}, \t_\Dt(J)) = \I(\A, \t_\Dt(J)) + \I(\mf{B}, \t_\Dt(J)) + \I(\A, \mf{B} \mid \t_\Dt(J)) - \I(\A, \mf{B})&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;(see &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#general-case&#34;&gt;Physical Information#general-case&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;we see that for $\H(\A \mid \t_\Dt(J)) + \H(\fB \mid \t_\Dt(J)) &amp;gt; \H(\A\otimes\fB \mid \t_\Dt(J))$ to be the case then $\I(\A,\fB \mid \t_\Dt(J))$ must be non-zero. Thus, for system A to have a large causal effect on both system A and system B (in the future), there needs to be redundancy between A and B. We also see that  $\I(\A, \mf{B} \mid \t_\Dt(J))$ is bounded above by $\I(\A\otimes\mf{B}, \t_\Dt(J)) + \I(\A, \mf{B})$. This puts a limit on how much information redundancy there can be, and thus how much information can be copied.&lt;/p&gt;
&lt;h2 id=&#34;scrambler-revisited&#34;&gt;Scrambler revisited&lt;/h2&gt;
&lt;p&gt;Given system A and its environment, with respective state spaces $\A, \cA$, and respective intervention sets $J^\dg \in \cA$ (varying system A) and $J \in \A$ (varying the environment),&lt;br&gt;
is there any necessary relationship between $\I(\A, \cA \mid \t_\Dt(J))$ and $\I(\A, \cA \mid \t_\Dt(J^\dg))$? That is to say, if system A copies its information to the environment, then can the environment also copy its information to system A?&lt;/p&gt;
&lt;p&gt;It would be easy to think the answer is no. Copying requires duplication. If system A&amp;rsquo;s state is copied to the environment, then its own state should remain in tact (otherwise this is merely information moving). For the environment to copy information to A, the state of A would need to be overwritten. Here is the apparent contradiction.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll now construct a setup where a system and its environment simultaneously copy their entire states onto each other without contradiction, i.e. $\I(\A, \cA \mid \t_\Dt(J)) = h(J)$ and $\I(\A, \cA \mid \t_\Dt(J^\dg)) = h(J^\dg)$ are both at their maximums.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s consider the smallest scrambler (&lt;a href=&#34;#scrambler&#34;&gt;#Scrambler&lt;/a&gt;) where $k=3$:&lt;/p&gt;
&lt;p&gt;$A = B = \set{0,1,2}$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\t_1(a,b) = \Big(a+b \pmod{3},\ b-a \pmod{3}\Big)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;The I/O table is&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$ab$&lt;/th&gt;
&lt;th&gt;$\t_1(ab)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$00$&lt;/td&gt;
&lt;td&gt;$00$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$01$&lt;/td&gt;
&lt;td&gt;$11$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$02$&lt;/td&gt;
&lt;td&gt;$22$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$10$&lt;/td&gt;
&lt;td&gt;$12$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$11$&lt;/td&gt;
&lt;td&gt;$20$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$12$&lt;/td&gt;
&lt;td&gt;$01$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$20$&lt;/td&gt;
&lt;td&gt;$21$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$21$&lt;/td&gt;
&lt;td&gt;$02$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$22$&lt;/td&gt;
&lt;td&gt;$10$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Using the partition formulation of systems A and B:&lt;br&gt;
$\A = \set{a\up{0},a\up{1},a\up{2}} = \set{\set{00,01,02},\set{10,11,12},\set{20,21,22}}$&lt;br&gt;
$\fB = \set{b\up{0},b\up{1},b\up{2}} = \set{\set{00,10,20},\set{01,11,21},\set{02,12,22}}$&lt;/p&gt;
&lt;p&gt;I will show that $\I(\A, \fB \mid \t(a\up{0}))$ and $\I(\A, \fB \mid \t(b\up{0}))$ are simultaneously at their maximum values. This suggests that, counterintuitively, information can be simultaneously copied from A to B, and from B to A.&lt;/p&gt;
&lt;p&gt;$a\up{0} = \set{00,01,02}$&lt;br&gt;
$b\up{0} = \set{00,10,20}$&lt;br&gt;
$\t_1(a\up{0}) = \set{00, 11, 22}$&lt;br&gt;
$\t_1(b\up{0}) = \set{00, 12, 21}$&lt;/p&gt;
&lt;p&gt;$\A\dom{a\up{0}} = \set{\set{00,01,02},\set{}}$&lt;br&gt;
$\fB\dom{a\up{0}} = \set{\set{00},\set{01},\set{02}}$&lt;br&gt;
$\A\dom{\t_1(a\up{0})} = \set{\set{00},\set{11},\set{22}}$&lt;br&gt;
$\fB\dom{\t_1(a\up{0})} = \set{\set{00},\set{11},\set{22}}$&lt;br&gt;
$\I(\A, \fB \mid a\up{0})) = 0$&lt;br&gt;
$\I(\A,\fB\mid \t_1(a\up{0})) = \lgfr{1\cdot 3}{1\cdot 1} = \lg(3) = h(a\up{0})$&lt;br&gt;
$\H(\A \mid \t_1(a\up{0})) = \H(\fB \mid \t_1(a\up{0})) = \lg(a\up{0})$&lt;/p&gt;
&lt;p&gt;$\A\dom{b\up{0}} = \set{\set{00},\set{10},\set{20}}$&lt;br&gt;
$\fB\dom{b\up{0}} = \set{\set{00,10,20},\set{}}$&lt;br&gt;
$\A\dom{\t_1(b\up{0})} = \set{\set{00},\set{12},\set{21}}$&lt;br&gt;
$\fB\dom{\t_1(b\up{0})} = \set{\set{00},\set{12},\set{21}}$&lt;br&gt;
$\I(\A, \fB \mid b\up{0})) = 0$&lt;br&gt;
$\I(\A,\fB\mid \t_1(b\up{0})) = \lg(3) = h(b\up{0})$&lt;br&gt;
$\H(\A \mid \t_1(b\up{0})) = \H(\fB \mid \t_1(b\up{0})) = \lg(3)$&lt;/p&gt;
&lt;p&gt;So $\I(\A,\fB\mid \t_1(a\up{0})) = h(a\up{0})$ and $\I(\A,\fB\mid \t_1(b\up{0})) = h(b\up{0})$ which are their respective maximum values (because $\I(\A,\fB) = 0$ and $\I(\A\otimes\fB, R) = h(R)$ for any $R\subseteq\O$).&lt;/p&gt;
&lt;h1 id=&#34;is-redundancy-fictitious&#34;&gt;Is Redundancy Fictitious?&lt;/h1&gt;
&lt;p&gt;The appearance of copied state is due to the representation of systems that we use. Notice that my proposed definition of copying and redundancy each rely on state partitions to be provided. If we just had a universe consisting of state space $\O$ and bijective time-evolution $\t_\Dt$, without any systems defined within the universe, there would not be any apparent copying or redundancy.&lt;/p&gt;
&lt;p&gt;Take the simple copier again. I defined the state space as $\O = \set{00,01,10,11}$. The representation of theses states as binary strings begs the copying interpretation. What if instead I stripped away the extraneous representation of these states so that they became featureless objects? Like this:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\O = \set{\o_1, \o_2, \o_3, \o_4}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $\t_1$ has the following I/O table:&lt;br&gt;
$\o_1 \mapsto \o_1$&lt;br&gt;
$\o_2 \mapsto \o_3$&lt;br&gt;
$\o_3 \mapsto \o_4$&lt;br&gt;
$\o_4 \mapsto \o_2$&lt;/p&gt;
&lt;p&gt;Now the possible states in $\O$ don&amp;rsquo;t have any inherent interpretation, representation, or meaning. Their only feature is that they can be distinguished, i.e. they have identity. Combined with the time-evolution function $\t_1$, the only structure that is apparent here are the cycles $\o_1 \to \o_1$ and $\o_2 \to \o_3 \to \o_4 \to \o_1$.&lt;/p&gt;
&lt;p&gt;We can go ahead and define whatever systems we like (having arbitrary state spaces). However, there are two trivial systems for this toy universe.&lt;/p&gt;
&lt;p&gt;System T, whose states are the cycles:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mf{T} = \set{\set{\o_1}, \set{\o_2, \o_3, \o_4}}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;System O, whose states are all singleton:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mf{O} = \set{\set{\o_1}, \set{\o_2}, \set{\o_3}, \set{\o_4}}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Both these systems&#39; states never change through time, i.e. $\t_1(\set{\o_1}) = \set{\o_1}$ and $\t_1(\set{\o_2, \o_3, \o_4}) = \set{\o_2, \o_3, \o_4}$, and obviously $\t_1(\mf{O}) = \mf{O}$.&lt;/p&gt;
&lt;p&gt;It is easy to show that using any of the sets in $\mf{T}$ or $\mf{O}$ as intervention sets $J$ results in no change in redundancy over time, i.e. $\I(\mf{T}, \mf{O} \mid J) = \I(\mf{T}, \mf{O} \mid \t_\Dt(J))$ for all $\Dt$.&lt;/p&gt;
&lt;p&gt;For any universe defined by $\O$ and $\t_\Dt$, there is always a trivial system $\mf{T}$ whose states (equivalence classes) consist of the cycles on $\O$ under time evolution, and a trivial system consisting of the singleton partition $\mf{O}$ on $\O$. Both systems are always static through time, and their redundancy doesn&amp;rsquo;t change over time. Thus, for any universe, there is always a definition of two systems s.t. copying is not taking place and redundancy is not appearing over time.&lt;/p&gt;
&lt;p&gt;Clearly, redundancy and copying are relative phenomena - specifically relative to a particular system in the universe. This begs the question: Is the delineation between systems is objective or arbitrary. That is to say, what makes system A have the particular state space $\A$, what makes system B have the particular state space $\fB$, etc. ?  See &lt;a href=&#34;&#34; class=&#34;broken&#34;&gt;Preferred Representation Problem&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The observation of redundancy between two systems A and B implies any of&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$\I(\A, \fB) &amp;gt; 0$, i.e. your working definition of the systems in the universe contains redundancy.&lt;/li&gt;
&lt;li&gt;$\I(\A, \fB \mid J) &amp;gt; 0$, i.e. you are restricting the state space of the universe, i.e. making assumptions about what states the universe cannot be in.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The observation that redundancy in the universe increases over time implies any of&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$\A\up{t+\Dt} \neq \A\up{t}$ or $\fB\up{t+\Dt} \neq \fB\up{t}$, i.e. your definition of the state spaces of systems A and B is changing over time.&lt;/li&gt;
&lt;li&gt;$\I(\A, \fB \mid \t_\Dt(J)) &amp;gt; 0$ you are restricting the state space of the universe (making assumptions), and the time evolution of that restricted domain is causing redundancy to change over time.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;the-problem-of-assumptions-in-intelligence&#34;&gt;The Problem Of Assumptions In Intelligence&lt;/h1&gt;
&lt;p&gt;Why does our universe appear to have redundancy?&lt;/p&gt;
&lt;p&gt;Given that information copying and redundancy appear all around us, we must conclude that our brains operate on a state space with which there is naturally a lot of redundancy between systems (as we delineate them).&lt;/p&gt;
&lt;p&gt;It is important to draw a distinction between physical information that systems have (&lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#systems-have-information&#34;&gt;Physical Information#systems-have-information&lt;/a&gt;) and the conscious perception of information in intelligent and sentient systems. The former depends on the objective existence of both a universe state space $\O$ and the state space of that system, e.g. $\mf{A}$. The latter may be entirely independent of the former, i.e. an intelligent system might be aware of very different information than the system physically has. For an intelligent system to know what information it physically has would require it to have meta-information about itself, i.e. information about its own state space and state.&lt;/p&gt;
&lt;p&gt;The problem of assumptions is to explain what assumptions intelligent life make about their surroundings, and whether those assumptions are arbitrary or can be derived from some principles or evolutionary history of life on Earth. The answer to this question should also tell us what assumptions (or inductive biases or priors, to use machine learning terminology) to build into artificial intelligence in order for it to be general purpose, at least to the extent that humans are.&lt;/p&gt;
&lt;h2 id=&#34;alternative-framing&#34;&gt;Alternative framing&lt;/h2&gt;
&lt;p&gt;Another way of framing the problem of assumptions:&lt;/p&gt;
&lt;p&gt;Let $a\up{t} \in \A$ be a state of system A. Then if system A has the information $\O\tr a\up{t}$, it has information about its own future and the future of some other system B, quantified by $\I(\A, \t_\Dt(a\up{t}))$ and $\I(\fB, \t_\Dt(a\up{t}))$. Furthermore, if $\I(\mf{A}, \mf{B} \mid \t_\Dt(a\up{t})) &amp;gt; 0$, then system A &amp;ldquo;knows&amp;rdquo; that system A and B will be redundant in the future, given the information $\O\tr\t_\Dt(a\up{t})$. However, when that future time arrives, system A no longer has the information $\O\tr\t_\Dt(a\up{t})$, but instead has the information $\O\tr\t_\Dt(a\up{t+\Dt})$. Note that necessarily $a\up{t}\neq a\up{t+\Dt}$ in order for $\I(\mf{A}, \mf{B} \mid \t_\Dt(a\up{t})) &amp;gt; 0$ to hold. So although there would be redundancy between systems A and B knowing $\O\tr\t_\Dt(a\up{t})$, system A no longer has that information and the appearance of redundancy is lost when time $t+\Dt$ arrives.&lt;/p&gt;
&lt;p&gt;For redundancy to exist in the present moment, rather than the past or the future, there needs to be such an additional assumption, i.e. an a priori narrowing down of $\O$ to some smaller domain that makes otherwise orthogonal systems redundant. This assumption is not physical, as I&amp;rsquo;ve defined physical information. Yet all living things make such assumptions in their operation. See &lt;a href=&#34;&#34; class=&#34;broken&#34;&gt;The Origin Of Assumptions In Living Systems&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://danabo.github.io/blog/posts/causality-and-information/#information-about-entails-effect-on&#34;&gt;Causality And Information#information-about-entails-effect-on&lt;/a&gt;, I concluded that the only way for a system to have information about another system&amp;rsquo;s future is for the former system to causally determine the latter system. However, that is clearly not true in our universe. You can look at a map and drive on a sequence of streets you&amp;rsquo;ve never been on before, and yet you knew those streets would be there and where they would lead. You did not cause the streets to be as they were. You were able to have information about the streets because the map and the streets (as systems) have redundant information. In general, all life depends on information redundancy and environment prediction to survive and propagate. Life itself is a product of information redundancy - i.e. living organisms are self-replicators, and DNA stores the information that gets copied when an organism reproduces.&lt;/p&gt;
&lt;p&gt;Perhaps the redundancies we perceive might offer clues as to the restricted state spaces human brains consciously operate under (i.e. assumptions our brains make).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Causality And Information</title>
      <link>https://danabo.github.io/blog/posts/causality-and-information/</link>
      <pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/causality-and-information/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;https://danabo.github.io/blog/posts/causality-for-physics/&#34;&gt;Causality For Physics&lt;/a&gt;, I introduced Pearlian interventions for physical systems that evolve over time. In &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/&#34;&gt;Physical Information&lt;/a&gt;, I defined what it means for a system to have information. Here, I will merge these threads and talk about what it means for a system to have causal effect, and the connection with information.&lt;/p&gt;
&lt;h1 id=&#34;review&#34;&gt;Review&lt;/h1&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\es}{\emptyset}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\s}{\sigma}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\N}{\mb{N}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\H}{\mb{H}}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\Env}{\mf{E}}&lt;br&gt;
\newcommand{\expt}[2]{\mb{E}_{#1}\left[#2\right]}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\Mid}{\,\middle|\,}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[1]{_{\mid #1}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Dt}{{\Delta t}}&lt;br&gt;
\newcommand{\tr}{\rightarrowtail}&lt;br&gt;
\newcommand{\tx}{\prec}&lt;br&gt;
\newcommand{\qed}{\ \ \blacksquare}&lt;br&gt;
\newcommand{\c}{\overline}&lt;br&gt;
\newcommand{\A}{\mf{A}}&lt;br&gt;
\newcommand{\cA}{\c{\mf{A}}}&lt;br&gt;
\newcommand{\fB}{\mf{B}}&lt;br&gt;
\newcommand{\cB}{\c{\mf{B}}}&lt;br&gt;
\newcommand{\dg}{\dagger}&lt;br&gt;
\newcommand{\Do}{{\mathrm{do}}}&lt;br&gt;
\newcommand{\do}[2]{\underset{#1\leadsto #2}{\mathrm{do}}}&lt;br&gt;
\newcommand{\lgfr}[2]{\lg\par{\frac{#1}{#2}}}&lt;br&gt;
\newcommand{\sys}[2]{\left[#2\right]_{#1}}&lt;br&gt;
\require{cancel}&lt;br&gt;
$$&lt;/p&gt;
&lt;h2 id=&#34;information&#34;&gt;Information&lt;/h2&gt;
&lt;p&gt;This is a review of &lt;a href=&#34;https://danabo.github.io/blog/posts/bayesian-information-theory/&#34;&gt;Bayesian information theory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For possibility set $\O$ and subset $R\subseteq \O$, I define information as the narrowing-down of $\O$ to $R$, represented by the tuple&lt;br&gt;
$$&lt;br&gt;
\O \tr R \df (\O,R)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Suppose some $\o^*\in\O$ is the true possibility. Then the information $\O \tr R$ corresponds to the knowledge that $\o^* \in R$ and $\o^* \notin \O\setminus R$. Any set $A\subseteq\O$ is &lt;strong&gt;true&lt;/strong&gt; iff $\o^*\in A$, and &lt;strong&gt;false&lt;/strong&gt; otherwise.&lt;/p&gt;
&lt;p&gt;Given a measure $\mu$ on $\O$ (need not be normalized), the information $\O\tr R$ is quantified by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(R) \df \lgfr{\mu(\O)}{\mu(R)}\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which is the number of halvings to go from $\mu(\O)$ to $\mu(R)$.&lt;/p&gt;
&lt;p&gt;Given the sets $R, D \subseteq \O$ where $D$ is to be regarded as a &lt;em&gt;domain&lt;/em&gt; that we are narrowing down $\O$ to, the information $D \tr R\dom{D}$ is quantified by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(R \mid D) \df \lgfr{\mu(D)}{\mu(R\dom{D})}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
R\dom{D} \df R \cap D&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;is a shorthand for set intersection, which makes clear that we are restricting set $R$ to domain $D$.&lt;/p&gt;
&lt;p&gt;The information $\O\tr D$ is quantified by $h(D)$ which decomposes into&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(D) = h(R \mid D) + i(R, D)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where the pointwise mutual information (PMI) is defined as&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
i(R, D) = \lgfr{\mu(R\dom{D})\mu(\O)}{\mu(R)\mu(D)}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;In other words, the information quantity $h(D)$ (due to the domain restriction $\O\tr D$), is the sum of information about $D$ and information missing about $D$.&lt;/p&gt;
&lt;p&gt;If $i(R, A) = h(A)$, then $R \subseteq A$ and so the information $\O\tr R$ implies certainty that $A$ is true.&lt;br&gt;
If $i(R, A) = 0$, then $R \subseteq A$ contains no information about whether $A$ is true.&lt;br&gt;
If $i(R, A) &amp;lt; 0$, then information is lost about whether $A$ is true due to the information $\O\tr R$, i.e. $\O\tr R$ contains information about whether $A$ is false.&lt;br&gt;
If $i(R, A) = -\infty$, then $R \cap A = \es$ and $\O\tr R$ implies certainty that $A$ is false, i.e. an infinite amount of information would be needed to have certainty that $A$ is true.&lt;/p&gt;
&lt;p&gt;See &lt;a href=&#34;https://danabo.github.io/blog/posts/information-algebra/#mutual-information&#34;&gt;Information Algebra#mutual-information&lt;/a&gt; for further intuition on the meaning of PMI.&lt;/p&gt;
&lt;p&gt;I use $h(A \tr B) \df h(B \mid A)$ as a shorthand for quantity of the information $A \tr B$. Note that $h(\O \tr B) = h(B \mid \O) = h(B)$.&lt;/p&gt;
&lt;h2 id=&#34;physical-systems&#34;&gt;Physical Systems&lt;/h2&gt;
&lt;p&gt;Continuing from &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/&#34;&gt;Physical Information&lt;/a&gt;, let $\t_\Dt$ for $t\in\R$ be a family of bijective time-evolution functions on the universe&amp;rsquo;s state space $\O$ which form the group $(\set{\t_\Dt \mid \Dt\in\R}, \circ)$, where &amp;ldquo;$\circ$&amp;rdquo; is the function composition operator. Any system is defined by its state space, which is a partition on $\O$. For example, system A has state space $\mf{A}$, where each element $a\in\mf{A}$ is a possible state of the system, and $a\subseteq\O$ is the set of all states of the universe for which system A is in the same state $a$. State equivalence w.r.t. system A induces an equivalence relation on $\O$ where $\mf{A}$ is the set of equivalence classes:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\sys{\mf{A}}{\o} = a\,\,\mathrm{s.t.}\,\,\o\in a&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;A partition complement of $\A$, denoted $\cA$ (if one exists), satisfies the following properties:&lt;/p&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;$\cA$ is a partition of $\O$.&lt;/li&gt;
&lt;li&gt;$\I(\A, \cA) = 0$,&lt;/li&gt;
&lt;li&gt;$\A\otimes\cA = \mf{O} = \set{\set{\o}\mid\o\in\O}$,&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;where $\A\otimes\cA = \set{a\cap a^\dg \mid a\in\A \and a^\dg\in\cA}$ is the partition product of $\A$ and $\cA$, and $\mf{O}$ is the singleton partition of $\O$, which can be thought of as the universe&amp;rsquo;s state space. $\cA$ is the state space of system A&amp;rsquo;s environment, which is everything in the universe outside of system A.&lt;/p&gt;
&lt;h2 id=&#34;interventions&#34;&gt;Interventions&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;https://danabo.github.io/blog/posts/causality-for-physics/&#34;&gt;Causality For Physics&lt;/a&gt;, I introduced the &lt;strong&gt;intervention&lt;/strong&gt; on a trajectory of a system. Let $\s:\R\to\O$ be a &lt;strong&gt;trajectory&lt;/strong&gt;, which is a function from time to states s.t. $\s(t+\Dt) = \t_\Dt(\s(t))$ for all $t,\Dt\in\R$. We say that $\s$ is &lt;strong&gt;$\t$-valid&lt;/strong&gt;. An intervention at time $T$ is a surgery on $\s$, i.e. a modification to $\s$, s.t. $\s$ on the domains $(-\infty,T)$ and $(T,\infty)$ are each $\t$-valid, but $\s$ on the domain $(T-\e,T+\e)$ for $\e&amp;gt;0$ is not $\t$-valid.&lt;/p&gt;
&lt;p&gt;The &amp;ldquo;do&amp;rdquo;-operator performs an intervention on trajectory $\s$ given state-replacement function $I : \O\to\O$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\do{I}{T}[\s](t) \df \begin{cases}\s(t) &amp;amp; t &amp;lt; T \\ \t_{t-T}(I(\s(T))) &amp;amp; t\geq T\end{cases}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Let $I_\o = \_\mapsto \o$ be the constant state-replacement function that outputs $\o$, and define $\s_\o$ to be the trajectory s.t. $\s_\o(T) = \o$. Then&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\do{I_\o}{T}[\s](t) = \begin{cases}\s(t) &amp;amp; t &amp;lt; T \\ \s_\o(t) &amp;amp; t\geq T\end{cases}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;h1 id=&#34;intervention-sets&#34;&gt;Intervention Sets&lt;/h1&gt;
&lt;p&gt;Judea Pearl defines causal effect as the set of all changes resulting from all possible interventions on a variable (see &lt;a href=&#34;https://danabo.github.io/blog/posts/causality-for-physics/#causal-effect&#34;&gt;Causality For Physics#causal-effect&lt;/a&gt; for details). To characterize causal effect in physical systems, it follows that we should consider a set of interventions taken at some time $T$ in parallel (so to speak). Specifically, an &lt;strong&gt;intervention set&lt;/strong&gt; is a set of states, $J\subseteq\O$, representing the set of simultaneous interventions that set the universe&amp;rsquo;s state at time $T$ to every $\o\in J$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mc{J}_\Do = \left\{\do{I_\o}{T} \,\middle|\, \o\in J\right\}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This set of interventions applied to a trajectory $\s$ results in the set of modified trajectories,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mc{J}_\Do\s = \left\{\par{t\mapsto\begin{cases}\s(t) &amp;amp; t &amp;lt; T \\ \s_\o(t) &amp;amp; t\geq T\end{cases}} \,\middle|\, \o\in J\right\}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;The set of states $E_\Dt = \left[\mc{J}_\Do\s\right](T+\Dt)$ for $\Dt &amp;gt; 0$ is called the &lt;strong&gt;effect set&lt;/strong&gt; of the intervention set $J$ at time $T+\Dt$. Notice that $E_\Dt = \t_\Dt(J)$.&lt;/p&gt;
&lt;p&gt;Because time-evolution is &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_chain&#34;target=&#34;_blank&#34;&gt;Markovian&lt;/a&gt; (state at time $t$ only depends on state at $t-\e$ for arbitrarily small $\e&amp;gt;0$), we can entirely disregard the pre-intervention trajectory $\s$. The effect set $E_\Dt$ (for every $\Dt &amp;gt; 0$) fully characterizes the effect $\Dt$ into the future of the intervention set $J$. Because $E_\Dt$ depends only on $J$ and not the trajectory $\s$, we can bypass the &amp;ldquo;do&amp;rdquo;-operator entirely and just work with intervention sets and effect sets.&lt;/p&gt;
&lt;p&gt;With this simplification, we can just as easily perform retro-causal interventions. That is to say, $E_\Dt = \t_\Dt(J)$ where $\Dt &amp;lt; 0$ is also an effect set, i.e. the set of retro-effects due to intervening at time $T$ and propagating the changes into the past. Furthermore, $E_0 = \t_0(J) = J$ is also an effect set, and I consider an intervention to be its own simultaneous effect at the time the intervention is taken.&lt;/p&gt;
&lt;p&gt;Interventions that propagate causal effects into the past and future are &lt;strong&gt;bidirectional&lt;/strong&gt;. In the case of trajectories, a bidirectional intervention that sets time $T$ to state $\o$ replaces $\s$ with the alternative trajectory $\s_\o$, completely erasing any trace of $\s$. Bidirectional interventions don&amp;rsquo;t perform surgeries, losing the key feature of Pearlian interventions. If you are suspecting that this kind of intervention is merely conditionalization, you are correct. Because our time-evolution is Markovian and we are conditioning on a node in the Markov chain (the &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_blanket&#34;target=&#34;_blank&#34;&gt;Markov blanket&lt;/a&gt;), the &amp;ldquo;do&amp;rdquo;-operator and conditionalization are equivalent operations (see &lt;a href=&#34;https://danabo.github.io/blog/posts/causality-for-physics/#when-interventions-and-conditionalization-are-equivalent&#34;&gt;Causality For Physics#when-interventions-and-conditionalization-are-equivalent&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;From here on, I&amp;rsquo;ll only work with intervention sets and effect sets, leaving out mention of the &amp;ldquo;do&amp;rdquo;-operator and surgeries on trajectories entirely.&lt;/p&gt;
&lt;h1 id=&#34;quantifying-causal-effect&#34;&gt;Quantifying Causal Effect&lt;/h1&gt;
&lt;p&gt;Interventions on causal models are usually taken from the 1st person perspective, i.e. the perspective of a human or &amp;ldquo;agent&amp;rdquo; that is trying to decide what to do in the world. I&amp;rsquo;ll start from that perspective, and then shift to a 3rd person perspective where interventions are w.r.t. systems within the model.&lt;/p&gt;
&lt;p&gt;Suppose we (the creators of this physical model) know that the universe is in state $\o\up{t}$ at time $t$. Then we have the information $\O\tr\set{\o\up{t}}$ about time $t$, and the information $\O\tr\set{\t_\Dt(\o\up{t})}$ about time $t+\Dt$.&lt;/p&gt;
&lt;p&gt;Applying the intervention set $J$ at time $t$ means that now the universe can be in any of the states in $J$ (or all of them at the same time if you prefer to think of it that way). Our information about the state of the universe at time $t$ has been reduced to $\O\tr J$, and $\O\tr \t_\Dt(J)$ about the state at time $t+\Dt$.&lt;/p&gt;
&lt;p&gt;Regarding information quantities, we started with $h\par{\set{\o\up{t}}}$ bits (certainty that the universe is in state $\o\up{t}$), and the intervention set $J$ reduced our information to $h(J)$ bits, for an information loss of $h\par{\set{\o\up{t}}} - h(J) = \lgfr{\mu(J)}{\mu\set{\o\up{t}}}$ bits. This is the number of doublings it takes to expand the set $\set{\o\up{t}}$ out to $J$, just as $h(J)$ is the number of halvings it takes to narrow down $\O$ to $J$.&lt;/p&gt;
&lt;p&gt;In general, let $E = \t_\Dt(J)$ be an effect set. $E$ replaces $\o\up{t+\Dt}$ as the state of the universe at time $t+\Dt$, which we can view as expanding out the singleton set $\set{\o\up{t+\Dt}}$ to $E$, which requires $\lgfr{\mu(E)}{\mu\set{\o\up{t+\Dt}}}$ doublings, and is also the quantity of information lost about what state the universe is in at time $t+\Dt$. I call this the &lt;strong&gt;quantity of causal effect&lt;/strong&gt; of $E$.&lt;/p&gt;
&lt;p&gt;Note that we can write this quantity more succinctly as $\lg\nu_{\o\up{t+\Dt}}(E)$, which now looks like the log-size of $E$, where the measure $\nu_\o(E) = \mu(E)/\mu\set{\o}$ is defined as a rescaling of $\mu$ so that $\o$ has the unit size. In this sense, $\o$ serves as a reference for choice of units when computing the size of $E$. If $\mu$ is uniform (i.e. $\mu\set{\o} = \mu\set{\o&#39;}$ for all $\o,\o&#39;\in\O$), then $\o$ is irrelevant for calculating the log-size, and we have $\lg\nu(E) = \lg\mu(E) - u$ where $u=\lg\mu\set{\o}$ is a constant. Furthermore, if $\mu$ is the counting measure, then $\lg\nu(E) = \lg\abs{E}$.&lt;/p&gt;
&lt;h2 id=&#34;information-algebra-review&#34;&gt;Information Algebra Review&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;https://danabo.github.io/blog/posts/information-algebra/#mutual-information&#34;&gt;Information Algebra#mutual-information&lt;/a&gt;, I gave the intuition that pointwise mutual information (PMI), $i(A, D)$, quantifies the amount by which the information needed to have certainty about $A$ is reduced by having $\O\tr D$. PMI is also the negative change in information due to replacing $\O\tr A$ with $D \tr A\dom{D}$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
i(A, D) &amp;amp;= -(h(D \tr A\dom{D}) - h(\O\tr A)) \\&lt;br&gt;
&amp;amp;= h(A) - h(A \mid D)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;The conditional information, $h(A \mid D)$, quantifies the remaining amount of information needed to have certainty about $A$, given $\O\tr A$. Conditional information is the change in information due to replacing $\O\tr D$ with $\O\tr A\dom{D}$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(A \mid D) &amp;amp;= h(\O\tr A\dom{D}) - h(\O\tr D) \\&lt;br&gt;
&amp;amp;= h(A\cap D) - h(D)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Their sum of $i(A,D)$, the information had about whether $A$ is true, plus $h(A\mid D)$, the information still needed to know that $A$ is true, is the total quantity of information $h(A)$ about whether $A$ is true:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(A) = i(A, D) + h(A\mid D)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;h2 id=&#34;effect-algebra&#34;&gt;Effect Algebra&lt;/h2&gt;
&lt;p&gt;Above I defined the quantity of causal effect due to effect set $E$ as $\lg\mu(E) - u$ where $u$ is some normalization constant (which sets the unit size for the scaled measure $\nu$). I used singleton sets of the form $\set{\o}$ as references for the unit size, i.e. $u = \lg\mu\set{\o}$.&lt;/p&gt;
&lt;p&gt;In general, any set $A\subseteq\O$ can be a reference for scaling $\mu$. The quantity of the causal effect $E$ relative to $A$ is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\lg\mu(E) - \lg\mu(A) &amp;amp;= \lg\par{\frac{\mu(E)}{\mu(A)}\cdot\frac{\mu(\O)}{\mu(\O)}}\\&lt;br&gt;
&amp;amp;= h(A) - h(E) \\&lt;br&gt;
&amp;amp;= -(h(\O\tr E) - h(\O\tr A))\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This is simply the change in information quantity due to replacing $\O\tr A$ with $\O\tr E$, i.e. the net information change due to replacing $A$ with $E$. This replacement operation can be decomposed into two steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Narrowing down $A$ to $A\dom{E}$, for an information gain of $h(A \tr A\dom{E}) = h(A\dom{E} \mid A) = h(E \mid A)$ halvings.&lt;/li&gt;
&lt;li&gt;Expanding out $A\dom{E}$ to $E$, for an information loss of $h(E \tr A\dom{E}) = h(A \mid E)$ doublings.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Quantity of causal effect is their difference:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(A) - h(E) &amp;amp;= \cancel{i(A, E)} + h(A \mid E) - (\cancel{i(E, A)} + h(E \mid A))\\&lt;br&gt;
&amp;amp;= h(A \mid E) - h(E \mid A) \\&lt;br&gt;
&amp;amp;= h(E \tr A\dom{E}) - h(A \tr A\dom{E})\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;So for any $A$, the total quantity of effect relative to $A$ (rescaling scaling so that $\nu(A) = 1$) equals the information lost about $A$ due to effect $E$ minus the information gained about $A$ due to effect $E$.&lt;/p&gt;
&lt;p&gt;If $A \subseteq E$, then $h(A) - h(E) = h(A \mid E)$.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210521185922.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210521185922.png&#34; 
         alt=&#34;Combined replacement operation, going from $A$ to $E$.&#34; width=&#34;600&#34;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;span class=&#34;caption&#34;&gt;
            &lt;p&gt;Combined replacement operation, going from $A$ to $E$.&lt;/p&gt;
        &lt;/span&gt;
&lt;/span&gt;&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210521185913.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;Two step replacement operation: 1. Narrowing down $A$ to $A\dom{E}$; 2. Expanding out $A\dom{E}$ to $E$.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;effect-on&#34;&gt;Effect-On&lt;/h2&gt;
&lt;p&gt;Just as $i(A,E)$ is the quantity of &amp;ldquo;information-about&amp;rdquo;,&lt;br&gt;
$h(A \mid E)$ is quantity of &amp;ldquo;effect-on&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;$i(A,E)$ is the relative change in quantity of information needed to know that $A$ is true, due to gaining the information $\O\tr E$.&lt;/p&gt;
&lt;p&gt;$h(A\mid E)$ is the quantity of information lost about whether $A$ is true due to the loss of information $E \tr \set{\o^*}$, where $\o^*$ is the true state (assuming $\o^* \in E$).&lt;/p&gt;
&lt;p&gt;When I discuss intervention sets w.r.t. systems below, those intervention sets will always contain the true state of the universe.&lt;/p&gt;
&lt;h1 id=&#34;systems&#34;&gt;Systems&lt;/h1&gt;
&lt;p&gt;Let $\o\up{t}\in\O$ be the true state of the universe at time $t$.&lt;br&gt;
System A has state space $\A$ and system A&amp;rsquo;s environment has state space $\cA$, which is a partition complement of $\A$.&lt;br&gt;
Let $a\up{t}=\sys{\A}{\o\up{t}}\in\A$ and $\c{a}\up{t}=\sys{\cA}{\o\up{t}}\in\cA$ be the states of system A and the environment respectively at time $t$.&lt;br&gt;
Then $a\up{t}\cap\c{a}\up{t} = \set{\o\up{t}}$.&lt;/p&gt;
&lt;p&gt;In the usual formulation of causality, an intervention is an action taken on the world by an agent. In my formulation, an intervention set $J$ is a collection of counterfactual states, i.e. states that the universe &lt;em&gt;could&lt;/em&gt; be in. The effect of an intervention set is uncertainty about which state the universe is in, either in the past, present, or future. That is to say, causal effect is lack of information.&lt;/p&gt;
&lt;p&gt;System A lacks information about the environment&amp;rsquo;s state, and so from system A&amp;rsquo;s perspective, the universe could be in any one of the states $\o \in a\up{t}$. This is logically equivalent to applying the intervention set $J = a\up{t}$ at time $t$. The effect $E = \t_\Dt(a\up{t})$ at time $t+\Dt$ is system A&amp;rsquo;s lack of information about time $t+\Dt$. Likewise, from the environment&amp;rsquo;s perspective, the universe can be in any of the states $\o\in\c{a}\up{t}$, and so on.&lt;/p&gt;
&lt;p&gt;System A has the information quantity $h(a\up{t})$ at time $t$, but also the uncertainty quantity (lack of information) $h\par{\set{\o\up{t}} \Mid a\up{t}}$. They add up to the total information there is to have about the true state of the universe:&lt;/p&gt;
&lt;p&gt;$$h\par{a\up{t}} + h\par{\set{\o\up{t}} \Mid a\up{t}} = h\par{\set{\o\up{t}}}\,.$$&lt;/p&gt;
&lt;p&gt;If we consider the intervention set $J = a\up{t}$, then $h\par{\set{\o\up{t+\Dt}} \Mid \t_\Dt(a\up{t})}$ is the quantity of causal effect at time $t+\Dt$ due to replacing $\set{\o\up{t+\Dt}}$ with $\t_\Dt(a\up{t})$. By to conservation of information quantity, this quantity of causal effect is constant for all $\Dt\in\R$. This quantity is the total &lt;strong&gt;causal power&lt;/strong&gt; of the environment from system A&amp;rsquo;s perspective. Likewise, $h\par{\set{\o\up{t}} \Mid \c{a}\up{t}} = h\par{\set{\o\up{t+\Dt}} \Mid \t_\Dt(\c{a}\up{t})}$ is the total causal power of system A, from the environment&amp;rsquo;s perspective.&lt;/p&gt;
&lt;p&gt;Causal power is a constant through time, but can vary depending on which state $\o\in\O$ is true. That is to say, $h\par{\set{\o} \Mid \sys{\A}{\o}}$ need not equal $h\par{\set{\o&#39;} \Mid \sys{\A}{\o&#39;}}$ for $\o,\o&#39;\in\O$, and likewise for $h\par{\set{\o} \Mid \sys{\cA}{\o}}$ and $h\par{\set{\o&#39;} \Mid \sys{\cA}{\o&#39;}}$.&lt;/p&gt;
&lt;h2 id=&#34;effect-vs-information&#34;&gt;Effect vs Information&lt;/h2&gt;
&lt;p&gt;In addition to system A and it&amp;rsquo;s environment, consider any system B with state space $\fB$.&lt;/p&gt;
&lt;p&gt;Following from &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#information-about-systems&#34;&gt;Physical Information#information-about-systems&lt;/a&gt;, at time $t$, system A has the information quantity $i(b,\t_\Dt(a\up{t}))$ about whether some state $b\in\fB$ is true (contains $\o\up{t+\Dt}$) at time $t+\Dt$.&lt;/p&gt;
&lt;p&gt;Also, from system A&amp;rsquo;s perspective at time $t$, the environment has the effect quantity $h(b \mid \t_\Dt(a\up{t}))$ on $b$ at time $t+\Dt$, which is the quantity of information system A is missing about whether $b$ is true (the quantity of information needed to have certainty that $b$ is true).&lt;/p&gt;
&lt;p&gt;The total quantity of information there is to have about whether $b$ is true decomposes into information had about $b$ and information missing about $b$ (effect on $b$):&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(b) = i(b, \t_\Dt(a\up{t})) + h(b \mid \t_\Dt(a\up{t}))\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Likewise, system A&amp;rsquo;s environment (at time $t$) has the information $i(b,\t_\Dt(\c{a}\up{t}))$ about whether $b$ is true at time $t+\Dt$, and from its perspective, system A has the effect quantity $h(b \mid \t_\Dt(\c{a}\up{t}))$ on $b$ at time $t+\Dt$. We have the decomposition $h(b) = i(b, \t_\Dt(\c{a}\up{t})) + h(b \mid \t_\Dt(\c{a}\up{t}))$.&lt;/p&gt;
&lt;p&gt;Note that if $b \cap \t_\Dt(a\up{t}) = \es$, then $i(b, \t_\Dt(a\up{t})) = -\infty$ and $h(b \mid \t_\Dt(a\up{t})) = \infty$, meaning that system A is missing an infinite quantity of information about whether $b$ is true, i.e. system A has certainty that $b$ is false. The effect of the environment on $b$ is infinite, meaning that the effect of varying the environment is to always make $b$ false. On the other hand, if $h(b \mid \t_\Dt(a\up{t})) = 0$, then $i(b, \t_\Dt(a\up{t})) = h(b)$ and the effect of varying the environment is to always make $b$ true, and thus system A has certainty that $b$ is true.&lt;/p&gt;
&lt;h1 id=&#34;sum-conservation-laws&#34;&gt;Sum-Conservation Laws&lt;/h1&gt;
&lt;p&gt;Analogous to &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#sum-conservation-laws&#34;&gt;Physical Information#sum-conservation-laws&lt;/a&gt;, quantity of causal effect decomposes into a conserved sum.&lt;/p&gt;
&lt;p&gt;Let $E$ be an effect set and $b\in\fB$ be a possible state of system B such that $b \cap E$ is non-empty contains the true state $\o\in\O$. Then $h(\set{\o}) - h(E) = h(\set{\o} \mid E)$ is the total quantity of effect $E$, and $h(b \mid E)$ is the effect $E$ on $b$.&lt;/p&gt;
&lt;p&gt;Suppose $h(b \mid E) &amp;lt; h(\set{\o} \mid E)$. Then we might ask, &amp;ldquo;where did the remaining effect go?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Shrinking $b$ down to $b\cap c$ s.t. $b\cap c \subseteq E$, then we have $h(b\cap c \mid E) = \lg\mu(E) - \lg\mu(b\cap c)$, which is the quantity of causal effect $E$ using $b\cap c$ as the reference unit size. Furthermore, if $c$ is chosen so that $b\cap c = \set{\o}$, then $h(b\cap c \mid E) = h(\set{\o} \mid E)$ is the total quantity of effect $E$.&lt;/p&gt;
&lt;p&gt;We have the following decomposition:&lt;br&gt;
$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(b\cap c \mid E) &amp;amp;= h(b \mid E) + h(b \mid c \cap E)\\&lt;br&gt;
&amp;amp;= h(b \mid E) + h(c \mid E) - i(b, c \mid E)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Since $h(\cdot \mid \cdot)$ is always positive, $h(b\cap c \mid E) = h(b \mid E) + h(b \mid c \cap E)$ is a decomposition into positive terms. The next line, $h(b\cap c\mid E) = h(b \mid E) + h(c \mid E) - i(b, c \mid E)$ is a decomposition into the separate effects of $E$ on $b$ and $c$ individually, minus their interaction.&lt;/p&gt;
&lt;p&gt;This nicely complements the information sum-law from &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#pointwise&#34;&gt;Physical Information#pointwise&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
i(b \cap c, E) = i(b, E) + i(c, E) - i(b, c, E)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $i(b \cap c, E) = h(E)$ when $b \cap c \subseteq E$.&lt;/p&gt;
&lt;p&gt;When added together, they form the combined decomposition:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(b \cap c) &amp;amp;= i(b \cap c, E) + h(b\cap c \mid E) \\&lt;br&gt;
&amp;amp;= (i(b, E) + i(c, E) - i(b, c, E)) + (h(b \mid E) + h(c\mid E) - i(b, c \mid E))\\&lt;br&gt;
&amp;amp;= (i(b, E) + h(b \mid E)) + (i(c, E) + h(c \mid E)) - i(b,c) \\&lt;br&gt;
&amp;amp;= h(b) + h(c) - i(b,c)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;h2 id=&#34;self-interventions&#34;&gt;Self-Interventions&lt;/h2&gt;
&lt;p&gt;Going back to system A and its environment, with respective state spaces $\A$ and the partition-complement $\cA$, recall that $a^\dg \in \cA$ is both a state of system A&amp;rsquo;s environment and an intervention set varying system A while keeping the environment held fixed. From the environment&amp;rsquo;s perspective, system A has the effect set $E = \t_\Dt({a^\dg}\up{t})$, and the quantity of effect $h(a^\dg \mid E)$ on the environment state $a^\dg$, and $h(a \mid E)$ on system A&amp;rsquo;s state $a$.&lt;/p&gt;
&lt;p&gt;We could ask, does system A have causal effect from system A&amp;rsquo;s perspective? At first this may seem like a contradiction of terms, since I defined the information that system A has to be exactly it&amp;rsquo;s current state. Causal effect of system A is due to lack of information about system A&amp;rsquo;s state.&lt;/p&gt;
&lt;p&gt;Just as in &lt;a href=&#34;https://danabo.github.io/blog/posts/physical-information/#expectation&#34;&gt;Physical Information#expectation&lt;/a&gt; I considered the narrowing down of a partition to a sub-partition, let&amp;rsquo;s now consider interventions on partitions rather than states. Specifically, replacing the single system-A state $a\up{t}$ (a subset of universe states $\O$) with the state set $\A$ (a partition of $\O$). Then $\A$ varies the state of system A, while also keeping the state of the environment unknown.&lt;/p&gt;
&lt;p&gt;Let $\t_\Dt(\A) = \set{\t_\Dt(a) \mid a\in\A}$ be the time-evolved partition, i.e. the set of all of system A&amp;rsquo;s states time-evolved $\Dt$ into the future. Let&amp;rsquo;s motivate a measure of system A&amp;rsquo;s causal effect on the environment due to this new kind of intervention on partitions. Consider the following cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\t_\Dt(\A) = \cA$. Clearly system A&amp;rsquo;s state at time $t$ fully determines the environment&amp;rsquo;s state at time $t+\Dt$, and so system A&amp;rsquo;s effect on the environment is maximal.&lt;/li&gt;
&lt;li&gt;$\I(\cA, \t_\Dt(\A)) = 0$, i.e. $\cA$ and $\t_\Dt(\A)$ are orthogonal. Clearly system A&amp;rsquo;s state at time $t$ has no determination on the environment&amp;rsquo;s state at time $t+\Dt$, and system A has no effect on the environment.&lt;/li&gt;
&lt;li&gt;For some $a\in\A$, if the sub-partition $\cA\dom{\t_\Dt(a)} = \set{a^\dg\cap \t_\Dt(a) \Mid a^\dg\in\cA}$ contains multiple non-empty members, then that variation in the enviornment&amp;rsquo;s state given a particular state of system A is system A&amp;rsquo;s lack of determination of the environment&amp;rsquo;s state. That &amp;ldquo;lack of determination&amp;rdquo;, i.e. variation, can be quantified using $\H(\cA \mid \t_\Dt(a))$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210523130803.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;The case where $\t_\Dt(\A) = \cA$.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210523130821.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;The case where $\I(\cA, \t_\Dt(\A)) = 0$.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210523130830.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;The case where $\H(\cA \mid \t_\Dt(a)) &amp;gt; 0$, meaning there is some variation to the environment when system A&amp;#39;s state $a$ is held fixed. This is the part of the environment&amp;#39;s total variation $\H(\cA)$ that is not caused by system A.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;It should be becoming clear that&lt;/p&gt;
&lt;p&gt;$$\I(\cA, \t_\Dt(\A))$$&lt;/p&gt;
&lt;p&gt;is quantifying the summary effect of varying system A&amp;rsquo;s state on the environment, and $\H(\cA \mid \t_\Dt(\A))$ the remaining variation in the environment not due to system A, giving the total&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\H(\cA) = \I(\cA, \t_\Dt(\A)) + \H(\cA \mid \t_\Dt(\A))\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This should be surprising, since I previously defined $i(a^\dg, \t_\Dt(a))$ as the information system A has (being in state $a$) about the environment state $a^\dg$ in the future, and $h(a^\dg \mid \t_\Dt(a))$ the effect of varying the &lt;em&gt;environment&lt;/em&gt; on the environment&amp;rsquo;s state. Now, I&amp;rsquo;m saying that the expected PMI, $\I(\cA, \t_\Dt(\A))$, is quantifying the causal effect of system A on the environment.&lt;/p&gt;
&lt;p&gt;This connection can be rigorously arrived at.&lt;br&gt;
Let $R = \t_\Dt(a)$ and $R^\dg = \t_\Dt(a^\dg)$, and $b\subseteq\O$ is some set.&lt;br&gt;
Note that if $a$ and $a^\dg$ are orthogonal and their intersection $a\cap a^\dg = \set{\o}$ is singleton, then the same is true for the time-evolved sets $R$ and $R^\dg$.&lt;/p&gt;
&lt;p&gt;By plugging in $h(b) = i(b, R^\dg) + h(b \mid R^\dg)$ to $h(b) = i(b, R \cap R^\dg) = i(b, R) + i(b, R^\dg) + i(R, R^\dg\mid b)$, we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(b \mid R^\dg) = i(b, R) + i(R, R^\dg\mid b)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Taking the expectation of both sides and replacing $b$ with the state of the environment, we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\H(\cA \mid \t_\Dt(\cA)) = \I(\cA, \t_\Dt(\A)) + \I(\t_\Dt(\A), \t_\Dt(\cA)\mid \cA)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;and all the terms are now guaranteed to be positive. Then we have the inequality,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\H(\cA \mid \t_\Dt(\cA)) \geq \I(\cA, \t_\Dt(\A))\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;with equality when $\I(\t_\Dt(\A), \t_\Dt(\cA)\mid \cA) = 0$.&lt;/p&gt;
&lt;p&gt;We can interpret $\H(\cA \mid \t_\Dt(\cA))$ as the average of $h(a^\dg \mid \t_\Dt(a&#39;^\dg))$ across all $a^\dg, a&#39;^\dg \in \cA$, which is the effect on env. state $a^\dg$ due to varying system A, while keeping the initial env. state fixed at $a&#39;^\dg$. So the average effect of system A on the env., in this sense, is lower bounded by the summary effect, $\I(\cA, \t_\Dt(\A))$, of system A on the environment due to taking the partition $\A$ to be an intervention set (which does not specify that the environment is in any particular state).&lt;/p&gt;
&lt;h1 id=&#34;the-information-effect-cube&#34;&gt;The Information-Effect Cube&lt;/h1&gt;
&lt;p&gt;As before, system A has the state space $\A$ and its environment the partition complement $\cA$. Let $a\in\A$ be any system-A state, and $a^\dg\in\cA$ be any environment state. Let $R = \t_\Dt(a&#39;)$ and $R^\dg = \t_\Dt(a&#39;^\dg)$ be the time-evolved states of system A and its environment.&lt;/p&gt;
&lt;p&gt;$R$ can be regarded as either the information that system A has, $\O\tr R$, or the effect set due to varying the environment (intervention set $a$). Likewise, $R^\dg$ can be regarded as either the information that the environment has, $\O\tr R^\dg$, or the effect set due to varying system A (intervention set $a^\dg$).&lt;/p&gt;
&lt;p&gt;So $i(a, R)$ is the information system A has about its own future state $a$, and $i(a, R^\dg)$ is the information the environment has about system A&amp;rsquo;s future state $a$. Likewise, $h(a \mid R)$ is the effect of the environment on system A&amp;rsquo;s future state $a$, and $h(a \mid R^\dg)$ is the effect of system A on system A&amp;rsquo;s future state $a$.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210523141006.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;The table of all the possible permutations of $i \leftrightarrow h$, $a\leftrightarrow a^\dg$ and $R\leftrightarrow R^\dg$.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;All of these quantities can be visualized together as the corners of a cube:&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210523132219.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
Ever pair of vertices has a corresponding identity linking the two, which can be useful for answering a number of questions about causality and information.&lt;/p&gt;
&lt;p&gt;For example, the more information sys. A has about the env.&amp;rsquo;s future, the less information sys. A has about its own future? We can verify this using the identity $i(a^\dg, R) = h(R) - i(a, R) - i(a, a^\dg \mid R)$, assuming that $a\cap a^\dg \in R$.  If all the other terms are held constant, then $i(a^\dg, R)$ and $i(a, R)$ are inversely related.&lt;/p&gt;
&lt;p&gt;Here are a few more relationships:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$i(a, R) = h(a) - i(a, R^\dg) - i(R, R^\dg \mid a)$, assuming $R \cap R^\dg \subseteq a$.&lt;/li&gt;
&lt;li&gt;$h(a \mid R) = i(a^\dg, R) + i(a, a^\dg\mid R)$&lt;/li&gt;
&lt;li&gt;$h(a \mid R) = i(a, R^\dg) + i(R, R^\dg\mid a)$&lt;/li&gt;
&lt;li&gt;$h(a\mid R) = \e_\o(R) - h(a^\dg\mid R) + i(a,a^\dg\mid R)$ where $\e_\o(R) = h(\set{\o}\mid R) = \lg\mu(R) - \lg\mu\set{\o}$ is the quantity of causal effect of $R$ with $\o$ as the reference unit size,  assuming that $a \cap a^\dg = \set{\o}$ and $\o\in R$.&lt;/li&gt;
&lt;li&gt;$h(a \mid R) = h(a) - h(a \mid R^\dg) - i(R,R^\dg\mid a)$, assuming $R \cap R^\dg \subseteq a$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These can be used to address questions such as,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The more info the env. has about sys. A&amp;rsquo;s future, the more effect the env. has on sys. A&amp;rsquo;s future? Use $h(a \mid R) = i(a, R^\dg) + i(R, R^\dg\mid a)$, where $i(a, R^\dg)$ is the info the env. has about sys. A&amp;rsquo;s state $a$, and $h(a \mid R)$ is the effect of the env. on sys A&amp;rsquo;s state $a$ (remember that $R = \t_\Dt(a&#39;)$ is the effect of the intervention set $a&#39;$ that varies the environment while keeping sys. A fixed).&lt;/li&gt;
&lt;li&gt;The more effect sys. A has on the environment&amp;rsquo;s future, the less effect sys. A has on its own future? Use $h(a^\dg\mid R^\dg) = \e_\o(R^\dg) - h(a\mid R^\dg) + i(a,a^\dg\mid R^\dg)$, where $h(a^\dg\mid R^\dg)$ is the effect of sys. A on env. state $a^\dg$, and $h(a\mid R^\dg)$ is the effect of sys. A on sys. A state $a$.&lt;/li&gt;
&lt;li&gt;The more effect the env. has on sys. A&amp;rsquo;s future, the less effect sys. A has on its own future? Use $h(a \mid R) = h(a) - h(a \mid R^\dg) - i(R,R^\dg\mid a)$, where $h(a \mid R)$ is the effect of the env. on sys. A&amp;rsquo;s state $a$, and $h(a \mid R^\dg)$ is the effect of sys. A on sys. A&amp;rsquo;s state $a$.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;information-about-entails-effect-on&#34;&gt;Information-about entails effect-on&lt;/h2&gt;
&lt;p&gt;Let $a\up{t}\in\A$ be the state of system A, and ${a^\dg}\up{t}\in\cA$ be the state of the environment.&lt;br&gt;
${a^\dg}\up{t} =J$ is also an intervention set varying system A while keeping the environment fixed.&lt;/p&gt;
&lt;p&gt;For any system B with state space $\fB$, we have the identity,&lt;br&gt;
$$&lt;br&gt;
\H(\fB \mid \t_\Dt({a^\dg}\up{t})) = \I(\fB, \t_\Dt(a\up{t})) + \I(\t_\Dt(a\up{t}), \t_\Dt({a^\dg}\up{t}) \mid \fB)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;All of these terms are non-zero. This tells us that the average information system A has about system B&amp;rsquo;s state, $\I(\fB, \t_\Dt(a\up{t}))$, is lower bounded by the average effect of system A on system B, $\H(\fB \mid \t_\Dt({a^\dg}\up{t}))$.&lt;/p&gt;
&lt;p&gt;That is to say, in order for system A to have information about system B&amp;rsquo;s state in the future, system A must effect system B&amp;rsquo;s state in the future. We can infer that the information system A has about system B is exactly whatever system A causally determines in system B&amp;rsquo;s state, minus some potential lost information, $\I(\t_\Dt(a\up{t}), \t_\Dt({a^\dg}\up{t}) \mid \fB)$.&lt;/p&gt;
&lt;p&gt;This is a fairly absurd conclusion, given that everyday life depends greatly on the fact that we can know a lot about the world around us without causally determining much at all about the world. I discuss this a bit further in &lt;a href=&#34;https://danabo.github.io/blog/posts/redundancy-and-copying/#the-problem-of-assumptions-in-intelligence&#34;&gt;Redundancy And Copying#the-problem-of-assumptions-in-intelligence&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;asymmetric-causality&#34;&gt;Asymmetric Causality&lt;/h2&gt;
&lt;p&gt;If system A effects the environment, does the environment effect system A by the same amount?&lt;/p&gt;
&lt;p&gt;If system A has information about the environment, does the environment have the same amount of information about system A?&lt;/p&gt;
&lt;p&gt;These questions can be addressed using&lt;/p&gt;
&lt;p&gt;$$h(a\mid R) = h(a^\dg\mid R^\dg) + i(a,a^\dg\mid R) - i(R,R^\dg\mid a^\dg)$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$i(a^\dg,R) = i(a,R^\dg) - i(a,a^\dg\mid R) + i(R,R^\dg\mid a)\,.$$&lt;/p&gt;
&lt;p&gt;The situation is symmetric iff $i(a,a^\dg\mid R) = i(R,R^\dg\mid a^\dg)$.&lt;/p&gt;
&lt;p&gt;For a simple example where causal effect is asymmetric, consider the discrete system where $\O = \set{0,1}^2$ and one-step time-evolution is defined by the following table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$\o$&lt;/th&gt;
&lt;th&gt;$\t_1(\o)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;01&lt;/td&gt;
&lt;td&gt;01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The first bit is the state of system A, $\A = \set{\set{00, 01}, \set{10, 11}}$, and the second bit is the state of the environment, $\cA = \set{\set{00, 10}, \set{01, 11}}$. Clearly $\t_1(\cA) = \cA$, i.e. the environment&amp;rsquo;s state is always constant through time. But system A&amp;rsquo;s state transition depends on the state of the environment, i.e. varying the state of the environment varies the time-evolution of system A. The environment has an effect on system A, but system A does not have an effect on the environment.&lt;/p&gt;
&lt;p&gt;In physics, we expect there to be symmetry. Newtonian mechanics adds the constraint that any two particles mutually pull on each other, i.e. each exerts a force on the other. I&amp;rsquo;m tempted to say that Newton&amp;rsquo;s third law guarantees that causal interactions are always symmetric, but I have not yet done the math on that.&lt;/p&gt;
&lt;h2 id=&#34;combined-relationships&#34;&gt;Combined Relationships&lt;/h2&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; i(a\cap a^\dg, R\cap R^\dg) \\&lt;br&gt;
&amp;amp;\,\,=\,\,\, i(a,R) + i(a,R^\dg) + i(a^\dg,R) + i(a^\dg,R^\dg) \\&lt;br&gt;
&amp;amp;\quad + i(a,a^\dg\mid R) + i(a,a^\dg \mid R^\dg) + i(R,R^\dg \mid a) + i(R,R^\dg \mid a^\dg) \\&lt;br&gt;
&amp;amp;\quad+ i(a,a^\dg,R,R^\dg)&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $i(a\cap a^\dg, R\cap R^\dg) = h(\set{\o})$ when $a\cap a^\dg = R\cap R^\dg = \set{\o}$, and $-\infty$ otherwise.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; h(a\cap a^\dg\mid R\cap R^\dg) \\&lt;br&gt;
&amp;amp;\,\,=\,\,\,  h(a \mid R) + h(a \mid R^\dg) + h(a^\dg \mid R) + h(a^\dg \mid R^\dg) \\&lt;br&gt;
&amp;amp;\quad - i(a,a^\dg\mid R) - i(a,a^\dg \mid R^\dg) - i(R,R^\dg \mid a) - i(R,R^\dg \mid a^\dg) \\&lt;br&gt;
&amp;amp;\quad - i(a,a^\dg,R,R^\dg) - h(a) - h(a^\dg)&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $h(a\cap a^\dg \mid R\cap R^\dg) = 0$ when $a\cap a^\dg = R\cap R^\dg = \set{\o}$, and $\infty$ otherwise.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Physical Information</title>
      <link>https://danabo.github.io/blog/posts/physical-information/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/physical-information/</guid>
      <description>&lt;p&gt;I will apply to abstract physics the same information algebra I introduced in &lt;a href=&#34;https://danabo.github.io/blog/posts/bayesian-information-theory/#defining-information&#34;&gt;Bayesian information theory#defining-information&lt;/a&gt; and further developed in &lt;a href=&#34;https://danabo.github.io/blog/posts/information-algebra/&#34;&gt;Information Algebra&lt;/a&gt;. &lt;em&gt;Bayesian&lt;/em&gt; information is just information from the perspective of an agent that may have or not have particular information. Below, I will introduce the notion of a physical system having or not having information about itself or other systems (regardless of whether or not it has &lt;em&gt;agenty&lt;/em&gt; attributes), and the same information algebra will apply. The only difference is a shift from the 1st person to 3rd person perspective.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\es}{\emptyset}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\N}{\mb{N}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\H}{\mb{H}}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\Env}{\mf{E}}&lt;br&gt;
\newcommand{\expt}[2]{\mb{E}_{#1}\left[#2\right]}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[1]{_{\mid #1}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Dt}{{\Delta t}}&lt;br&gt;
\newcommand{\tr}{\rightarrowtail}&lt;br&gt;
\newcommand{\tx}{\prec}&lt;br&gt;
\newcommand{\qed}{\ \ \blacksquare}&lt;br&gt;
\newcommand{\c}{\overline}&lt;br&gt;
\newcommand{\A}{\mf{A}}&lt;br&gt;
\newcommand{\cA}{\c{\mf{A}}}&lt;br&gt;
\newcommand{\dg}{\dagger}&lt;br&gt;
\newcommand{\lgfr}[2]{\lg\par{\frac{#1}{#2}}}&lt;br&gt;
\newcommand{\rv}{\boldsymbol}&lt;br&gt;
\require{cancel}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$\newcommand{\sys}[2]{\left[#2\right]_{#1}}$&lt;/p&gt;
&lt;h1 id=&#34;information-preliminaries&#34;&gt;Information Preliminaries&lt;/h1&gt;
&lt;p&gt;For sets $\O$ and $A \subseteq \O$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\O\tr A&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;&lt;em&gt;is&lt;/em&gt; information. This denotes the narrowing down of possibility space $\O$ to possibility space $A$ containing the &lt;em&gt;true&lt;/em&gt; possibility $\o^*\in A$.&lt;/p&gt;
&lt;p&gt;The information $\O\tr A$ implies a domain restriction. For some other set $B \subseteq \O$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
B\dom{A} \df B \cap A&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;is the domain restriction operation on $B$, which makes clear which set is the domain and which set is being restricted.&lt;/p&gt;
&lt;p&gt;Let $\mf{P}$ be a partition of $\O$. Then&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\mf{P}\dom{A} &amp;amp;\df \set{p\dom{A} \mid p\in\mf{P}} \\&lt;br&gt;
&amp;amp;= \set{p\cap A \mid p\in\mf{P}}&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;is the domain restriction of partition $\mf{P}$ to domain $A$, s.t. $\bigcup\mf{P} = A$.&lt;/p&gt;
&lt;h1 id=&#34;information-theory-of-systems&#34;&gt;Information Theory Of Systems&lt;/h1&gt;
&lt;p&gt;I will use the abstraction of physics that I introduced in &lt;a href=&#34;https://danabo.github.io/blog/posts/causality-for-physics/#abstract-physics&#34;&gt;Causality For Physics#abstract-physics&lt;/a&gt;. Let $\O$ be a set of possible states and $\t_\Dt : \O\to\O$, $\Dt\in\R$, be a family of bijective time-evolution functions on $\O$. In general, time-evolution forms the group $(\set{\t_\Dt \mid \Dt\in\R}, \circ)$, where $\t_{\Dt+\Dt&#39;} = \t_\Dt\circ\t_{\Dt&#39;}$ and $\t_{-\Dt}=\t^{-1}_\Dt$, and $\t_0:\o\mapsto\o$ is the identity function.&lt;/p&gt;
&lt;p&gt;I will regard $\O$ as the state-space of an entire universe (i.e. a closed system). The universe may contain any number of systems labeled &amp;ldquo;A&amp;rdquo;, &amp;ldquo;B&amp;rdquo;, &amp;ldquo;C&amp;rdquo;, etc., with respective state-spaces $A, B, C,\dots$, so that $\O\subseteq A\m B\m C\m \dots$ and states are tuples, $\o = (a, b, c, \dots) \in \O$. Then the time-evolution function&lt;/p&gt;
&lt;p&gt;$$\t_\Dt : (a, b, c, \dots) \mapsto \t_\Dt(a, b, c, \dots)$$&lt;/p&gt;
&lt;p&gt;jointly time-evolves all the systems simultaneously, which allows $\t_\Dt$ to incorporate arbitrary interactions between systems. This also means that the time evolution of, say, system A, depends on not just A&amp;rsquo;s state, but the state of all systems, i.e. the universe&amp;rsquo;s state $\o$.&lt;/p&gt;
&lt;p&gt;There is an alternative way to describe systems using partitions. Let $\mf{A}, \mf{B}, \mf{C},\dots$ each be a partition on $\O$. Partition $\mc{A}$ is a representation of system A&amp;rsquo;s state space, partition $\mf{B}$ is a representation of system B&amp;rsquo;s state space, and so on. I&amp;rsquo;ll denote elements of a partition with lowercase letters, e.g. $a\in\mf{A},\ b\in\mf{B},\ c\in\mf{C},\ \dots$&lt;/p&gt;
&lt;p&gt;In the state-space view, $a\in A$ is a featureless element of which universal states $\o$ are composed. In the partition view, on the other hand, $a\in\mf{A}$ is a subset of $\O$, corresponding to all the states of the universe that are indistinguishable to system A, i.e. the set of all universal states $\o\in\O$ for which system A is in the same state $a$. You can think of $\mf{A}$ as the set of equivalence classes for the relation &amp;ldquo;same state from system A&amp;rsquo;s perspective&amp;rdquo;. Let $\sys{\mf{A}}{\o}$ be the equivalence class containing $\o$, i.e. $\sys{\mf{A}}{\o} = a\in\mf{A}$ s.t. $\o\in a$.&lt;/p&gt;
&lt;p&gt;From here on I will treat the states of systems as subsets of $\O$, and the state spaces of systems will be partitions of $\O$.&lt;/p&gt;
&lt;h2 id=&#34;systems-have-information&#34;&gt;Systems Have Information&lt;/h2&gt;
&lt;p&gt;Suppose the universe is in state $\o\up{t}\in\O$ at time $t$. Then system A, with state space $\mf{A}$, is in state $a\up{t} = \sys{\mf{A}}{\o\up{t}}$. From system A&amp;rsquo;s perspective, $a\up{t}$ is the set of states the universe can be in.&lt;/p&gt;
&lt;p&gt;System A has the information $\O \tr a\up{t}$, which reads &amp;ldquo;$\O$ is narrowed down to $a\up{t}$.&amp;rdquo; System A possesses this information in a purely physical sense. System A need not have awareness or understanding that it posses information, or even the capacity for awareness or understanding of anything. Merely as a physical description, I define any system with state space $\mf{A}$ to have the information $\O \tr \sys{\mf{A}}{\o\up{t}}$ at time $t$.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514153113.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
As a corollary, the universe has the information $\O\tr\set{\o\up{t}}$ at time $t$. The universe can be viewed as the &lt;em&gt;supersystem&lt;/em&gt; with state space $\mf{O} = \set{\set{\o} \mid \o\in\O}$, the partition of singletons. In this sense, the universe has total information, corresponding to narrowing down to a single state.&lt;/p&gt;
&lt;p&gt;This definition of what it means for a system to have information will allow us to talk about what information the system has about itself and other systems at various times, as well as the information the system gains or losses about them as time evolves.&lt;/p&gt;
&lt;h2 id=&#34;interactions&#34;&gt;Interactions&lt;/h2&gt;
&lt;p&gt;If $a\up{t}$ is the state of system A at time $t$, then $\t_{\Dt}(a\up{t})$ is NOT the time-evolution of system A&amp;rsquo;s state. A&amp;rsquo;s state at time $t+\Dt$ is $a\up{t+\Dt}=\sys{\mf{A}}{\o\up{t+\Dt}}$ where $\o\up{t+\Dt} = \t_\Dt(\o\up{t})$. If $\t_{\Dt}(a\up{t}) \neq a\up{t+\Dt}$, then system A &lt;strong&gt;interacted&lt;/strong&gt; with another system (or the environment) in the time interval $(t, t+\Dt)$. Note that by necessity, $\o\up{t+\Dt} \in \t_{\Dt}(a\up{t})\cap a\up{t+\Dt}$.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514153146.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
Then what is $\t_{\Dt}(a\up{t})$? At time $t$, system A has information not just about time $t$, but about all other times. Specifically, at time $t$, system A has the information $\O\tr \t_{\Dt}(a\up{t})$ about time $t+\Dt$. It is important to distinguish between the time when a system has information and the time it has information about. So at time $t+\Dt$, system A has information $\O\tr \t_{-\Dt}(a\up{t+\Dt})$ about time $t$.&lt;/p&gt;
&lt;p&gt;If $\t_{\Dt}(a\up{t}) \neq a\up{t+\Dt}$, then system A does not have complete information about its own future state, which is the necessary result of interaction. Furthermore, $\t_{\Dt}(a\up{t}) \neq a\up{t+\Dt} \iff \t_{-\Dt}(a\up{t+\Dt}) \neq a\up{t}$, and so after system A interacted, it has forgotten information about its previous state at time $t$. That is to say, interaction causes a system to lose information about its past.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514153301.png&#34; alt=&#34;&#34;&gt;
&lt;/p&gt;
&lt;h1 id=&#34;conservation-of-information&#34;&gt;Conservation Of Information&lt;/h1&gt;
&lt;p&gt;Recapping &lt;a href=&#34;https://danabo.github.io/blog/posts/information-algebra/&#34;&gt;Information Algebra&lt;/a&gt;, suppose we are given some measure $\mu$ on $\O$. This measure need not be normalized. Then for measureable set $R\subseteq\O$, the quantity of the information $\O\tr R$ is given by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(\O\tr R) = h(R) = \lg\par{\frac{\mu(\O)}{\mu(R)}}\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $h(R)$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Information_content&#34;target=&#34;_blank&#34;&gt;information content&lt;/a&gt; (or pointwise entropy) of $R$, and $h(\O\tr R)$ is my own shorthand notation to make it clear what information is being quantified.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conservation of information&lt;/strong&gt; is the property of any bijective time-evolution, whereby the information $\O\tr \t_\Dt(a\up{t})$ is enough to recover the information $\O\tr a\up{t}$, because $a\up{t} = \t^{-1}_\Dt(\t_\Dt(a\up{t}))$, for all $\Dt\in\R$. That is to say, time-evolution of arbitrary state sets $R\subseteq\O$ does not destroy the information $\O\tr R$ (this is distinct from the time-evolution of systems which, as we saw, can lose information).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conservation of information quantity&lt;/strong&gt; is a property of &lt;strong&gt;measure-preserving&lt;/strong&gt; time-evolution. Let $\mu$ additionally be a $\t_\Dt$-&lt;a href=&#34;https://en.wikipedia.org/wiki/Invariant_measure&#34;target=&#34;_blank&#34;&gt;invariant measure&lt;/a&gt; on $\O$, i.e. $\mu(\t_\Dt^{-1}(A)) = \mu(A)$ for all measurable $A\subseteq \O$ and for all $\Dt\in\R$. Because $\t_\Dt$ is bijective, &lt;a href=&#34;https://encyclopediaofmath.org/wiki/Invariant_measure&#34;target=&#34;_blank&#34;&gt;this is equivalent to&lt;/a&gt; requiring $\mu(\t_\Dt(A)) = \mu(A)$. Then $h(\O\tr a\up{t}) = h(\O\tr \t_\Dt(a\up{t}))$ for all $t, \Dt\in\R$.&lt;/p&gt;
&lt;p&gt;Conservation of information quantity is a stronger property that requires a $\t$-invariant measure in addition to bijective time-evolution. In classical mechanics, &lt;a href=&#34;https://en.wikipedia.org/wiki/Liouville%27s_theorem_%28Hamiltonian%29&#34;target=&#34;_blank&#34;&gt;Liouville&amp;rsquo;s theorem&lt;/a&gt; shows that any Newtonian time-evolution preserves uniform measures on phase space. This result is sometimes referred to as &lt;em&gt;conservation of information&lt;/em&gt; by physicists, who are referring to conservation of information quantity within my nomenclature. For details, see&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://physicstravelguide.com/theorems/liouvilles_theorem&#34;target=&#34;_blank&#34;&gt;Liouville&amp;rsquo;s theorem - physicstravelguide.com&lt;/a&gt; (Davis &amp;amp; Schwichtenberg)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://theoreticalminimum.com/courses/statistical-mechanics/2013/spring/lecture-1&#34;target=&#34;_blank&#34;&gt;Entropy and conservation of information - theoreticalminimum.com&lt;/a&gt; - (Susskind)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://philsci-archive.pitt.edu/15985/1/gibbsliouville.pdf&#34;target=&#34;_blank&#34;&gt;On the Gibbs-Liouville theorem in classical mechanics&lt;/a&gt; (Henriksson)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.11569&#34;target=&#34;_blank&#34;&gt;Hamiltonian mechanics is conservation of information entropy&lt;/a&gt; (Carcassi &amp;amp; Aidala)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;information-about-systems&#34;&gt;Information About Systems&lt;/h1&gt;
&lt;p&gt;Suppose there are at least two systems, A and B, with respective state spaces $\mf{A}$ and $\mf{B}$. Let system A be in state $a\up{t}$ at time $t$. System A (at $t$) has the information $\O\tr \t_{\Dt}(a\up{t})$ about time $t+\Dt$. What information does A have about B&amp;rsquo;s state at time $t+\Dt$?&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://danabo.github.io/blog/posts/information-algebra/#mutual-information&#34;&gt;Information Algebra#mutual-information&lt;/a&gt;, I showed that pointwise mutual information (PMI) quantifies &amp;ldquo;information about&amp;rdquo;. Specifically,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
i(a\up{t}, b) = i(b, a\up{t}) = \lg\par{\frac{\mu(a\up{t}\cap b)\mu(\O)}{\mu(a\up{t})\mu(b)}}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;quantifies how much information system A, being in state $a\up{t}$, has about whether system B is in state $b\in\mf{B}$ at time $t$.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514153829.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
If $i(a\up{t}, b) = 0$, then $a\up{t}$ and $b$ are &lt;strong&gt;orthogonal&lt;/strong&gt; states. State spaces $\mf{A}$ and $\mf{B}$ are called orthogonal iff $i(a,b) = 0$ for all $a\in\mf{A}$ and $b\in\mf{B}$. Usually, systems are defined to be orthogonal, meaning that the state of one system can be chosen totally independently of the state of the other. Non-orthogonal systems have information about each other &lt;em&gt;by construction&lt;/em&gt;, regardless of their mutual time-evolution. On the other hand, orthogonal systems always have zero information about each other at the present moment. That is to say, $i(a\up{t}, b) = 0$ for all $\mf{B}$, i.e. system A has no information about the state of system B at time $t$. However, system A may have information about system B&amp;rsquo;s past or future state.&lt;/p&gt;
&lt;p&gt;$\O\tr \t_\Dt(a\up{t})$ is the information system A has &lt;em&gt;at time $t$&lt;/em&gt; about time $t+\Dt$. Then it follows that $i(\t_\Dt(a\up{t}), b)$ is the quantity of information system A has, &lt;em&gt;at time $t$&lt;/em&gt;, about whether system B is in state $b$ &lt;em&gt;at time $t+\Dt$&lt;/em&gt;. If $\t_\Dt(a\up{t}) \in b$, then $i(\t_\Dt(a\up{t}), b) = h(b) = h(\O\tr b)$ and system A (at time $t$) has certainty that system B is in state $b$ at time $t+\Dt$. On the other hand, if $b \in \t_\Dt(a\up{t})$, then $i(\t_\Dt(a\up{t}), b) = h(\t_\Dt(a\up{t})) = h(\O\tr \t_\Dt(a\up{t}))$ which is just the total quantity of information that system A has about time $t+\Dt$.&lt;/p&gt;
&lt;p&gt;To fully lay out what information system A has (at time $t$) about system B&amp;rsquo;s state at time $t+\Dt$, we need to look at all the quantities of information A has about every state $b\in\mf{B}$, which can be given as the vector&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\vtup{i(\t_\Dt(a\up{t}), b) \mid b\in\mf{B}}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Note that $i(\t_\Dt(a\up{t}), b)$ can be negative (and has no lower bound), which means that system A has needs more quantity of information than $h(\O\tr b)$ to have certainty that system B is in state $b$. If system A has information that rules out state $b$ with certainty, i.e. $b\cap \t_\Dt(a\up{t}) = \es$, then $i(\t_\Dt(a\up{t}), b) = -\infty$. &lt;a href=&#34;https://danabo.github.io/blog/posts/information-algebra/#mutual-information&#34;&gt;Information Algebra#mutual-information&lt;/a&gt; goes into further detail about the interpretation of PMI quantities.&lt;/p&gt;
&lt;h2 id=&#34;information-gain&#34;&gt;Information Gain&lt;/h2&gt;
&lt;p&gt;The difference&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
i(\t_{t&#39;-t-\Dt}(a\up{t+\Dt}), b) - i(\t_{t&#39;-t}(a\up{t}), b)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;is &lt;strong&gt;information gain&lt;/strong&gt;, i.e. the information system A gained (or lost if negative) about whether system B is in state $b$ at time $t&#39;$ due to the time-evolution of system A&amp;rsquo;s state over the time interval $(t,t+\Dt)$.&lt;/p&gt;
&lt;p&gt;Likewise, $i(\t_{t&#39;-t-\Dt}(a\up{t+\Dt}), a) - i(\t_{t&#39;-t}(a\up{t}), a)$ is system A&amp;rsquo;s information gain (or loss) about itself, specifically whether it is in state $a$ at time $t&#39;$.&lt;/p&gt;
&lt;h1 id=&#34;sum-conservation-laws&#34;&gt;Sum-Conservation Laws&lt;/h1&gt;
&lt;p&gt;Let $\O\tr R$ be the information some unspecified system at some unspecified time has about some other time. Then that system has the quantity of information $h(\O\tr R)$.&lt;/p&gt;
&lt;p&gt;Let $b\in\mf{B}$ be a possible state of system B. Suppose $i(b, R) &amp;lt; h(\O\tr R)$. Then you might ask, &amp;ldquo;where did the remaining information go?&amp;rdquo; That is to say, does it make sense to think that the complete quantity of information $h(\O\tr R)$ should be divided among information about various things? Could we then have the information about everything add up to $h(\O\tr R)$, analogous to how conservation of mass and energy in physics results in reactions or interactions s.t. the energies and masses of the outputs add up to the input energy and mass?&lt;/p&gt;
&lt;p&gt;Information does not quite work like this. For instance, the sum of the vector $\vtup{i(\t_\Dt(a\up{t}), b) \mid b\in\mf{B}}$ need not be $h(R)$. This is evident when you consider that it&amp;rsquo;s possible for the system with information $\O\tr R$ to have the information quantity $h(R)$ about $b\in\mf{B}$ and about $b&#39;\in\mf{B}$, if both $b$ and $b&#39;$ are contained within $R$. Then at least two entries in the vector are each $h(R)$. Furthermore, entries can be arbitrarily negative, and even $-\infty$ as we saw above.&lt;/p&gt;
&lt;p&gt;I have found two ways to achieve something like a sum-conservation law for information quantity. One way uses pointwise quantities, and the other way uses expected quantities, i.e. entropy and mutual information.&lt;/p&gt;
&lt;h2 id=&#34;pointwise&#34;&gt;Pointwise&lt;/h2&gt;
&lt;p&gt;Suppose $i(b, R) &amp;lt; h(\O\tr R)$. If we &amp;ldquo;shrank&amp;rdquo; $b$ down by intersecting with some other set $c$ such that $b \cap c \subseteq R$, then we&amp;rsquo;d have  $i(b\cap c, R) = h(\O\tr R)$. Writing $i(b\cap c, R)$ as a sum involving $i(b, R)$ gives us a sum-conservation law:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
i(b \cap c, R) &amp;amp;= i(b, R) + i(c, R) - i(b, c, R) \\&lt;br&gt;
&amp;amp;= i(b, R) + i(c, R) - i(b, c) + i(b, c \mid R) \\&lt;br&gt;
&amp;amp;= h(\O\tr R)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This is easy to check using the definition of PMI and $i(b, c, R)\df i(b, c) - i(b, c \mid R)$, and&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
i(b, c \mid R) \df \lg\par{\frac{\mu(b\cap c\cap R)\mu(R)}{\mu(b\cap R)\mu(c \cap R)}}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;If $c$ is chosen such that $b$ and $c$ are orthogonal, i.e. $i(b,c)=0$, and plugging in $h(\O\tr R)$ for $i(b \cap c, R)$, then we have the simpler form&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(\O\tr R) = i(b, R) + i(c, R) + i(b, c \mid R)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which does not involve the information quantity $i(b,c)$ due to redundancy between the choice of $b$ and $c$.&lt;/p&gt;
&lt;p&gt;Note that the &amp;ldquo;$i$&amp;rdquo; quantities may be negative, but $h(\O\tr R)$ is always positive. Thus at least one of these terms is positive.&lt;/p&gt;
&lt;p&gt;It is possible for the information $\O\tr R$ to not contain information (or contain negative information) about $b$ or $c$. Then all of the positive information quantity goes into the term $i(b, c \mid R)$, which can be thought of as the quantity of information $\O\tr b$ has about whether $c$ is the case, given the smaller state space $R$.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514153229.png&#34; alt=&#34;&#34;&gt;
&lt;/p&gt;
&lt;h3 id=&#34;information-about-more-than-two-sets&#34;&gt;Information about more than two sets&lt;/h3&gt;
&lt;p&gt;Suppose $i(b\cap c, R) &amp;lt; h(\O\tr R)$. We can repeat the process above again by choosing a third set $a$ s.t. $i(a\cap b\cap c, R) = h(\O\tr R)$. In general, there is an $n$-way relationship.&lt;/p&gt;
&lt;p&gt;Let $x_1,\dots,x_n,R \subseteq \O$ be arbitrary sets. Then,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
i(x_1\cap\dots\cap x_n,R) = i(x_1\cap\dots\cap x_{n-1},R) + i(x_n, R \mid x_1\cap\dots\cap x_{n-1})\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Using the identity&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; i(y_{n-k+1}, \dots, y_n, R \mid y_1\cap\dots\cap y_{n-k}) \\&lt;br&gt;
&amp;amp;\quad\,\, = \,\,i(y_{n-k+1}, \dots, y_n, R \mid y_1\cap\dots\cap y_{n-k-1}) \\&lt;br&gt;
&amp;amp;\qquad\quad- i(y_{n-k}, \dots, y_n, R \mid y_1\cap\dots\cap y_{n-k-1})&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;we can recursively expanding out these terms to produce an expression for $i(x_1\cap\dots\cap x_n,R)$ entirely composed of non-conditional multi-way PMI terms of the form $i(y_1, \dots, y_n)$.&lt;/p&gt;
&lt;p&gt;So for example, expanding out $i(x_n, R \mid x_1\cap\dots\cap x_{n-1})$ with $k=1$, we have&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; i(x_n, R \mid x_1\cap\dots\cap x_{n-1}) \\&lt;br&gt;
&amp;amp;\quad=\,\, i(x_n, R \mid x_1\cap\dots\cap x_{n-2}) \\&lt;br&gt;
&amp;amp;\qquad\,\,- i(x_{n-1}, x_n, R \mid x_1\cap\dots\cap x_{n-2})\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Then further expanding out the resulting terms, using $y_1, \dots, y_{n&#39;} = x_1, \dots, x_{n-2}, x_n$ and $k=1$, we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; i(x_n, R \mid x_1\cap\dots\cap x_{n-2})\\&lt;br&gt;
&amp;amp;\quad=\,\, i(x_n, R \mid x_1\cap\dots\cap x_{n-3}) \\&lt;br&gt;
&amp;amp;\qquad\,\,- i(x_{n-2}, x_n, R \mid x_1\cap\dots\cap x_{n-3})\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;and using $y_1, \dots, y_n = x_1, \dots, x_n$ and $k=2$, we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; i(x_{n-1}, x_n, R \mid x_1\cap\dots\cap x_{n-2}) \\&lt;br&gt;
&amp;amp;\quad=\,\, i(x_{n-1}, x_n, R \mid x_1\cap\dots\cap x_{n-3}) \\&lt;br&gt;
&amp;amp;\qquad\,\,- i(x_{n-2}, x_{n-1}, x_n, R \mid x_1\cap\dots\cap x_{n-3})\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Repeat this process of expanding out these terms until all conditional arguments are gone.&lt;/p&gt;
&lt;p&gt;Multi-way PMI terms can then be converted into 2-way PMI terms using the definition $i(y_1, \dots, y_n) \df i(y_1, \dots, y_{n-1}) - i(y_1, \dots, y_{n-1}\mid y_n)$.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;For case of three sets $a,b,c$, we have&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; i(a\cap b\cap c,R) \\&lt;br&gt;
&amp;amp;\quad\,=\, i(a, R) + i(b, R) + i(c, R) \\&lt;br&gt;
&amp;amp;\qquad\,\,- i(a, b, R) - i(a, c, R) - i(b, c, R) \\&lt;br&gt;
&amp;amp;\qquad\,\,+ i(a,b,c,R)&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
i(a,b,c,R) &amp;amp;= i(a,b,c) - i(a,b,c\mid R)\\&lt;br&gt;
&amp;amp;= i(a,b) - i(a,b \mid c) - i(a,b \mid R) + i(a,b \mid c\cap R)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;If $a,b,c$ are all mutually orthogonal, i.e. $i(a,b) = i(a,c) = i(b,c) = i(a,b,c) = 0$, then&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; i(a\cap b\cap c,R) \\&lt;br&gt;
&amp;amp;\quad\,=\, i(a, R) + i(b, R) + i(c, R) \\&lt;br&gt;
&amp;amp;\qquad\,\,+ i(a,b \mid R) + i(b,c \mid R) + i(a,b \mid c\cap R)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;h2 id=&#34;expectation&#34;&gt;Expectation&lt;/h2&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210518175356.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
It would be nice if there was a single quantity describing $\mf{B}\tr\mf{B}\dom{R}$, the narrowing down of partition $\mf{B}$ to domain $R$, analogous to $h(\O\tr R)$ for individual sets. I will motivate such a quantity from a few special cases.&lt;/p&gt;
&lt;p&gt;If $P\subseteq 2^\O$ is some set of sets, then let $\mu(P) = \mu(\bigcup P)$. Then for partition $\mf{B}$ of $\O$, we have $\mu(\mf{B}) = \mu(\bigcup\mf{B}) = \mu(\O)$. Let&amp;rsquo;s define the quantity $h(\mf{B}\tr \mf{B}\dom{R})$ on a few special cases.&lt;/p&gt;
&lt;p&gt;Consider $\mf{B}\tr \set{b}$ for some $b\in\mf{B}$.&lt;br&gt;


  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514154831.png&#34; alt=&#34;&#34;&gt;
&lt;/p&gt;
&lt;p&gt;Let&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(\mf{B}\tr \set{b}) &amp;amp;= \lg\par{\frac{\mu(\mf{B})}{\mu\set{b}}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(\O)}{\mu(b)}} \\&lt;br&gt;
&amp;amp;= h(\O\tr b)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Then the quantity of information due to narrowing down the partition $\mf{B}$ to one of its elements $b$ is equal to the quantity of information due to narrowing down the possibility space $\O$ to $b$.&lt;/p&gt;
&lt;p&gt;In general, let $\mf{B}&#39; \subseteq \mf{B}$. Then&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(\mf{B}\tr \mf{B}&#39;) &amp;amp;= \lg\par{\frac{\mu(\mf{B})}{\mu(\mf{B}&#39;)}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(\O)}{\mu(\bigcup \mf{B}&#39;)}} \\&lt;br&gt;
&amp;amp;= h\par{\O\tr \bigcup \mf{B}&#39;}\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514154938.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
One more special case: suppose $\mf{B}$ and $\mf{B}\dom{R}$ are &lt;strong&gt;uniform&lt;/strong&gt;, meaning that $\mu(b) = \mu(b&#39;)$ or $0$ for all $b,b&#39;\in\mf{B}$, and likewise for $\mf{B}\dom{R}$ (which may contain the empty set).&lt;/p&gt;
&lt;p&gt;Then&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(\mf{B}\tr \mf{B}\dom{R}) &amp;amp;= h(\O\tr b) - h(R \tr b\cap R)\\&lt;br&gt;
&amp;amp;= h(\O\tr R) - h(b \tr b\cap R)\\&lt;br&gt;
&amp;amp;= i(b, \bigcup \mf{B}\dom{R}) \\&lt;br&gt;
&amp;amp;= i(b, R)&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;for some $b\in\mf{B}$ s.t. $b\cap R \neq \es$. If $R$ reduces each $b\in\mf{B}$ by the same amount, then $i(b, R) = 0$ for all $b\in\mf{B}$ (i.e. $R$ and $b$ are orthogonal), and so $h(\mf{B}\tr \mf{B}\dom{R}) = 0$, indicating that $\O\tr R$ contains no information about the partition $\mf{B}$.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514155029.png&#34; alt=&#34;&#34;&gt;


  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514155002.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
Let $\hat{\mf{B}}\dom{R} = \set{b\in\mf{B} \mid b\cap R \neq \es}$ be the subset of $\mf{B}$ containing elements that have non-zero intersection with $R$. We&amp;rsquo;d like $h(\mf{B}\tr \mf{B}\dom{R}) = h(\mf{B}\tr \hat{\mf{B}}\dom{R}) = \lg\par{\frac{\mu(\mf{B})}{\mu(\hat{\mf{B}}\dom{R})}}$. Notice that $\mu(b)/\mu(\bigcup\hat{\mf{B}}\dom{R}) = \mu(b\cap R)/\mu(R)$, which gives us&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mu(\bigcup\hat{\mf{B}}\dom{R}) = \mu(b)\frac{\mu(R)}{\mu(b\cap R)}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Plugging in, we get $\lg\par{\frac{\mu(\mf{B})}{\mu(\hat{\mf{B}}\dom{R})}} = \lg\par{\frac{\mu(\O)}{\mu(b)\frac{\mu(R)}{\mu(b\cap R)}}} = i(b, R)$.&lt;/p&gt;
&lt;h3 id=&#34;mutual-information&#34;&gt;Mutual Information&lt;/h3&gt;
&lt;p&gt;In the more general case $\mf{B}$ and $\mf{B}\dom{R}$ are not uniform partitions. We will need some kind of averaging operation over $i(b,R)$ for $b\in\mf{B}$ that reduces to our special cases above, and zeros out all the $i(b,R) = -\infty$ terms where $b\cap R = \es$. Taking the expectation w.r.t. $\mu(\cdot \mid R)$ fulfills both requirements.&lt;/p&gt;
&lt;p&gt;Let&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\expt{x\in\mf{X}}{f(x)} = \frac{1}{\mu(\bigcup\mf{X})} \sum_{x\in\mf{X}} \mu(x)\,f(b)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;for discrete $\mf{X}$ and&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\expt{x\in\mf{X}}{f(x)} = \frac{1}{\mu(\bigcup\mf{X})}\int_{x\in\mf{X}} \rho(x)\,f(b)\,\mathrm{d}x&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;for continuous $\mf{X}$, where $\rho$ is the density function for measure $\mu$. These quantities are normalized by $\mu(\bigcup\mf{X})$ where $\bigcup\mf{X}$ is the domain of the partition $\mf{X}$.&lt;/p&gt;
&lt;p&gt;Define the mutual information between partitions $\mf{A}$ and $\mf{B}$ as&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{A}, \mf{B}) \df \expt{a\in\mf{A},b\in\mf{B}}{i(a,b)}\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;as well as the conditional mutual information&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{A}, \mf{B} \mid R) \df \expt{a\dom{R}\in\mf{A}\dom{R},b\dom{R}\in\mf{B}\dom{R}}{i(a,b\mid R)}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Define the mutual information between partition $\mf{B}$ and set $R$ as&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{B}, R) \df \expt{b\dom{R}\in\mf{B}\dom{R}}{i(b,R)}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;In the discrete case,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{B}, R) = \sum_{b\in\mf{B}} \frac{\mu(b\cap R)}{\mu(R)}i(b,R)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;In general, define the quantity of information that $\O\tr R$ contains about which element of partition $\mf{B}$ is the state of system B:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(\mf{B}\tr \mf{B}\dom{R}) \df \I(\mf{B}, R)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Let $\mf{C}$ be the state space of some other system C. Taking the expectation of the pointwise sum-conservation law from above, we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\I(\mf{B}\otimes\mf{C}, R) &amp;amp;= \I(\mf{B}, R) + \I(\mf{C}, R) - \I(\mf{B}, \mf{C}, R) \\&lt;br&gt;
&amp;amp;= \I(\mf{B}, R) + \I(\mf{C}, R) - \I(\mf{B}, \mf{C}) + \I(\mf{B}, \mf{C} \mid R)\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mf{B}\otimes\mf{C}\df \set{b\cap c \mid b\in\mf{B} \and c\in\mf{C}}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;is the &lt;strong&gt;partition product&lt;/strong&gt; of $\mf{B}$ and $\mf{C}$, i.e. the intersection of all pairs of elements of $\mf{B}$ and $\mf{C}$.&lt;/p&gt;
&lt;p&gt;While $\I(\mf{B}, R)$ and $\I(\mf{C}, R)$ are always non-negative (2-way mutual information is always non-negative), the 3-way mutual information $\I(\mf{B}, \mf{C}, R)$ can be negative. If $\mf{B}$ and $\mf{C}$ are orthogonal, i.e. $\I(\mf{B}, \mf{C}) = 0$, then&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{B}\otimes\mf{C}, R) = \I(\mf{B}, R) + \I(\mf{C}, R) + \I(\mf{B}, \mf{C} \mid R)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which is a decomposition of $\I(\mf{B}\otimes\mf{C}, R)$ into non-negative terms. This looks more like the sum-conservation laws we have for mass and energy (sum of non-negative terms is conserved).&lt;/p&gt;
&lt;h3 id=&#34;environments&#34;&gt;Environments&lt;/h3&gt;
&lt;p&gt;Let $\mf{B}$ be some state space. A &lt;strong&gt;partition complement&lt;/strong&gt; of $\mf{B}$, denoted $\c{\mf{B}}$, satisfies the following properties:&lt;/p&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;$\c{\mf{B}}$ is a partition of $\O$.&lt;/li&gt;
&lt;li&gt;$\I(\mf{B}, \c{\mf{B}}) = 0$,&lt;/li&gt;
&lt;li&gt;$\mf{B}\otimes\c{\mf{B}} = \mf{O} = \set{\set{\o}\mid\o\in\O}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In general, $\mf{B}$ does not have a unique complement, and may not have any complement. For example, if $\O = \set{\o_1, \o_2, \o_3}$ and $\mf{B} = \set{\set{\o_1, \o_2}, \set{\o_3}}$, then it is easy to check that $\mf{B}$ has no complement.&lt;/p&gt;
&lt;p&gt;If each element of $\mf{B}$ is infinite, then $\mf{B}$ always has a complement. If each element of $\mf{B}$ is finite, then it has a complement if each element has the same cardinality.&lt;/p&gt;
&lt;p&gt;We can regard a complement $\c{\mf{B}}$ as the &lt;strong&gt;environment&lt;/strong&gt; of system B, which is everything in the universe outside of system B.&lt;/p&gt;
&lt;p&gt;Assuming $\mf{B}$ has a complement $\c{\mf{B}}$, then the sum-conservation law from above is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{B}\otimes\c{\mf{B}}, R) = \I(\mf{B}, R) + \I(\c{\mf{B}}, R) + \I(\mf{B}, \c{\mf{B}} \mid R)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;A useful identity here is that $\I(\mf{O}, R) = h(\O\tr R)$. Since $\mf{B}\otimes\c{\mf{B}} = \mf{O}$, then we have&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(\O\tr R) = \I(\mf{B}, R) + \I(\c{\mf{B}}, R) + \I(\mf{B}, \c{\mf{B}} \mid R)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Proof&lt;/strong&gt;&lt;/em&gt; that $\I(\mf{O}, R) = h(\O\tr R)$.&lt;/p&gt;
&lt;p&gt;Let $\mf{X}$ be a partition of $\O$ s.t. for each $x\in\mf{X}$, either $x\cap R = \es$ or $x$. That is to say, there is some subset $Y \subseteq \mf{X}$ s.t. $R = \bigcup Y$. Then $Y = \mf{X}\dom{R}$.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\I(\mf{X}, R) &amp;amp;= \sum_{x\in\mf{X}} \mu(x \mid R) \lg\par{\frac{\mu(x\cap R)\mu(\O)}{\mu(x)\mu(R)}} \\&lt;br&gt;
&amp;amp;= \sum_{x\in \mf{X}\dom{R}} \mu(x \mid R) \lg\par{\frac{\cancel{\mu(x)}\mu(\O)}{\cancel{\mu(x)}\mu(R)}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(\O)}{\mu(R)}} \\&lt;br&gt;
&amp;amp;= h(\O\tr R)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Since $\mf{O}$ is the singleton partition, it satisfies the condition above for all $R\subseteq \O$. Thus $\I(\mf{O}, R) = h(\O\tr R)$. $\qed$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Combining conservation of information quantity,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(\O\tr R) = h(\O\tr \t_\Dt(R))\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;with the sum-conservation law,  we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; \I(\mf{B}, R) + \I(\c{\mf{B}}, R) + \I(\mf{B}, \c{\mf{B}} \mid R) \\&lt;br&gt;
=\,\, &amp;amp; \I(\mf{B}, \t_\Dt(R)) + \I(\c{\mf{B}}, \t_\Dt(R)) + \I(\mf{B}, \c{\mf{B}} \mid \t_\Dt(R))\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Consider system A with state space $\A$, and its environment with state space $\cA$. At time $t$, system A is in state $a\up{t}\in\mf{A}$ and has the information $\O\tr a\up{t}$ about time $t$. Since $\I(\A, a\up{t}) = h(\O\tr a\up{t})$, then $\I(\cA, a\up{t}) + \I(\A, \cA \mid a\up{t}) = 0$.&lt;/p&gt;
&lt;p&gt;Then our conservation law reduces to&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\I(\A, a\up{t}) &amp;amp;= \I(\A, \t_\Dt(a\up{t})) + \I(\cA, \t_\Dt(a\up{t})) + \I(\A, \cA \mid \t_\Dt(a\up{t})) \\&lt;br&gt;
&amp;amp;= h(\O\tr a\up{t}) \,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;If $\I(\A, \t_\Dt(a\up{t})) = h(\O\tr \t_\Dt(a\up{t})) = h(\O\tr a\up{t})$, then $\I(\cA, \t_\Dt(a\up{t})) + \I(\A, \cA \mid \t_\Dt(a\up{t})) = 0$ and system A (at time $t$) has no information about the environment at time $t+\Dt$. Since all the terms are positive, for system A to have information about the future environment, system A must have less than complete information about its own future state.&lt;/p&gt;
&lt;p&gt;A tricky case to be aware of is when $\I(\A, \t_\Dt(a\up{t})) = 0$ and $\I(\cA, \t_\Dt(a\up{t})) = 0$. This would seem to be saying that system A has no information about its own future state and the environment&amp;rsquo;s future state. It would then seem that the information quantity $h(\O\tr a\up{t})$ simply disappeared and was not conserved. That quantity went into the third term, $\I(\A, \cA \mid \t_\Dt(a\up{t})) = h(\O\tr a\up{t})$, which indicates that system A becomes highly correlated with its environment in the future.&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514160217.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;$R=a\in\A$. Then $\I(\A,R) = h(\O\tr R)$ and $\I(\cA,R) = 0$, $\I(\A,\cA \mid R) = 0$.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514160232.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;$R=a^\dg\in\cA$. Then $\I(\cA,R) = h(\O\tr R)$ and $\I(\A,R) = 0$, $\I(\A,\cA \mid R) = 0$.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514160247.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;$\I(\A,R)$ and $\I(\cA,R)$ are both non-zero, and $\I(\A,\cA \mid R) = 0$, meaning $\A$ and $\cA$ are still orthogonal when restricted to the domain $R$.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;br&gt;


  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210514160256.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;$\I(\A,R) = 0$ and $\I(\cA,R) = 0$, since restricting either partition to the domain $R$ still tells you nothing about the other partition. However, $\I(\A,\cA \mid R) = h(\O\tr R)$, meaning $\A$ and $\cA$ restricted to the domain $R$ are maximally redundant, i.e. given $R$ and some $a\in\mf{A}$, you can uniquely determine $a^\dg\in\mf{A}$, and vice versa.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;general-case&#34;&gt;General Case&lt;/h4&gt;
&lt;p&gt;For arbitrary systems with state spaces $\A$ and $\mf{B}$, we have&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\A\otimes\mf{B}, R) = \I(\A, R) + \I(\mf{B}, R) + \I(\A, \mf{B} \mid R) - \I(\A, \mf{B})&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Using the identity $\I(\A\otimes\mf{B}, R) = h(R) - \H(R \mid \A\otimes\mf{B})$, where $h(R) = h(\O\tr R)$ and&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\H(R \mid \A\otimes\mf{B}) &amp;amp;= \expt{z\dom{R} \in (\A\otimes\mf{B})\dom{R}}{h(R \mid z)} \\&lt;br&gt;
&amp;amp;= \sum_{z \in \A\otimes\mf{B}} \frac{\mu(z\cap R)}{\mu(R)}\lgfr{\mu(z)}{\mu(R \cap z)}\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;(for discrete $\A\otimes\mf{B}$)&lt;/p&gt;
&lt;p&gt;we can write the above identity in terms of $h(R)$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(R) = \H(R \mid \A\otimes\mf{B}) + \I(\A, R) + \I(\mf{B}, R) + \I(\A, \mf{B} \mid R) - \I(\A, \mf{B})\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;When all $z \in \A\otimes\mf{B}$ are either contained in $R$ or outside of $R$ (i.e. $z \cap R = \es$ or $R$), then $\H(R \mid \A\otimes\mf{B}) = 0$.&lt;/p&gt;
&lt;p&gt;When $\A$ and $\mf{B}$ are orthogonal, then $\I(\A, \mf{B}) = 0$.&lt;/p&gt;
&lt;h2 id=&#34;shannon-quantities&#34;&gt;Shannon Quantities&lt;/h2&gt;
&lt;p&gt;It is helpful to connect this all back to the standard language of information theory. Let $\rv{A}, \rv{B}, \rv{C}$ be random variables with joint distribution $p(\rv{A}, \rv{B}, \rv{C})$.&lt;/p&gt;
&lt;p&gt;Mutual information is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
I(\rv{A}, \rv{B}) = \expt{a,b\sim p(\rv{A},\rv{B})}{\lgfr{p(a, b)}{p(a)p(b)}}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;What are less obvious are the Shannon analogs to $\I(\mf{A}, R)$ and $\I(\mf{A}\otimes\mf{B}, R)$.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll define the non-standard Shannon quantity:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
I(\rv{A}, \rv{B} = b) \df \expt{a\sim p(\rv{A} \mid \rv{B}=b)}{\lgfr{p(a, b)}{p(a)p(b)}}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This is not quite a conditional quantity like $H(\rv{A} \mid \rv{B} = b)$, because the contents of the expectation are not a pointwise conditional quantity (like $h(a \mid b)$). Then $I(\rv{A}, \rv{B} = b)$ is really its own thing. It is the expectation of non-conditional pointwise mutual information $i(a,b)$, but over a conditional probability distribution. Then (for $b\in\mf{B}$ on the lhs) we have the analog&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{A}, b) \iff I(\rv{A}, \rv{B} = b)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Next we have the partition product, $\mf{A}\otimes\mf{B}$. As a random variable, this is just the random tuple $\rv{T_{A,B}} = (\rv{A}, \rv{B})$. The random variable $\rv{T_{A,B}}$ is just the combined outcome of both random variables $\rv{A}$ and $\rv{B}$. We must distinguish between&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
I((\rv{A}, \rv{B}), \rv{C}) &amp;amp;= \expt{a,b,c\sim p(\rv{A},\rv{B},\rv{C})}{\lgfr{p(a, b, c)}{p(a,b)p(c)}} \\&lt;br&gt;
&amp;amp;= \expt{t,c\sim p(\rv{T_{A,B}},\rv{C})}{\lgfr{p(t, c)}{p(t)p(c)}} \\&lt;br&gt;
&amp;amp;= I(\rv{T_{A,B}}, \rv{C})&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;and the 3-way mutual information&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
I(\rv{A}, \rv{B}, \rv{C}) = I(\rv{A}, \rv{B}) - I(\rv{A}, \rv{B} \mid \rv{C})\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Then we have the analogs (for $c\in\mf{C}$)&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{A}\otimes\mf{B}, c) \iff I((\rv{A}, \rv{B}), \rv{C}=c)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(\mf{A}, \mf{B}, c) \iff I(\rv{A}, \rv{B}, \rv{C}=c)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;We also have the same decompositions on these Shannon quantities:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
I((\rv{A}, \rv{B}), \rv{C}) = I(\rv{A}, \rv{C}) + I(\rv{B}, \rv{C}) - I(\rv{A}, \rv{B}, \rv{C})&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
I((\rv{A}, \rv{B}), \rv{C}=c) = I(\rv{A}, \rv{C}=c) + I(\rv{B}, \rv{C}=c) - I(\rv{A}, \rv{B}, \rv{C}=c)\,.&lt;br&gt;
$$&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Information Algebra</title>
      <link>https://danabo.github.io/blog/posts/information-algebra/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/information-algebra/</guid>
      <description>&lt;p&gt;I further expand on the ideas I introduced in &lt;a href=&#34;https://danabo.github.io/blog/posts/bayesian-information-theory/&#34;&gt;Bayesian information theory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\es}{\emptyset}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\E}{\mb{E}}&lt;br&gt;
\newcommand{\N}{\mb{N}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\H}{\mb{H}}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[1]{_{|#1}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Dt}{{\Delta t}}&lt;br&gt;
\newcommand{\Dh}{{\Delta h}}&lt;br&gt;
\newcommand{\tr}{\rightarrowtail}&lt;br&gt;
\newcommand{\tra}[2]{\,^{#1\!\!}\searrow _{#2\,}}&lt;br&gt;
\newcommand{\mi}[4]{\,^{#1\!\!}\searrow _{#2\,}\rightrightarrows ^{#3}\searrow _{#4\,}}&lt;br&gt;
\newcommand{\absp}[1]{\abs{#1}^+}&lt;br&gt;
\newcommand{\Bar}{\overline}&lt;br&gt;
\newcommand{\dmid}{\,\|\,}&lt;br&gt;
\newcommand{\V}[1]{\begin{pmatrix}#1\end{pmatrix}}&lt;br&gt;
\require{cancel}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;We have a set of possibilities $\O$, and there is a &lt;em&gt;true&lt;/em&gt; but unknown possibility $\o^*\in\O$. I define information as a tuple of the form $(\O,R)$ where $R\subseteq \O$, which asserts that $\o^*\in R$. I notate these information tuples with arrows:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\O\tr R \df (\O, R)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which makes it clear that information is the &lt;em&gt;narrowing-down&lt;/em&gt; of a possibility space.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505092619.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505092619.png&#34; width=&#34;600&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;br&gt;
I also use the following notation for &lt;strong&gt;domain restriction&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
A\dom{B} \df A \cap B\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which is the set $A$ restricted to the domain of $B$. This notation is more compact than intersection notation, and I can use it to emphasize the semantic distinction between which set is being restricted and which set is the domain.&lt;/p&gt;
&lt;p&gt;To quantify information, we need a measure $\mu$ on $\O$. When $\O$ is finite, I always use the counting measure $\mu(A) = \abs{A}$. The measure $\mu$ need not be normalized on $\O$, i.e. $\mu(\O)$ need not be $1$. I interpret $\mu$ as just a measure of the size of regions of the possibility space, rather than a measure of probability or randomness.&lt;/p&gt;
&lt;p&gt;The information $\O \tr R$ is quantified by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h_\O(R) \df \lg\par{\frac{\mu(\O)}{\mu(R)}} = \lg\par{\frac{1}{\mu(R\mid \O)}}\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which has the unit &lt;em&gt;bits&lt;/em&gt; and measures the number of halvings it takes to go from $\O$ to $R$.&lt;/p&gt;
&lt;p&gt;I put $\O$ in the subscript of $h$ to make it clear what the domain is. Let $\mu(A \mid B) \df \mu(A\dom{B} \mid B) = \mu(A\cap B\mid B)$ be the measure $\mu$ restricted to $B$ and normalized so that $\mu(B \mid B) = 1$. When $\mu(\O) = 1$, then $h_\O(R) = -\lg\mu(R)$ which is called &lt;em&gt;self-information&lt;/em&gt; in Shannon&amp;rsquo;s information theory, and $h(A \mid B) = -\lg\mu(A \mid B)$ is called &lt;em&gt;conditional self-information&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;If $\O$ has already been narrowed down to $R$, and is then further narrowed down to $R&#39;\subseteq R$, the incremental quantity of information, i.e. the quantity of $R\tr R&#39;$, is given by $h(R&#39; \mid R)$. In general, for any sets $A,B \subseteq \O$, the information $B \tr A\dom{B}$ is quantified by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(A \mid B) &amp;amp;\df h_\O(A\dom{B}) - h_\O(B) \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(B)}{\mu(A\dom{B})}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{1}{\mu(A\mid B)}}\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;I leave off the $\O$ subscript because it has no bearing on this quantity. Note that $h(A \mid B) = h_B(A\dom{B}) = h_B(A\cap B)$ is just another way to specify the domain $B$. This is convenient notationally when $A\setminus B\neq \es$.&lt;/p&gt;
&lt;p&gt;To make working with these quantities easier, I adopt the following shorthand:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(B \tr A\dom{B}) &amp;amp;\df h(A\dom{B} \mid B) = h_B(A\dom{B}) \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(B)}{\mu(A\dom{B})}}\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;The lhs of the arrow goes in the numerator, and the rhs of the arrow goes in the denominator. This is convenient for thinking algebraically about more complex manipulations:&lt;/p&gt;
&lt;p&gt;For $A \subseteq B$ and $B\subseteq C$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(C \tr B) + h(B \tr A) &amp;amp;= \lg\par{\frac{\mu(C)}{\cancel{\mu(B)}}} + \lg\par{\frac{\cancel{\mu(B)}}{\mu(A)}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(C)}{\mu(A)}} \\&lt;br&gt;
&amp;amp;= h(C\tr A)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Likewise we obtain the following identities:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(C\tr A) - h(B \tr A) &amp;amp;= h(C \tr B) \\&lt;br&gt;
h(C \tr A) - h(C \tr B) &amp;amp;= h(B \tr A)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This successive narrowing down can be represented visually:&lt;/p&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505092828.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505092828.png&#34; width=&#34;600&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;
&lt;h1 id=&#34;mutual-information&#34;&gt;Mutual Information&lt;/h1&gt;
&lt;p&gt;Let $A,R\subseteq \O$. Suppose we have the information $\O\tr R$, corresponding to the knowledge that $\o^*\in R$. To be more succinct, I will say that we know that $R$ is &lt;em&gt;true&lt;/em&gt;. Also suppose we don&amp;rsquo;t know whether $A$ is true, i.e. we don&amp;rsquo;t have the information $\O\tr A$. For information that is not known, I will use a &lt;em&gt;small diagonal arrow&lt;/em&gt;, $\tra{\O}{A}$. We can think of this as aspirational information, i.e. information we do not have but would like to have.&lt;/p&gt;
&lt;p&gt;Since $\tra{\O}{A}$ and $\O\tr A$ are mathematically equivalent, $h(\tra{\O}{A}) = h(\O\tr A) = \lg\frac{\mu(\O)}{\mu(A)}$.&lt;/p&gt;
&lt;p&gt;Does $\O\tr R$ move us closer to the goal of $\tra{\O}{A}$? That is to say, given we have the information $\O\tr R$, what &lt;strong&gt;information about&lt;/strong&gt; $A$ do we have? As we shall see, pointwise mutual information quantifies &amp;ldquo;information about&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;There are three ways $R$ and $A$ can interact:&lt;br&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505094432.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505094432.png&#34; width=&#34;600&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505094504.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505094504.png&#34; width=&#34;600&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505094519.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505094519.png&#34; width=&#34;600&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;br&gt;
Arrows here indicate information we actually have, i.e. $\O\tr R$, and lack of arrows indicates information we don&amp;rsquo;t have, i.e. $\tra{\O}{A}$ and $\tra{R}{A\cap R}$.&lt;/p&gt;
&lt;p&gt;In the first case, $A \subseteq R$, and $\tra{\O}{A}$ is transformed into $\tra{R}{A}$. Clearly $h(\tra{\O}{A}) - h(\tra{R}{A}) = h(\O\tr R)$ which is the quantity of information we have gained towards $\tra{\O}{A}$, and $h(\tra{R}{A})$ is the quantity of information still needed to know that $A$ is true.&lt;/p&gt;
&lt;p&gt;In the other two cases, parts of $A$ are ruled out, which shrinks $A$ or reduces it to the empty set. The aspirational information $\tra{\O}{A}$ is transformed into $\tra{R}{A\dom{R}}$. The change in quantity is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
h(\tra{\O}{A}) - h(\tra{R}{A\dom{R}}) &amp;amp;= \lg\par{\frac{\mu(\O)}{\mu(A)}} - \lg\par{\frac{\mu(R)}{\mu(A\dom{R})}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(A\dom{R})\mu(\O)}{\mu(A)\mu(R)}}\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;and nothing cancels out if $A \neq A\dom{R}$. This is an irreducible quantity of interest, called &lt;strong&gt;pointwise mutual information&lt;/strong&gt; (PMI), formally defined as&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
i_\O(A, R) &amp;amp;\df \lg\par{\frac{\mu(A\dom{R})\mu(\O)}{\mu(A)\mu(R)}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(A \mid \O)}{\mu(A \mid R)}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(R \mid \O)}{\mu(R \mid A)}} \,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;When $\mu(\O) = 1$ we get the more familiar expression, $i_\O(A, R) = \lg\par{\frac{\mu(A \cap R)}{\mu(A)\mu(R)}}$.&lt;/p&gt;
&lt;p&gt;We can see that $i_\O(A, R)$ can also be written&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
i_\O(A, R) &amp;amp;= \lg\par{\frac{\mu(\O)}{\mu(R)}} - \lg\par{\frac{\mu(A)}{\mu(A\dom{R})}} \\&lt;br&gt;
&amp;amp;= h(\O\tr R) - h(\tra{A}{A\dom{R}}) \\&lt;br&gt;
&amp;amp;= i_\O(R, A)\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where the $A$ and $R$ corners are swapped.&lt;/p&gt;
&lt;p&gt;Since $h(\tra{A}{A\dom{R}})$ is always positive (because $\mu(A\dom{R})\leq\mu(A)$), we see that $i_\O(A, R)$ is upper bounded by $h(\O\tr R)$, and $i_\O(A, R) = h(\O\tr R)$ when $A \subseteq R$ (since $\mu(A\dom{R}) = \mu(A)$), which we previously derived.&lt;/p&gt;
&lt;p&gt;What about when $A\dom{R} \neq A$? It turns out that $i_\O(A, R)$ is not lower bounded, and can be arbitrarily negative. To interpret these negative values, let&amp;rsquo;s think about what is going on visually. The information $\O\tr R$ transforms $(\O,A)$ to $(R,A\dom{R})$:&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210505104353.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
In terms of quantity, what has changed is the ratio: $\frac{\mu(\O)}{\mu(A)}$ to $\frac{\mu(R)}{\mu(A\dom{R})}$. Specifically, if $\frac{\mu(\O)}{\mu(A)} \to \frac{\mu(R)}{\mu(A\dom{R})}$ is one halving, i.e. $\frac{\mu(R)}{\mu(A\dom{R})} = \frac{1}{2}\frac{\mu(\O)}{\mu(A)}$, then $i_\O(A, R) = \lg\par{\frac{\mu(\O)}{\mu(A)}\Big{/}\frac{\mu(R)}{\mu(A\dom{R})}} = \lg\par{\frac{\mu(\O)}{\mu(A)}\Big{/}\frac{1}{2}\frac{\mu(\O)}{\mu(A)}} = \lg(2) = 1$ bit.&lt;/p&gt;
&lt;p&gt;A different way to think about it is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
i_\O(A,R) &amp;amp;= \lg\par{\frac{\mu(\O)}{\mu(R)\frac{\mu(A)}{\mu(A\dom{R})}}} \\&lt;br&gt;
&amp;amp;= \lg\par{\frac{\mu(\O)}{\nu(R)}}\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $\nu(Q)=\mu(Q)\frac{\mu(A)}{\mu(A\dom{R})}$ rescales the size of any set $Q$ so that $\nu(A\dom{R}) = \mu(A\dom{R})\frac{\mu(A)}{\mu(A\dom{R})} = \mu(A)$. In this form, $i_\O(A,R)$ looks like the quantity of information for $\O\tr R$, but where the numerator and denominator use different measures. This quantity of information can be negative, unlike $h(\O\tr R)$.&lt;/p&gt;
&lt;p&gt;This rescaling can be visualized by drawing to scale the relative proportions of $\mu(\O)$ and $\mu(A)$, and show below that the same relative proportions of $\nu(R)$ and $\nu(A\dom{R})$, so that $\nu(A\dom{R})$ is visually the same size as $\mu(A)$:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210506164550.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210506164550.png&#34; width=&#34;400&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;br&gt;
Here lengths denote size. This image shows that 1 bit is gained about whether $A$ is true because the domain is halved, i.e. we are 1 bit closer to knowing that $A$ is true. However, the bottom rectangle is rescaled so that $A$ and $A\dom{R}$ are visually the same size. $h(\O\tr R)$ may not be 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210506164602.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210506164602.png&#34; width=&#34;740&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;br&gt;
Here is another example where the narrowing down $\tra{A}{A\dom{R}}$ outpaces the narrowing down $\O\tr R$, i.e. more of $A$ is ruled out than the domain of $A$ is reduced. We see that this scaled domain appears to be doubled, which is the loss of 1 bit, i.e. $i_\O(A,R) = -1$. We are 1 bit further away from knowing that $A$ is true, and we now need an additional bit of information to know $\tra{\O}{A}$ compared with before $\O\tr R$ was known (compared with total ignorance).&lt;/p&gt;
&lt;p&gt;Now we see why PMI is upper bounded but not lower bounded. At most, $i_\O(A, R) = h(\O\tr A)$ if $R = A$, which is equivalent to gaining the information that $A$ is true. This can be achieved in a finite number of halvings. On the other hand, the scaled domain of $A\dom{R}$ can grow arbitrarily large as $R$ rules out more and more of $A$, i.e. $\mu(A \setminus R) \to \mu(A)$ implies $\mu(A\dom{R}) \to 0$. If $A \cap R = \es$, then $i_\O(A,R) = -\infty$, which we can interpret to mean that $\O\tr R$ proves that $A$ is &lt;em&gt;false&lt;/em&gt;, i.e. the knowledge that $\o^* \notin A$. Thus no amount of information can make $A$ true (an infinite quantity of information here indicates a contradiction).&lt;/p&gt;
&lt;h2 id=&#34;pmi-vs-conditional-information&#34;&gt;PMI vs conditional information&lt;/h2&gt;
&lt;p&gt;$i_\O(A, R)$ and $h(A \mid R)$ are each quantifying a kind of transformation on $\tra{\O}{A}$. Assuming that $\O\tr R$ is already known,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$i_\O(A, R)$ quantifies a change in the lhs (domain) and a rescaling of the rhs: $\tra{\O}{A} \to \tra{R}{A\dom{R}}$, whereas&lt;/li&gt;
&lt;li&gt;$h(A \mid R)$ quantifies a change in the rhs (target): $(\O\tr R) \to (\O \tr A)$, i.e. the amount of additional bits gained by this transformation.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;A well known identity from information theory is $i_\O(A, R) + h(A \mid R) = h_\O(A)$, or written another way:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
i_\O(A, R) + h(R \tr A\dom{R}) = h(\O\tr A)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Why is this sum not equal to $h(\O\tr A\dom{R})$? Note that $h(\O\tr R) + h(R \tr A\dom{R}) = h(\O\tr A\dom{R})$. As we saw, $i_\O(A, R)$ is closely related to $h(\O\tr R)$ but not always the same.&lt;/p&gt;
&lt;p&gt;The difference between $i_\O(A, R) + h(R \tr A\dom{R})$ and $h(\O\tr R) + h(R \tr A\dom{R})$ can be illustrated visually.&lt;/p&gt;
&lt;p&gt;Double domain reduction $h(\O\tr R) + h(R \tr A\dom{R}) = h(\O\tr A\dom{R})$:&lt;br&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505132315.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505132315.png&#34; width=&#34;600&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The PMI $i_\O(A, R)$ involves a rescaling of $A\dom{R}$ to $A$, shown visually. The transformation $\tra{\O}{A} \to \tra{R}{A\dom{R}}$, when rescaled covers the &lt;em&gt;distance&lt;/em&gt; $i_\O(A, R)$ in the diagram. $h(R \tr A\dom{R})$ covers the remaining &lt;em&gt;distance&lt;/em&gt;, which is equivalent to the total distance $h(\O\tr A)$.&lt;br&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505134431.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505134431.png&#34; width=&#34;400&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;appendix-pmi-algebra&#34;&gt;Appendix: PMI Algebra&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;ve played around with an algebraically convenient notation for PMI, and this is what I arrived at:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
h(\mi{\O}{A}{R}{A\dom{R}}) \df h(\tra{\O}{A}) - h(\tra{R}{A\dom{R}}) = i_\O(A, R)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;It visualizes the joint narrowing down involved in mutual information:&lt;/p&gt;
&lt;span class=&#34;image-container&#34;&gt;&lt;span class=&#34;link&#34; &gt;&lt;a href=&#34;../../Pasted%20image%2020210505100706.png&#34; 
        target=&#34;_blank&#34;&gt;&lt;img class=&#34;img&#34; src=&#34;../../Pasted%20image%2020210505100706.png&#34; width=&#34;400&#34;/&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/span&gt;
&lt;p&gt;This notation has the downside of not being compact. I&amp;rsquo;m not sure if it helps with reasoning about relations between quantities. You can evaluate that for yourself:&lt;/p&gt;
&lt;p&gt;$h(\mi{\O}{A}{R}{A\dom{R}}) = h(\mi{\O}{R}{A}{A\dom{R}})$&lt;br&gt;
$h(\mi{\O}{A}{R}{A\dom{R}}) = h(\O\tr R) - h(A \tr A\dom{R})$&lt;/p&gt;
&lt;p&gt;$h(\O\tr R) - h(\mi{\O}{A}{R}{A\dom{R}}) = h(A \tr A\dom{R})$&lt;br&gt;
$h(\tra{\O}{A}) - h(\mi{\O}{A}{R}{A\dom{R}}) = h(\tra{R}{A\dom{R}})$&lt;br&gt;
$h(\mi{\O}{A}{R}{A\dom{R}}) + h(\tra{R}{A\dom{R}}) = h(\tra{\O}{A})$&lt;br&gt;
$h(\mi{\O}{A}{R}{A\dom{R}}) + h(A \tr A\dom{R}) = h(\O\tr R)$&lt;/p&gt;
&lt;p&gt;$h(\mi{\O}{A}{R}{A\dom{R}}) + h(R\tr A\dom{R}) + h(A \tr A\dom{R}) = h(\O\tr A\dom{R})$&lt;br&gt;
$h(\mi{\O}{A}{R}{A\dom{R}}) + h(\O\tr R) + h(R \tr A\dom{R}) = h(\O\tr A\dom{R})$&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Causality For Physics</title>
      <link>https://danabo.github.io/blog/posts/causality-for-physics/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/causality-for-physics/</guid>
      <description>&lt;p&gt;The definition of causality within physics is not a settled matter, perhaps surprisingly. My understanding is that this question is studied more by philosophers than physicists, as the field of physics tends to avoid interpretational problems. That is to say, theories like relativity or quantum mechanics are mathematically well defined and make predictions, so that&amp;rsquo;s all there is to it, right? I&amp;rsquo;m not a physicist, so I will proceed to ask such questions.&lt;/p&gt;
&lt;p&gt;I suspect that causality and information are intimately related. To initiate my pursuit to understand physical information, I am starting by trying to understand the role causality plays in physics. The &lt;a href=&#34;https://plato.stanford.edu/entries/causation-physics&#34;target=&#34;_blank&#34;&gt;SEP&lt;/a&gt; outlines some of the conversation and ideas around causality and physics. I haven&amp;rsquo;t read these ideas yet, but I want to take my own tabula rasa stab at the problem before reading about what other people have tried. I am familiar with Judea Pearl&amp;rsquo;s notion of causality in machine learning and statistics, which I will attempt to apply to physics below.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\s}{\sigma}&lt;br&gt;
\newcommand{\t}{\tau}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\d}{\delta}&lt;br&gt;
\newcommand{\dd}{\mathrm{d}}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\E}{\mb{E}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\vtup}[1]{\left\langle#1\right\rangle}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[2]{#1_{\mid #2}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
\newcommand{\Do}{\mathrm{do}}&lt;br&gt;
\newcommand{\do}[2]{\underset{#1\leadsto #2}{\mathrm{do}}}&lt;br&gt;
\newcommand{\restr}[1]{_{\mid{#1}}}&lt;br&gt;
\newcommand{\dt}{{\D t}}&lt;br&gt;
\newcommand{\Dt}{{\D t}}&lt;br&gt;
\newcommand{\ddT}{{\delta T}}&lt;br&gt;
\newcommand{\Mid}{\,\middle|\,}&lt;br&gt;
\newcommand{\qed}{\ \ \blacksquare}&lt;br&gt;
$$&lt;/p&gt;
&lt;h1 id=&#34;causal-models&#34;&gt;Causal Models&lt;/h1&gt;
&lt;p&gt;First, I&amp;rsquo;ll outline Pearl&amp;rsquo;s framework for causality. I used &lt;a href=&#34;http://bayes.cs.ucla.edu/BOOK-2K/&#34;target=&#34;_blank&#34;&gt;Causality&lt;/a&gt; (Pearl) and &lt;a href=&#34;https://mitpress.mit.edu/books/elements-causal-inference&#34;target=&#34;_blank&#34;&gt;Elements of Causal Inference&lt;/a&gt; (Peters, Janzing, SchÃ¶lkopf) to learn about this topic.&lt;/p&gt;
&lt;p&gt;Pearl assumes the world (or some part of it) can be represented by graph, where nodes represent potential observations, and their directed edges represent causal links. For example (from Pearl):&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210412175938.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
The core idea in Pearl&amp;rsquo;s causality is the &lt;strong&gt;intervention&lt;/strong&gt;, which is a modification to the graph where a node is disconnected from all incoming arrows and held fixed at some value.&lt;/p&gt;
&lt;p&gt;An example of an intervention:&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210412175953.png&#34; alt=&#34;&#34;&gt;
&lt;br&gt;
An intervention in this graph is a &lt;strong&gt;graph surgery&lt;/strong&gt; (as Pearl calls it). Graph interventions correspond to real-world interventions. The intervention depicted above corresponds to someone forcing the sprinkler system to turn on (e.g. by switching the sprinkler system&amp;rsquo;s setting from auto to manual). The sprinkler state is now causally independent of everything else in the graph, because we, the experimenters, have directly determined its state (we would need to be careful to ensure our own actions are not causally linked to the system we are studying). By observing the down stream effects of this change to the graph, the &lt;strong&gt;causal effect&lt;/strong&gt; of the particular node $X_3$ can be measured. That is the effect of $X_3$, independent of other nodes like $X_1$.&lt;/p&gt;
&lt;p&gt;Generally Pearl places a probability distribution on graph node states, given by $P(X_1=x_1, X_2=x_2, X_3=x_3, \dots)$, or using shorthand, $P(x_1, x_2, x_3, \dots)$. I&amp;rsquo;ll use capital letters, $X_i$, to denote graph nodes themselves (or random variables on graph nodes), and lowercase letters, $x_i$, to denote a specific value that the correspond node takes on. So for example, node $X_3$, the sprinkler state, could take on the values $\mathrm{ON}$ or $\mathrm{OFF}$. In the abstract, $X_3$ takes on some value $x_3$. Sometimes I&amp;rsquo;ll introduce a &amp;ldquo;prime&amp;rdquo; tick, $x&#39;_3$, to denote some other value that may be distinct from $x_3$.&lt;/p&gt;
&lt;p&gt;There is an alternative &lt;strong&gt;functional&lt;/strong&gt; perspective, where each node&amp;rsquo;s value is a deterministic function of incoming values traveling along inward arrows, and an auxiliary noise input not depicted in the graph. Those noise inputs can themselves be determined (i.e. held fixed), but be pulled from an algorithmically random stream. I will stick to the deterministic perspective when I discuss physics, while recognizing that random physical processes can be viewed as deterministic but algorithmically random.&lt;/p&gt;
&lt;p&gt;Quoting &lt;a href=&#34;http://bayes.cs.ucla.edu/BOOK-2K/&#34;target=&#34;_blank&#34;&gt;Causality&lt;/a&gt;, section 1.4.1, &lt;em&gt;Structural Equations&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In its general form, a functional causal model consists of a set of equations of the form&lt;br&gt;
$$x_i = f_i(pa_i,u_i),\quad i=1,\dots,n\,,$$&lt;br&gt;
where $pa_i$ (connoting parents) stands for the set of variables that directly determine the value of $X_i$ and where the $U_i$ represent errors (or âdisturbancesâ) due to omitted factors.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is to say, the parents $PA_i$ of node $X_i$ is the set of nodes with arrows pointing into $X_i$. So in the example, $PA_3 = \set{X_1}$ because $X_1$ is the only node pointing into $X_3$, and $PA_4 = \set{X_2, X_3}$ because both $X_2$ and $X_3$ point into $X_4$. Node $X_1$ is not a direct parent of $X_4$.&lt;/p&gt;
&lt;p&gt;$U_i$ is an auxiliary input node to each $X_i$ which is not depicted in the graph, which makes the output value $x_i$ random. In my view, each value $u_i$ is pulled from an algorithmically random stream. Given the set of values $pa_i$ and value $u_i$, the output of the function $f_i$ is then able to be random.&lt;/p&gt;
&lt;p&gt;A note about notation: It would not be correct to write $f_i(PA_i,U_i)$ which passes the nodes themselves into the function $f_i$. On the other hand, $f_i(pa_i,u_i)$ is passing the values $pa_i$ of the parent nodes $PA_i$ and $u_i$ of the noise input node $U_i$ into the function.&lt;/p&gt;
&lt;h2 id=&#34;do-operator&#34;&gt;Do-Operator&lt;/h2&gt;
&lt;p&gt;If $P$ is the probability measure on the initial graph (e.g. figure 1.2 above), then what is the probability measure on the modified graph after taking an intervention (e.g. figure 1.4)? Pearl uses &amp;ldquo;do&amp;rdquo;-notation, which for the example above looks like this:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
P(x_1, x_2, x_3, x_4, x_5 \mid \Do(X_3 = \mathrm{ON}))\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This is the probability of the vector of node values $(x_1, x_2, x_3, x_4, x_5)$ given that the intervention setting node $X_3$ to constant value $\mathrm{ON}$ was taken. Note the notational similarity to conditional probability: $P(x_1, x_2, x_3, x_4, x_5 \mid X_3 = \mathrm{ON})$. Conditionalization is a different operation on the measure $P$ than the &amp;ldquo;do&amp;rdquo;-operator, but they are mathematically related and their similar notation is justified.&lt;/p&gt;
&lt;p&gt;For an arbitrary graph with nodes $X_1,\dots,X_n$, and probability measure $P$ on node values, the conditional probability of value vector $(x_1, \dots, x_n)$ given $X_i = x&#39;_i$ is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
P(x_1, \dots, x_n \mid x&#39;_i) = \begin{cases}&lt;br&gt;
\frac{P(x_1, \dots, x_n)}{P(x&#39;_i)} &amp;amp; x_i=x&#39;_i \\&lt;br&gt;
0 &amp;amp; x_i \neq x&#39;_i&lt;br&gt;
\end{cases}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;whereas the probability of $(x_1, \dots, x_n)$ given that intervention $\Do(X_i = x&#39;_i)$ was taken is (&lt;a href=&#34;http://bayes.cs.ucla.edu/BOOK-2K/&#34;target=&#34;_blank&#34;&gt;Causality&lt;/a&gt;, eq 3.11)&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
P(x_1, \dots, x_n \mid \mathrm{do}(x&#39;_i)) = \begin{cases}&lt;br&gt;
\frac{P(x_1, \dots, x_n)}{P(x&#39;_i \mid pa_i)} &amp;amp; x_i=x&#39;_i \\&lt;br&gt;
0 &amp;amp; x_i \neq x&#39;_i&lt;br&gt;
\end{cases}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Both operations are performing a &lt;strong&gt;domain restriction&lt;/strong&gt; on $P$, in the sense that the resulting measure assigns 0 probability to all vectors $(x_1, \dots, x_n)$ where $x_i \neq x&#39;_i$, for some constant $x&#39;_i$. The difference between them is that conditionalization, $P(x_1, \dots, x_n \mid x&#39;_i)$, simply rescales the resulting measure by $1/P(x&#39;_i)$ after domain restriction, whereas intervention, $P(x_1, \dots, x_n \mid \mathrm{do}(x&#39;_i))$, re-weights every single probability independently by $1/P(x&#39;_i \mid pa_i)$, where $pa_i$ is the set of values in $(x_1, \dots, x_n)$ for the parent nodes $PA_i$ of node $X_i$.&lt;/p&gt;
&lt;p&gt;Rewriting $P(x_1, \dots, x_n)$, we can see why multiplying by $1/P(x&#39;_i \mid pa_i)$ corresponds to an intervention:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
P(x_1, \dots, x_n) = \prod_{j=1}^n P(x_j \mid pa_j)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;by the chain rule of probability, because the graph also encodes which nodes are statistically independent, i.e. if $x_k \notin pa_j$, then $P(x_j \mid x_k) = P(x_j)$.&lt;/p&gt;
&lt;p&gt;The operation of removing the connections going into $X_i$ from the parents $PA_i$ is a matter of removing the term $P(x_i \mid pa_i)$ by dividing it out.&lt;/p&gt;
&lt;p&gt;This formulation of an intervention can be generalized further. Instead of setting $X_i$ to a constant value $x&#39;_i$, in general, we can replace the node distribution $P(X_i \mid PA_i)$ with the new distribution $Q(X_i \mid PA&#39;_i)$ where $PA&#39;_i$ is some new set of parents, which may or may not be the empty set, or equivalent to or overlap with the old parents $PA_i$. If $PA&#39;_i$ is empty, that is equivalent to making $Q$ statistically independent where $Q(X_i \mid PA_i) = Q(X_i)$. We can get our constant-value intervention by choosing a delta distribution (one-hot for discrete $X_i$, and Dirac delta for continuous $X_i$) $Q(X_i) = \d_{x&#39;_i}$ which is non-zero only if $X_i = x&#39;_i$. Now this general-case intervention is replacing the term $P(X_i \mid PA_i)$ with $Q(X_i \mid PA&#39;_i)$, which looks like this:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; P\left(x_1, \dots, x_n \Mid\, \Do\left\{P(x_i\mid pa_i) \to Q(x_i\mid pa&#39;_i)\right\}\ \right) \\ \\&lt;br&gt;
&amp;amp;=&lt;br&gt;
P(x_1, \dots, x_n)\frac{Q(x_i \mid pa&#39;_i)}{P(x_i \mid pa_i)}\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;When $Q(x_i \mid pa&#39;_i) = Q(x_i) = \d_{x&#39;_i}$ this expression reduces to the constant-value intervention defined above.&lt;/p&gt;
&lt;p&gt;In the functional perspective, an intervention replaces $f_i(pa_i, u_i)$ with some other function $f&#39;_i(pa&#39;_i, u_i)$.&lt;/p&gt;
&lt;h2 id=&#34;causal-effect&#34;&gt;Causal Effect&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;http://bayes.cs.ucla.edu/BOOK-2K/&#34;target=&#34;_blank&#34;&gt;Causality&lt;/a&gt;, definition 3.2.1, Pearl defines causal effect as follows:&lt;/p&gt;
&lt;p&gt;Let $X$ and $Y$ be two disjoint sets of graph nodes. The &lt;strong&gt;causal effect&lt;/strong&gt; of $X$ on $Y$ is the &lt;em&gt;function&lt;/em&gt; $\mc{E}$ from the space of node values for $X$ to the space of probability measures on $Y$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mc{E}(x) = P(Y \mid \Do(X=x))\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $x$ is some chosen vector of values for the nodes $X$.&lt;/p&gt;
&lt;p&gt;That is to say, the causal effect of nodes $X$ on nodes $Y$ is characterized by the set of all interventions obtained setting $X$ to every possible value $x$, where each intervention is characterized by a change in probability distribution on $Y$. That is to say, the causal effect of $X$ on $Y$ is characterized by how $P(Y \mid \Do(X=x))$ varies for different $x$, and compared to no intervention $P(Y)$.&lt;/p&gt;
&lt;h2 id=&#34;when-interventions-and-conditionalization-are-equivalent&#34;&gt;When Interventions And Conditionalization Are Equivalent&lt;/h2&gt;
&lt;p&gt;It should be obvious that when node $X_i$ has no parents then $P(x_{1:n} \mid \Do(x&#39;_i)) = P(x_{1:n} \mid x&#39;_i)$ for all node values $x&#39;_i$, because $PA_i = \emptyset$ and so $P(x&#39;_i \mid pa_i) = P(x&#39;_i)$.&lt;/p&gt;
&lt;p&gt;Another case is when we are only considering the marginal distribution on a subset of variables. Then the conditional distribution and intervention distribution on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_blanket&#34;target=&#34;_blank&#34;&gt;Markov blanket&lt;/a&gt; of that subset are equivalent.&lt;/p&gt;
&lt;p&gt;To see what I mean, let&amp;rsquo;s consider the Markov chain $X_1, \dots, X_n$ where $P(x_1, \dots, x_n) = P(x_n \mid x_{n-1})P(x_{n-1} \mid x_{n-2})\dots P(x_2 \mid x_1)P(x_1)$ and $PA_i = \set{X_{i-1}}$ for all $i &amp;gt; 1$. Then we have&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; P(x_n, \dots, x_{i+1} \mid \Do(x&#39;_i)) \\&lt;br&gt;
&amp;amp;\quad= \sum_{x_{i-1},\dots,x_1} P(x_n, \dots, x_1 \mid \Do(x&#39;_i)) \\&lt;br&gt;
&amp;amp;\quad= \begin{cases}&lt;br&gt;
\sum_{x_{i-1},\dots,x_1}\frac{P(x_n, \dots, x_{i+1}\mid x_i)P(x_i \mid x_{i-1})P(x_{i-1},\dots,x_1)}{P(x&#39;_i \mid x_{i-1})} &amp;amp; x_i=x&#39;_i \\&lt;br&gt;
0 &amp;amp; x_i \neq x&#39;_i&lt;br&gt;
\end{cases} \\&lt;br&gt;
&amp;amp;\quad= \sum_{x_{i-1},\dots,x_1}P(x_n, \dots, x_{i+1} \mid x&#39;_i)P(x_{i-1},\dots,x_1) \\&lt;br&gt;
&amp;amp;\quad= P(x_n, \dots, x_{i+1} \mid x&#39;_i)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210519122301.png&#34; alt=&#34;&#34;&gt;
&lt;/p&gt;
&lt;h1 id=&#34;causality-for-physics&#34;&gt;Causality For Physics&lt;/h1&gt;
&lt;p&gt;Pearl&amp;rsquo;s causality is based on the idea of the intervention, which is a kind of graph surgery.&lt;/p&gt;
&lt;p&gt;To apply Pearl&amp;rsquo;s causality to physics, we&amp;rsquo;d need to define what an intervention does to physical processes. There are two immediate problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pearl defines interventions for causal graphs, where node values are sampled i.i.d., and the nodes represent are stateless and otherwise  isolated processes (aside from their arrows). Physics, on the other hand, allows for arbitrary interactions between systems, to the point where the boundaries between systems may be blurred or destroyed so that it does not even make sense to think about there being any independent components at all (think about a liquid or gas). Physical processes are not i.i.d. (the future depends on the past), and they have internal state which determines their future time evolution.&lt;/li&gt;
&lt;li&gt;Classical physics is non-probabilistic (non-statistical Newtonian mechanics and relativity). If our notation of causality is to be suitable to all of physics, we need to apply to Newtonian mechanics, which means causality must precede probability. Therefore we need to define interventions on deterministic systems.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Pearl generally considers a graph intervention to represent an intervention that can conceivably be taken, and ideally taken recently so that the causal effect of various interventions can be empirically estimated with histograms (empirically estimate $P(Y \mid \Do(X))$ and $P(Y)$).&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t think physical plausible interventions can generalize to arbitrary physical systems. I will instead consider what I call a &lt;strong&gt;counterfactual intervention&lt;/strong&gt;, which is merely a modification to a mathematical model (i.e. representation) of physics. A counterfactual intervention is hypothetical, and produces a different time-line than the &amp;ldquo;factual&amp;rdquo; time-evolution of the system. A counterfactual intervention is the answer to the question, &amp;ldquo;what would have happened if the system were in state $x&#39;$ rather than state $x$ at time $t$?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;If intuition serves right and the logical structure of causality lies within all theories of physics, the purpose of the counterfactual intervention is to probe those theories to make their implicit causal structures mathematically explicit.&lt;/p&gt;
&lt;p&gt;My objective here is to define an abstract definition for theories of physics in general, define what it means to take a counterfactual intervention on a physical system (both probabilistic or non-probabilistic), and then to show the equivalence of this type of intervention to Pearl&amp;rsquo;s graph intervention above.&lt;/p&gt;
&lt;h2 id=&#34;abstract-physics&#34;&gt;Abstract Physics&lt;/h2&gt;
&lt;p&gt;In any theory of physics there is a state space $\O$. In Newtonian mechanics, state is a vector of various components of the system, such as a &lt;a href=&#34;https://en.wikipedia.org/wiki/Canonical_coordinates#Definition_in_classical_mechanics&#34;target=&#34;_blank&#34;&gt;vector of positions and momenta&lt;/a&gt; given by $\o = (\vec{q}, \vec{p}) \in \O$. In general state can include other kinds of &lt;a href=&#34;https://en.wikipedia.org/wiki/Degrees_of_freedom_%28mechanics%29&#34;target=&#34;_blank&#34;&gt;degrees of freedom&lt;/a&gt; such as the orientation of solid bodies in 3D space. In quantum mechanics there is &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_state&#34;target=&#34;_blank&#34;&gt;quantum state&lt;/a&gt;, and state spaces are &lt;a href=&#34;https://en.wikipedia.org/wiki/Hilbert_space#Quantum_mechanics&#34;target=&#34;_blank&#34;&gt;Hilbert spaces&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;theory of physics&lt;/strong&gt; specifies both the state space $\O$ and how to solve for the time-evolution of the system given a particular state $\o_t$ at time $t$. The result is a complete description of a system&amp;rsquo;s time evolution through state space given as a state-function of time, $\s : \R \to \O : t \mapsto \s(t)$, which I&amp;rsquo;ll call a &lt;strong&gt;trajectory&lt;/strong&gt;. To be clear, a single trajectory $\s$ is a single possible time-evolution, e.g. where $\s(t) = \o_t$.&lt;/p&gt;
&lt;p&gt;The mathematical machinery that converts known information, e.g. the state of the system at time $t$, varies between theories of physics and often makes use of a &lt;a href=&#34;https://en.wikipedia.org/wiki/Analytical_mechanics#Lagrangian_mechanics&#34;target=&#34;_blank&#34;&gt;Lagrangian&lt;/a&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Analytical_mechanics#Hamiltonian_mechanics&#34;target=&#34;_blank&#34;&gt;Hamiltonian&lt;/a&gt;. These details can be abstracted away.  In principle, for any theory of physics  there is a family of &lt;a href=&#34;https://en.wikipedia.org/wiki/Time_evolution#Time_evolution_operators&#34;target=&#34;_blank&#34;&gt;time-evolution functions&lt;/a&gt; $\t_{\Dt} : \O \to \O$, for every time interval $\Dt\in\R$ (both positive and negative) which maps any state $\o\in\O$ at time $t$ to the state at time $t+\Dt$. Typically physics is &lt;a href=&#34;https://en.wikipedia.org/wiki/T-symmetry&#34;target=&#34;_blank&#34;&gt;time-symmetric&lt;/a&gt;, which means that $\t_{\Dt}$ is a bijection and thus invertible. Note also that $\t_{\Dt}$ does not depend on the absolute time $t$, and so we are implicitly assuming the given theory of physics is &lt;a href=&#34;https://en.wikipedia.org/wiki/Time_translation_symmetry&#34;target=&#34;_blank&#34;&gt;time-translationally invariant&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The set of all trajectories is $\R \to \O$, &lt;a href=&#34;https://en.wikipedia.org/wiki/Function_space&#34;target=&#34;_blank&#34;&gt;denoting the set of all functions&lt;/a&gt; from $\R$ to $\O$. For a given time-evolution family $\t$, there is a subset of trajectories which are &lt;strong&gt;valid for $\t$&lt;/strong&gt; (or &lt;strong&gt;$\t$-valid&lt;/strong&gt;),&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\Sigma = \set{\s : \R\to\O \mid \fa t,\Dt\in\R : \s(t+\dt) = \t_\dt(\s(t))}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;h3 id=&#34;incorporating-probability&#34;&gt;Incorporating Probability&lt;/h3&gt;
&lt;p&gt;Suppose we want to work with some kind of statistical physics. Perhaps we are uncertain about which state the system is in, or the state is randomly chosen. We can just as easily put a probability measure on the set of trajectories.&lt;/p&gt;
&lt;p&gt;Let $M$ be a probability measure on the set of all trajectories $\R \to \O$. Moreover, we want to require $M$ to obey the physics of $\t$ and assign zero probability to physically impossible trajectories, i.e. $\t$-invalid trajectories. Specifically, $M$ should assign 0 probability to any set comprised &lt;em&gt;only&lt;/em&gt; of $\t$-invalid trajectories, or equivalently, $M(\Sigma) = 1$ (if $M$ is a normalized measure).&lt;/p&gt;
&lt;p&gt;This is not typically how statistical physics is conceived of. Normally, there is a probability measure on states at time $t$, and time evolution time-evolves that measure. Instead, I&amp;rsquo;ve put a static global measure $M$ on entire trajectories. However, these two views are equivalent.&lt;/p&gt;
&lt;p&gt;Let $\mu_t$ be the marginal probability measure on state space $\O$ of the &amp;ldquo;system&amp;rdquo; at time $t$. Specifically, $\mu_t$ is the unique marginal distribution of $M$ on time $t$ only, given by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mu_t(\mc{O}) = M\set{\s:\R\to\O \mid \s(t) \in \mc{O}}\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;for (measurable) state subsets $\mc{O}\subseteq \O$. Then $\mu_{t+\Dt}$ is then the time-evolution of measure $\mu_t$, given by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\mu_{t+\Dt}(\mc{O}) = \mu_t(\t^{-1}_\Dt(\mc{O}))\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Proof&lt;/strong&gt;&lt;/em&gt; that $\mu_t(\t^{-1}_\Dt(\mc{O})) = M\set{\s:\R\to\O \mid \s(t+\Dt) \in \mc{O}}$:&lt;br&gt;
$M\set{\s:\R\to\O \mid \s(t+\Dt) \in \mc{O}}$&lt;br&gt;
$= M\set{\s\in\Sigma \mid \s(t+\Dt) \in \mc{O}} + M\set{\s\in\overline{\Sigma} \mid \s(t+\Dt) \in \mc{O}}$&lt;br&gt;
$= M\set{\s\in\Sigma \mid \s(t+\Dt) \in \mc{O}} + 0$.&lt;br&gt;
$\set{\s\in\Sigma \mid \s(t+\Dt) \in \mc{O}} = \set{\s\in\Sigma \mid \s(t) \in \t^{-1}_\Dt(\mc{O})}$ by the definition of $\Sigma$.&lt;br&gt;
$M\set{\s\in\Sigma \mid \s(t) \in \t^{-1}_\Dt(\mc{O})}$&lt;br&gt;
$= M\set{\s:\R\to\O \mid \s(t) \in \t^{-1}_\Dt(\mc{O})}$&lt;br&gt;
$= \mu_t(\t^{-1}_\Dt(\mc{O}))$ by the definition of $\mu_t$. $\qed$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Proof&lt;/strong&gt;&lt;/em&gt; that $M$ is uniquely determined by $\mu_t$, so long as $\t_\Dt$ is a bijection and $M(\Sigma)=1$.&lt;/p&gt;
&lt;p&gt;At time $t$, for each $\o\in\O$, there is a unique $\t$-valid trajectory $\s$ that passes through $\o$, given by the mapping $t&#39;\mapsto\t_{t&#39;-t}(\o)$. Therefore, there is a family of bijections between the $\t$-valid trajectories $\Sigma$ and state space $\O$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\Gamma_t : \O \to \Sigma : \o \mapsto(t&#39;\mapsto\t_{t&#39;-t}(\o))\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;for all $t\in\R$. So $\Gamma_t(\o) = \s$ where $\s(t) = \o$ and $\s$ is $\t$-valid. The inverse is then $\Gamma^{-1}_t(\s)=\s(t)$. I haven&amp;rsquo;t defined proper measure spaces on trajectories and states, so I will just assume $\Gamma_t$ is a measurable function.&lt;/p&gt;
&lt;p&gt;We can derive the following relation:&lt;br&gt;
$\mu_t(\mc{O}) = M\set{\s:\R\to\O \mid \s(t) \in \mc{O}}$&lt;br&gt;
$=M\set{\s\in\Sigma \mid \s(t) \in \mc{O}}$&lt;br&gt;
$=M\Gamma_t\mc{O}$.&lt;/p&gt;
&lt;p&gt;Thus for any (measurable) subset of trajectories $S \subseteq (\R\to\O)$, there is a corresponding (measurable) subset of states $\mc{O} = \Gamma^{-1}_t(S\cap\Sigma)$ so that $M(S) = M(S\cap\Sigma) = M(\Gamma_t\Gamma^{-1}_t(S\cap\Sigma)) = M(\Gamma_t\mc{O}) = \mu_t(\mc{O})$. $\qed$&lt;/p&gt;
&lt;h2 id=&#34;interventions-for-physics&#34;&gt;Interventions For Physics&lt;/h2&gt;
&lt;p&gt;Let $I : \O\to\O$ be a &lt;strong&gt;state-replacement function&lt;/strong&gt;. Usually we want $I$ to be some kind of state projection function where $I(\O) \subset \O$ is a strict subset.&lt;/p&gt;
&lt;p&gt;I will define a &amp;ldquo;do&amp;rdquo;-operator on individual trajectories which performs a surgery and outputs a modified trajectory. Specifically, given state-replacement function $I$ and time $T$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\do{I}{T}[\s](t) \df \begin{cases}\s(t) &amp;amp; t &amp;lt; T \\ \t_{t-T}(I(\s(T))) &amp;amp; t\geq T\end{cases}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;The resulting trajectory is identical to $\s$ prior to time $T$, and discontinuously jumps at time $T$ to the alternative $\t$-valid trajectory starting from state $I(\s(T))$. In this way, $I$ determines which trajectory &amp;ldquo;tail&amp;rdquo; to attach to the given trajectory &amp;ldquo;head&amp;rdquo; $\s$. The resulting &amp;ldquo;Frankenstein&amp;rdquo;-trajectory is usually not globally $\t$-valid, but its head and tail are guaranteed to be $\t$-valid, and thus is locally $\t$-valid everywhere &lt;em&gt;except&lt;/em&gt; across time $T$.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s overload this &amp;ldquo;do&amp;rdquo;-operator to apply element-wise to sets, so&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\Sigma&#39; = \do{I}{T} \Sigma = \set{\do{I}{T}[\s] \Mid \s\in\Sigma}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Starting with the measure $M$ from above, applying $\do{I}{T}$ to the set of all trajectories $\R\to\O$ induces a transformed measure $M&#39;$, where for subsets $S&#39; \subseteq (\R\to\O)$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
M&#39;(S&#39;) = M\left(\do{I}{T}^{-1}S&#39;\right) = M\set{\s\in\Sigma \Mid \do{I}{T}[\s] \in S&#39;}\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This conception of intervention is different from Pearl&amp;rsquo;s, which is a modification of the functions generating the behavior of the process in question. In my formulation, I am modifying the state of the process at some point in time, but keeping the behavior-generating-functions, i.e. $\t$, unchanged. That is to say, I am modifying systems, but not the physics, whereas Pearl is modifying the physics, so to speak.&lt;/p&gt;
&lt;h3 id=&#34;proof-of-pearl-equivalence&#34;&gt;Proof of Pearl-Equivalence&lt;/h3&gt;
&lt;p&gt;The question is whether my definition of an intervention is equivalent with Pearl&amp;rsquo;s. To prove this, I need to put my intervention in terms of Pearl&amp;rsquo;s setup.&lt;/p&gt;
&lt;p&gt;The measure $M$ on trajectories corresponds to the measure $P$ on graph states, and the transformed measure $M&#39;$ corresponds to the transformed measure $P(\ldots \mid \Do(\ldots))$ on the modified graph.&lt;/p&gt;
&lt;p&gt;Recall that $M&#39;$ is defined by&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
M&#39;(S&#39;) = M\set{\s\in\Sigma \Mid \do{I}{T}[\s] \in S&#39;}\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;for subsets $S&#39;\subseteq (\R\to\O)$ of trajectories. I need to show that $M&#39;$ has the same form as Pearl&amp;rsquo;s general intervention.&lt;/p&gt;
&lt;p&gt;It will help to define the following notation on trajectories:&lt;br&gt;
$\s\restr{(a,b)}$ is the domain restriction of trajectory $\s$ to time interval $(a,b)$.&lt;/p&gt;
&lt;p&gt;I will use the following short-hands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\s_{&amp;gt;T} = \s\restr{(T,\infty)}$&lt;/li&gt;
&lt;li&gt;$\s_{&amp;lt;T} = \s\restr{(-\infty,T)}$&lt;/li&gt;
&lt;li&gt;$\s_{\ddT} = \s\restr{(T-\dt,T)}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where $\dt &amp;gt; 0$ be an arbitrarily small positive real number.&lt;/p&gt;
&lt;p&gt;The goal is to prove that&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
M&#39;(S&#39;) = \int_{S&#39;} \frac{Q(\s(T) \mid \s_{\ddT})}{M(\s(T) \mid \s_{\ddT})}  \dd M(\s)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;for some probability measure $Q$. This is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Lebesgue_integration&#34;target=&#34;_blank&#34;&gt;Lebesgue integral&lt;/a&gt; w.r.t. $\s$ using measure $M$, which for our purposes is just the expectation of the integrand w.r.t. measure $M$. As a Riemann integral: $\int_{S&#39;} M(\s)\frac{Q(\s(T) \mid \s_{\ddT})}{M(\s(T) \mid \s_{\ddT})}  \dd \s$.&lt;/p&gt;
&lt;p&gt;It turns out that&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
Q(\s(T) \mid \s_{\ddT}) = M(I^{-1}(\s(T)) \mid \s_{\ddT})\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Proof&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We have,&lt;br&gt;
$M(\s) = M(\s_{&amp;gt;T} \mid \s(T)) \cdot M(\s(T) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T})$,&lt;br&gt;
where $M(\s(T) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T}) = M(\s(T) \mid \s_{&amp;lt;T})$ because $M$ is Markov w.r.t. time, which is guaranteed by the construction of $\Sigma$ from $\t_{\D t}$.&lt;/p&gt;
&lt;p&gt;Expanding out the integrand, we have&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; M(\s)\frac{Q(\s(T) \mid \s_{\ddT})}{M(\s(T) \mid \s_{\ddT})} \\ \\&lt;br&gt;
=\ &amp;amp; M(\s_{&amp;gt;T} \mid \s(T)) \cdot M(\s(T) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T})\frac{Q(\s(T) \mid \s_{\ddT})}{M(\s(T) \mid \s_{\ddT})} \\ \\&lt;br&gt;
=\ &amp;amp; M(\s_{&amp;gt;T} \mid \s(T)) \cdot Q(\s(T) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T}) \\ \\&lt;br&gt;
=\ &amp;amp; M(\s_{&amp;gt;T} \mid \s(T)) \cdot M(I^{-1}(\s(T)) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T})\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;The remainder of this proof consists of showing the following equivalences, which I&amp;rsquo;ll prove below as lemmas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$M(\s_{&amp;gt;T} \mid \s(T)) = M&#39;(\s_{&amp;gt;T} \mid \s(T))$&lt;/li&gt;
&lt;li&gt;$M(I^{-1}(\s(T)) \mid \s_{\ddT}) = M&#39;(\s(T) \mid \s_{\ddT})$&lt;/li&gt;
&lt;li&gt;$M(\s_{&amp;lt;T}) = M&#39;(\s_{&amp;lt;T})$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That allows us to rewrite:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; M(\s_{&amp;gt;T} \mid \s(T)) \cdot M(I^{-1}(\s(T)) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T}) \\ \\&lt;br&gt;
=\ &amp;amp; M&#39;(\s_{&amp;gt;T} \mid \s(T)) \cdot M&#39;(\s(T) \mid \s_{\ddT}) \cdot M&#39;(\s_{&amp;lt;T}) \\ \\&lt;br&gt;
=\ &amp;amp; M&#39;(\s)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Therefore&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; \int_{S&#39;} \frac{Q(\s(T) \mid \s_{\ddT})}{M(\s(T) \mid \s_{\ddT})}  \dd M(\s) \\ \\&lt;br&gt;
=\ &amp;amp; \int_{S&#39;} \dd M&#39;(\s) \\ \\&lt;br&gt;
=\ &amp;amp; M&#39;(S&#39;)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$\qed$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Proof&lt;/strong&gt;&lt;/em&gt; of remaining lemmas:&lt;/p&gt;
&lt;p&gt;The cases $M(\s_{&amp;gt;T} \mid \s(T)) = M&#39;(\s_{&amp;gt;T} \mid \s(T))$ and $M(\s_{&amp;lt;T}) = M&#39;(\s_{&amp;lt;T})$ are easy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Because the trajectory before $T$ is unchanged,&lt;br&gt;
$M(\s_{&amp;lt;T}) = M&#39;(\s_{&amp;lt;T})$,&lt;/li&gt;
&lt;li&gt;Because time evolution from $T$ onward is deterministic and obeys $\t_\dt$, there is exactly one trajectory $\s^*$ that is valid under $\t_\dt$ s.t. $\s^*(T) = \s(T)$. Thus&lt;br&gt;
$M(\s_{&amp;gt;T} \mid \s(T)) = M&#39;(\s_{&amp;gt;T} \mid \s(T)) = \begin{cases}1 &amp;amp; \s_{\geq T} = \s^*_{\geq T} \\ 0 &amp;amp; \mathrm{otherwise}\end{cases}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now to prove $M(I^{-1}(\s(T)) \mid \s_{\ddT}) = M&#39;(\s(T) \mid \s_{\ddT})$. Expanding out $M(I^{-1}(\s(T)) \mid \s_{\ddT})$, we get&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp;M(I^{-1}(\s(T)) \mid \s_{\ddT}) \\&lt;br&gt;
=\ &amp;amp; M\set{\z \in \Sigma \mid \z(T) \in I^{-1}(\s(T)) \wedge \z\restr{(T-\dt,T)} = \s_{\ddT}}\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Since&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\do{I}{T}[\z](t) = \begin{cases}\z(t) &amp;amp; t &amp;lt; T \\ \t_{t-T}(I(\z(T))) &amp;amp; t\geq T\end{cases}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;then $\z(T) \in I^{-1}(\s(T)) \iff I(\z(T)) = \s(T) \iff \do{I}{T}[\z](T) = \s(T)$,&lt;br&gt;
because $\t_0$ is the identity function.&lt;/p&gt;
&lt;p&gt;Furthermore, $\do{I}{T}[\z]\restr{(-\infty,T)} = \z\restr{(-\infty,T)}$,&lt;br&gt;
so $\z\restr{(T-\dt,T)} = \s_{\ddT} \iff \do{I}{T}[\z]\restr{(T-\dt,T)} = \s_{\ddT}$.&lt;/p&gt;
&lt;p&gt;Thus we can further expand out $M(I^{-1}(\s(T)) \mid \s_{\ddT})$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; M(I^{-1}(\s(T)) \mid \s_{\ddT}) \\&lt;br&gt;
=\ &amp;amp; M\set{\z \in \Sigma \mid \z(T) \in I^{-1}(\s(T)) \wedge \z\restr{(T-\dt,T)} = \s_{\ddT}} \\&lt;br&gt;
=\ &amp;amp; M\set{\z \in \Sigma \,\middle|\, \do{I}{T}[\z](T) = \s(T) \wedge \do{I}{T}[\z]\restr{(T-\dt,T)} = \s_{\ddT}} \\&lt;br&gt;
=\ &amp;amp; M&#39;(\s(T) \mid \s_{\ddT})\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;$\qed$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;There is one problematic aspect to this equivalence. Taking another look at the first step in the proof,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
&amp;amp; M(\s)\frac{Q(\s(T) \mid \s_{\ddT})}{M(\s(T) \mid \s_{\ddT})} \\ \\&lt;br&gt;
=\ &amp;amp; M(\s_{&amp;gt;T} \mid \s(T)) \cdot M(\s(T) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T})\frac{Q(\s(T) \mid \s_{\ddT})}{M(\s(T) \mid \s_{\ddT})} \\ \\&lt;br&gt;
=\ &amp;amp; M(\s_{&amp;gt;T} \mid \s(T)) \cdot Q(\s(T) \mid \s_{\ddT}) \cdot M(\s_{&amp;lt;T})\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;we make the assumption that $M(\s(T) \mid \s_{\ddT}) \neq 0$. Given the trajectory slice $\s_{\ddT} = \s\restr{(T-\dt,T)}$, there is only one $\t$-valid trajectory which shares the same slice, and so there is only one valid state $\o^*_T$ at time $T$ to follow from $\s\restr{(T-\dt,T)}$. Since $M$ obeys $\t$,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
M(\s(T) \mid \s_{\ddT}) = \d_{\o^*_T}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which is non-zero only if $\s(T) = \o^*_T$. If $\s\restr{(T-\dt,T)}$ is itself not $\t$-valid, we can define $M(\s(T) \mid \s_{\ddT})$ to be an improper probability measure that is always $0$.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d argue that interventions on deterministic trajectories is a limiting case of interventions on probabilistic trajectories where the transition probabilities converge to delta distributions. Then $M(\s(T) \mid \s_{\ddT})/M(\s(T) \mid \s_{\ddT})\to 1$ no matter what and the cancellation works.&lt;/p&gt;
&lt;h2 id=&#34;compatibility-with-modern-physics&#34;&gt;Compatibility with modern physics&lt;/h2&gt;
&lt;p&gt;The generalized formulation of physics, using state space $\O$ and time-evolution function $\t_{\D t}$, is compatible with classical physics and special relativity (for arbitrary choice of Lorentz frame). Is it compatible with quantum mechanics, general relativity, and beyond?&lt;/p&gt;
&lt;p&gt;It is compatible with QM if we are time-evolving quantum state and disregarding measurement. If we wanted to model stochastic measurement outcomes, or stochastic interactions in general, then we could do that using a non-deterministic time-evolution function, i.e. $\t_{\D t}$ is not a proper function and assigns more than one output to a given input. Alternatively, the state $\O$ could contain algorithmically random data which serves as a source of random inputs for $\t_{\D t}$.&lt;/p&gt;
&lt;p&gt;For special relativity, simultaneity is relative, but consistently holding to an arbitrary choice of Lorentz frame will work. Then, there is a $\t_{\D t}$ for every Lorentz frame, and one can transform between these time-evolution functions via Lorentz boosts.&lt;/p&gt;
&lt;p&gt;For general relativity, I am not personally clear on whether there exist global reference frames where there is a single simultaneous state of the universe, even if what is regarded as simultaneous is arbitrarily chosen. In that case, my formulation may break down. However, there should still be a causal DAG. Is it possible to topologically sort that DAG and then organize it into something like time slices? Each such slice would then correspond to a state in $\O$.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Modular Neural Networks</title>
      <link>https://danabo.github.io/blog/posts/modular-neural-networks/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://danabo.github.io/blog/posts/modular-neural-networks/</guid>
      <description>&lt;p&gt;$$&lt;br&gt;
\newcommand{\0}{\mathrm{false}}&lt;br&gt;
\newcommand{\1}{\mathrm{true}}&lt;br&gt;
\newcommand{\mb}{\mathbb}&lt;br&gt;
\newcommand{\mc}{\mathcal}&lt;br&gt;
\newcommand{\mf}{\mathfrak}&lt;br&gt;
\newcommand{\and}{\wedge}&lt;br&gt;
\newcommand{\or}{\vee}&lt;br&gt;
\newcommand{\a}{\alpha}&lt;br&gt;
\newcommand{\s}{\sigma}&lt;br&gt;
\newcommand{\t}{\theta}&lt;br&gt;
\newcommand{\T}{\Theta}&lt;br&gt;
\newcommand{\D}{\Delta}&lt;br&gt;
\newcommand{\o}{\omega}&lt;br&gt;
\newcommand{\O}{\Omega}&lt;br&gt;
\newcommand{\x}{\xi}&lt;br&gt;
\newcommand{\z}{\zeta}&lt;br&gt;
\newcommand{\fa}{\forall}&lt;br&gt;
\newcommand{\ex}{\exists}&lt;br&gt;
\newcommand{\X}{\mc{X}}&lt;br&gt;
\newcommand{\Y}{\mc{Y}}&lt;br&gt;
\newcommand{\Z}{\mc{Z}}&lt;br&gt;
\newcommand{\P}{\Psi}&lt;br&gt;
\newcommand{\y}{\psi}&lt;br&gt;
\newcommand{\p}{\phi}&lt;br&gt;
\newcommand{\l}{\lambda}&lt;br&gt;
\newcommand{\B}{\mb{B}}&lt;br&gt;
\newcommand{\m}{\times}&lt;br&gt;
\newcommand{\E}{\mb{E}}&lt;br&gt;
\newcommand{\H}{\mb{H}}&lt;br&gt;
\newcommand{\I}{\mb{I}}&lt;br&gt;
\newcommand{\R}{\mb{R}}&lt;br&gt;
\newcommand{\e}{\varepsilon}&lt;br&gt;
\newcommand{\set}[1]{\left\{#1\right\}}&lt;br&gt;
\newcommand{\par}[1]{\left(#1\right)}&lt;br&gt;
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}&lt;br&gt;
\newcommand{\inv}[1]{{#1}^{-1}}&lt;br&gt;
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}&lt;br&gt;
\newcommand{\dom}[2]{#1_{\mid #2}}&lt;br&gt;
\newcommand{\df}{\overset{\mathrm{def}}{=}}&lt;br&gt;
\newcommand{\M}{\mc{M}}&lt;br&gt;
\newcommand{\up}[1]{^{(#1)}}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;I wrote up these notes in preparation for my guest lecture in Tom Dean&amp;rsquo;s Stanford course, &lt;a href=&#34;https://web.stanford.edu/class/cs379c/&#34;target=&#34;_blank&#34;&gt;CS379C: Computational Models of the Neocortex&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Selected papers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.04227&#34;target=&#34;_blank&#34;&gt;Towards Modular Algorithm Induction&lt;/a&gt; (Abolafia et al.)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Modular Networks: Learning to Decompose Neural Computation&lt;/a&gt; (Kirsch et al.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;what&#34;&gt;What?&lt;/h1&gt;
&lt;p&gt;What do the phrases &amp;ldquo;modular architectures&amp;rdquo; and &amp;ldquo;learning modular structures&amp;rdquo; mean?&lt;/p&gt;
&lt;p&gt;In programming, a module is a reusable function. Modularity is a design principle, where code is composed of smaller functions which have well defined behavior in isolation, so that the system can be understood by looking at its parts (i.e. &lt;a href=&#34;https://en.wikipedia.org/wiki/Reductionism#In_science&#34;target=&#34;_blank&#34;&gt;reduction&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Modular code satisfies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt;: The internal behavior of one module doesn&amp;rsquo;t affect other modules.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reusability&lt;/strong&gt;: The same module applied in different circumstances, potentially given different kinds of data that follow the same pattern (think &lt;a href=&#34;https://en.wikipedia.org/wiki/Generic_programming&#34;target=&#34;_blank&#34;&gt;generics&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Abstract_type&#34;target=&#34;_blank&#34;&gt;abstract types&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the context of machine learning, a modular neural architecture is a type of neural network composed of smaller neural modules. If data can be said to contain modular structure (e.g. see &lt;a href=&#34;https://arxiv.org/abs/1902.07181&#34;target=&#34;_blank&#34;&gt;Andreas 2019&lt;/a&gt;), then one goal of modular neural networks is to recover that latent structure.&lt;/p&gt;
&lt;p&gt;Pictorial examples of modular neural networks:&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210413141842.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;[Kirsch et al.](https://arxiv.org/abs/1811.05249)&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210413141514.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;[Chang et al.](https://arxiv.org/abs/1807.04640)&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210413141932.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;[Abolafia et al.](https://arxiv.org/abs/2003.04227)&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;why&#34;&gt;Why?&lt;/h1&gt;
&lt;p&gt;Why have modular neural architectures? Is it beneficial for program synthesis? Is it beneficial for machine learning in general?&lt;/p&gt;
&lt;h2 id=&#34;data-invariances&#34;&gt;Data invariances&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1806.06765&#34;target=&#34;_blank&#34;&gt;Modularity Matters: Learning Invariant Relational Reasoning Tasks&lt;/a&gt;  (Jo et al.)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When a dataset has a large number of invariances, a machine learning model must learn to associate a large number of seemingly unrelated patterns with one another, which may exacerbate the interference problem &amp;hellip; One natural way to combat the interference problem is to allow for specialized sub-modules in our architecture. Once we modularize, we reduce the amount of interference that can occur between features in our model. These specialized modules can now learn highly discriminative yet invariant representations while not interfering with each other.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;strong-generalization&#34;&gt;Strong generalization&lt;/h2&gt;
&lt;p&gt;Strong generalization means getting the right answer for an input/task that is very different from the training regime. Sometimes this is called zero-shot learning. Humans seem to be able to this. How does it work?&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.07088&#34;target=&#34;_blank&#34;&gt;Learning Modular Neural Network Policies for Multi-Task and Multi-Robot Transfer&lt;/a&gt; (Devin et al.)&lt;/p&gt;
&lt;p&gt;

  &lt;figure&gt;
    
    &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210413144242.png&#34; alt=&#34;&#34;&gt;
    &lt;figcaption&gt;The robot and task networks are trained end-to-end on different robot-task combinations, with some held out. For example, during training this system does not encounter robot 2 combined with task 2, but does encounter robot 2 and task 2 separately in different situations. At test time, the system has to perform well when robot 2 is combined with task 2.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.01796&#34;target=&#34;_blank&#34;&gt;Modular Multitask Reinforcement Learning with Policy Sketches&lt;/a&gt; (Andreas 2016)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The modular structure of our approach, which associates every high-level action symbol with a discrete subpolicy,naturally induces a library of interpretable policy fragments that are easily recombined. This makes it possible to evaluate our approach under a variety of different data conditions: (1) learning the full collection of tasks jointly via reinforcement, (2) in a zero-shot setting where a policy sketch is available for a held-out task, and (3) in a adaptation setting, where sketches are hidden and the agent must learn to adapt a pretrained policy to reuse high-level actions in a new task.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;hellip; we have shown that it is possible to build agents that share behavior across tasks in order to achieve success in tasks with sparse and delayed rewards. This process induces an inventory of reusable and interpretable subpolicies which can be employed for zero-shot generalization when further sketches are available, and hierarchical reinforcement learning when they are not.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;parameter-sharing&#34;&gt;Parameter sharing&lt;/h2&gt;
&lt;p&gt;Convolutional and recurrent layers can be viewed as modular, in that they &amp;ldquo;stamp&amp;rdquo; a small neural network (with the same parameters) repeatedly in some pattern - repeated over space for CNNs, and repeated over time for RNNs.&lt;/p&gt;
&lt;h2 id=&#34;causal-learning&#34;&gt;Causal learning&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.10893&#34;target=&#34;_blank&#34;&gt;Recurrent Independent Mechanisms&lt;/a&gt; (Goyal et al.)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Physical processes in the world often have a modular structure which human cognition appears toexploit, with complexity emerging through combinations of simpler subsystems. Machine learningseeks to uncover and use regularities in the physical world. Although these regularities manifestthemselves as statistical dependencies, they are ultimately due to dynamic processes governed bycausal physical phenomena.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The notion of independent or autonomous mechanisms has been influential in the field of causal inference. A complex generative model, temporal or not, can be thought of as the composition of independent mechanisms or âcausalâ modules. In the causality community, this is often considered a prerequisite for being able to perform localized interventions upon variables determined by such models (Pearl, 2009). It has been argued that the individual modules tend to remain robust or invariant even as other modules change, e.g., in the case of distribution shift (SchÃ¶lkopf et al., 2012; Peterset al., 2017). This independence is not between the random variables being processed but between the description or parametrization of the mechanisms: learning about one should not tell us anything about another, and adapting one should not require also adapting another. One may hypothesize that if a brain is able to solve multiple problems beyond a single i.i.d. (independent and identically distributed) task, they may exploit the existence of this kind of structure by learning independent mechanisms that can flexibly be reused, composed and re-purposed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;An excerpt from Judea Pearl&amp;rsquo;s book &lt;a href=&#34;http://bayes.cs.ucla.edu/BOOK-2K/&#34;target=&#34;_blank&#34;&gt;Causality, 2nd ed.&lt;/a&gt;. Pearl refers to &amp;ldquo;mechanisms&amp;rdquo; as the nodes in a Bayesian network (e.g. depicted in figure 1.2), which are assumed to be modular: i.e. they are internally isolated, apart from causation traveling along their arrows, and they are reusable in the sense that the graph can be modified, which Pearl calls an intervention.&lt;/p&gt;
&lt;p&gt;

  &lt;img src=&#34;https://danabo.github.io/blog/Pasted%20image%2020210413224425.png&#34; alt=&#34;&#34;&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The example reveals a stronger sense in which causal relationships are more stable than the corresponding probabilistic relationships, a sense that goes beyond their basic ontologicalâepistemological difference. The relationship, âTurning the sprinkler on would not affect the rain,â will remain invariant to changes in the mechanism that regulates how seasons affect sprinklers. In fact, it remains invariant to changes in all mechanisms shown in this causal graph. We thus see that causal relationships exhibit greater robustness to ontological changes as well; they are sensitive to a smaller set of mechanisms. More specifically, and in marked contrast to probabilistic relationships, causal relationships remain invariant to changes in the mechanism that governs the causal variables ($X_3$ in our example).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Regardless of what use is eventually made  of our âunderstandingâ of things, we surely would prefer an understanding in terms of durable relationships, transportable across situations, over those based on transitory relationships. The sense of âcomprehensibilityâ that accompanies an adequate explanation is a natural by-product of the transportability of (and hence of our familiarity with) the causal relationships used in the explanation. It is for reasons of stability that we regard the falling barometer as predicting but not explaining the rain; those predictions are not transportable to situations where the pressure surrounding the barometer is controlled by artificial means. True understanding enables predictions in such novel situations, where some mechanisms change and others are added. It thus seems reasonable to suggest that, in the final analysis, the explanatory account of causation is merely a variant of the manipulative account, albeit one where interventions are dormant. Accordingly, we may as well view our unsatiated quest for understanding âhow data is generatedâ or âhow things workâ as a quest for acquiring the ability to make predictions under a wider range of circumstances, including circumstances in which things are taken apart, reconfigured, or undergo spontaneous change.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;program-induction-and-synthesis&#34;&gt;Program induction and synthesis&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1804.00218&#34;target=&#34;_blank&#34;&gt;HOUDINI: Lifelong Learning as Program Synthesis&lt;/a&gt; (Valkov et al.)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In contrast to standard methods for transfer learning in deep networks, which re-use the first few layers of the network, neural libraries have the potential to enable reuse of higher, more abstract levels of the network, in what could be called high-level transfer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;hellip; our results indicate that the modular representation used in HOUDINI allows it to transfer high-level concepts and avoid negative transfer. We demonstrate that HOUDINI offers greater transfer than progressive neural networks and traditional âlow-levelâ transfer, in which early network layers are inherited from previous tasks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.13404&#34;target=&#34;_blank&#34;&gt;Towards modular and programmable architecture search&lt;/a&gt; (Negrinho et al.)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The building blocks of our search spaces are modules and hyper-parameters. Search spaces are created through the composition of modules and their interactions.Implementing a new module only requires dealing with aspects local to the module. Modules and hyperparameters can be reused across search spaces, and new search spaces can be written by combining existing search spaces.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;how&#34;&gt;How?&lt;/h1&gt;
&lt;p&gt;How can modularity be achieved? Two things need to be simultaneously learned:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The modules themselves.&lt;/li&gt;
&lt;li&gt;How the modules are to be connected together.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Key ideas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Routing&lt;/strong&gt;: How the modules are connected together.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic&lt;/strong&gt; vs &lt;strong&gt;static&lt;/strong&gt; routing: Static routing is fixed for all inputs, while dynamic routing is conditioned on a given input or context. A router is a function that outputs module routing given context.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft&lt;/strong&gt; vs &lt;strong&gt;hard&lt;/strong&gt; routing: Soft routing is a weighted sum across all choices, while hard routing is a single discrete choice. Soft routing is differentiable while hard routing is not.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of soft routing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1410.5401&#34;target=&#34;_blank&#34;&gt;Neural Turing Machines&lt;/a&gt; (Graves et al.)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/nature20101&#34;target=&#34;_blank&#34;&gt;Differentiable neural computers&lt;/a&gt; (Graves et al.)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.08228&#34;target=&#34;_blank&#34;&gt;Neural GPUs Learn Algorithms&lt;/a&gt; (Kaiser et al.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of hard routing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1807.04640&#34;target=&#34;_blank&#34;&gt;Automatically Composing Representation Transformations as a Means for Generalization&lt;/a&gt; (Chang et al.)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.06392&#34;target=&#34;_blank&#34;&gt;Neural Random-Access Machines&lt;/a&gt; (Kurach et al.)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.07275&#34;target=&#34;_blank&#34;&gt;Learning Simple Algorithms from Examples&lt;/a&gt; (Zaremba et al.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Is there something in between soft and hard routing?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1701.06538&#34;target=&#34;_blank&#34;&gt;Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer&lt;/a&gt; (Shazeer et al.)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Modular Networks: Learning to Decompose Neural Computation&lt;/a&gt; (Kirsch et al.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;module-routing-in-detail&#34;&gt;Module routing in detail&lt;/h2&gt;
&lt;p&gt;Following the setup in &lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;In the case of soft routing, think of module weights as probabilities. Instead of summing module outputs, sum probabilities of each possible output. This leads to a natural correspondence between soft and hard routing, where hard routing is sampled from the probability distribution.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt;, the choices are organized into layers, where for each layer $l$ a subset of $M$ modules are selected and their outputs are summed. In &lt;a href=&#34;https://arxiv.org/abs/2003.04227&#34;target=&#34;_blank&#34;&gt;Abolafia et al.&lt;/a&gt;, modules are connected into arbitrary computation graphs.&lt;/p&gt;
&lt;p&gt;To keep things general, let $\mc{A}$ be a set of possible module routing choices, so that an element $a\in\mc{A}$ consists of all  choices needed for the architecture to produce an output (e.g. which modules to use in the computation graph and how they are connected).&lt;/p&gt;
&lt;p&gt;Given a routing choice $a\in\mc{A}$, the architecture output probability given input $x$ and parameters $\t$ is&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
p(y\mid x,a,\t)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Under the hood this output probability may be arrived at by combining the following components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A collection of differentiable functions (modules) $f_{\t\up{i}}\up{i} : \mc{Z}\up{i} \to \mc{Z}\up{j}$ where $\mc{Z}\up{i}$ and $\mc{Z}\up{j}$ are latent spaces (e.g. vectors in $\R^n$), and $\t\up{i}$ are the function parameters. Typically $\t = (\t\up{1},\t\up{2},\dots)$ and each module has independent and isolated parameters. The input $x$ may be initially encoded into a latent space, or some modules may have $\mc{Z} = \mc{X}$ and the data can be fed in directly.&lt;/li&gt;
&lt;li&gt;A function $g$ that takes routing specification $a$, modules $\set{f_i}$, and input $x$, and outputs hidden representation $h$ (also a real vector).&lt;/li&gt;
&lt;li&gt;A distribution &amp;ldquo;head&amp;rdquo; on output space $\mc{Y}$, s.t. $h$ represents the parameters of the distribution. For example, a Gaussian $\mc{N}(y \mid h)$ where $h$ encodes a vector of means and a covariance matrix.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Putting these three things together produces the probability distribution $p(y\mid x,a,\t)$. Given training target $y$, this probability is fully differentiable w.r.t. $\t$ (typically given by the architecture as a &lt;a href=&#34;https://en.wikipedia.org/wiki/Logit&#34;target=&#34;_blank&#34;&gt;logit&lt;/a&gt;, or log-probability). If routing choice $a$ were held fixed, we can train this architecture with standard supervised techniques, e.g. with SGD. Furthermore, if $a\up{k}$ can be provided by some external hard-coded system given training example $(x\up{k}, y\up{k})$, then we can use SGD to maximize the dataset log-probability&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\sum_{k=1}^N \log p(y\up{k}\mid x\up{k},a\up{k},\t)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This is essentially the used in &lt;a href=&#34;https://arxiv.org/abs/1807.04640&#34;target=&#34;_blank&#34;&gt;Chang et al.&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1511.02799&#34;target=&#34;_blank&#34;&gt;Andreas et al.&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ideally, we&amp;rsquo;d like to learn the module routing $a\up{k}$ for each training example $(x\up{k}, y\up{k})$. That means learning a routing function, which produces a routing $a\up{k}$ given input $x\up{k}$. Assuming $\mc{A}$ is a discrete space (routing choices are discrete, e.g. which modules to pick and how to connect them), we cannot differentiate such a function. RL could be used, as in &lt;a href=&#34;https://arxiv.org/abs/2003.04227&#34;target=&#34;_blank&#34;&gt;Abolafia et al.&lt;/a&gt;, but &lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt; provides a more general perspective that allows for differentiation in principle, though intractable in practice.&lt;/p&gt;
&lt;p&gt;Let the routing function output a probability distribution over $a\in\mc{A}$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
p(a \mid x, \p)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;This router is comprised of a function $r_\p$, parameterized by parameters $\p$, that takes in $x$ and outputs a hidden representation $h&#39;$ that, like before, holds the parameters for some probability distribution on $\mc{A}$ (e.g. Gaussian). If $a$ decomposes into a set of independent routing choices, e.g. $a=(a_1, a_2, \dots)$, then $p(a \mid x, \p) = \prod_t p(a_t \mid z_t, \p)$ where $\set{z_t}$ are potentially intermediate outputs from various modules, and at least one $z_t$ equals $x$.&lt;/p&gt;
&lt;p&gt;This gives us a joint distribution on $y$ and $a$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
p(y, a \mid x,\t,\p) = p(y\mid x,a,\t)p(a\mid x, \p)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;To find the probability of $y$ given $x$, independent of routing choice $a$, we marginalize out $a$:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
p(y \mid x, \t, \p) = \sum_{a\in\mc{A}} p(y\mid x,a,\t)p(a\mid x, \p)\,.&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;What this means in terms of training, is that if we are using naive SGD to maximize $\log p(y \mid x, \t, \p)$ w.r.t $\t$ and $\p$ jointly, then we simply sum over all possible routing choices in $\mc{A}$. In practice, this summation is intractable, since the number of routing decisions explodes as the number of modules is increased (as well as with other complexities like multi-input and multi-output modules).&lt;/p&gt;
&lt;p&gt;We can view the same optimization through the lense of the REINFORCE algorithm, which naturally leads to RL optimization, where $p(a\mid x, \p)$ is the policy, $a$ are actions, and $x$ are environment observations. The reward function is then $R(a\mid x) = p(y\mid x,a,\t)$ (or the log-probability of $y$ like in &lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt;). Let the loss function $\mc{L} = p(y \mid x, \t, \p)$. Then the gradient $\nabla_\p \mc{L}$ is given using the &lt;a href=&#34;https://dallascard.github.io/the-reinforce-trick.html&#34;target=&#34;_blank&#34;&gt;&amp;ldquo;log-trick&amp;rdquo;&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\nabla_\p \mc{L} &amp;amp;= \nabla_\p\E_{p(a\mid x, \p)}[p(y\mid x,a,\t)] \\&lt;br&gt;
&amp;amp;= \nabla_\p\E_{p(a\mid x, \p)}[R(a \mid x)] \\&lt;br&gt;
&amp;amp;= \E_{p(a\mid x, \p)}[\nabla_\p\log p(a\mid x, \p) R(a \mid x)]\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;which is the gradient as given in REINFORCE.&lt;/p&gt;
&lt;p&gt;For the experiments in &lt;a href=&#34;https://arxiv.org/abs/2003.04227&#34;target=&#34;_blank&#34;&gt;Abolafia et al.&lt;/a&gt;, I found that scaling up episode collection as much as possible using &lt;a href=&#34;https://arxiv.org/abs/1802.01561&#34;target=&#34;_blank&#34;&gt;IMPALA&lt;/a&gt; partially overcame the usual issues associated with RL: sparse reward, high variance gradients, and lack of stability. Stability is especially an issue when the modules are being trained at the same time, so that the reward being optimized is a moving target. We were not able to jointly learn module and routing, so in &lt;a href=&#34;https://arxiv.org/abs/2003.04227&#34;target=&#34;_blank&#34;&gt;Abolafia et al.&lt;/a&gt; we settled for hard coded modules and focused on getting the router to work.&lt;/p&gt;
&lt;h2 id=&#34;other-kinds-of-training&#34;&gt;Other kinds of training&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt; introduces a modified &lt;a href=&#34;https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm&#34;target=&#34;_blank&#34;&gt;EM algorithm&lt;/a&gt; for simultaneously training $\t$ and $\p$, where routing choice $a$ is the latent variable. As with EM, this is a two step iterative process, where joint probability of $a$ and $x$ is maximized with fixed $a$, and then $a$ is locally improved according to the current probability distribution. Rather than finding the argmax $a$, which is intractable, &lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt; samples an i.i.d. batch from $p(a \mid x, \p)$ and updates $a$ only if a higher probability $a$ is found.&lt;/p&gt;
&lt;p&gt;This training algorithm can be viewed as performing policy gradient training (RL) with a &amp;ldquo;top-$K$&amp;rdquo; buffer, as described in &lt;a href=&#34;https://arxiv.org/abs/1801.03526&#34;target=&#34;_blank&#34;&gt;Neural Program Synthesis with Priority Queue Training&lt;/a&gt; (Abolafia 2018), where $K=1$.&lt;/p&gt;
&lt;p&gt;Here is the general case of this training procedure:&lt;/p&gt;
&lt;p&gt;Let $\tilde{A}_n$ be a length-$S$ i.i.d. sample from $p(a_n \mid x_n,\p)$.&lt;br&gt;
Let $A_n^*$ be a top-$K$ buffer for the $n$-th training example $(x\up{n},y\up{n})$. That means $A_n^*$ holds the best $a_n$ observed over the course of training, scored by $p(a_n \mid x_n,\p)$. Note that this is a moving target, since $\p$ is simultaneously changing, so the joint score of $A_n^*$ can decrease.&lt;br&gt;
Let $A_n = \tilde{A}_n \cup A_n^*$.&lt;/p&gt;
&lt;p&gt;Let $B \subseteq D$ be a minibatch. The Monte Carlo gradient approximation (ala REINFORCE) is:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\nabla_\p\mc{L} \approx \frac{1}{\abs{B}}\sum_{n\in B}\frac{1}{\abs{A_n}}\sum_{a_n \in A_n} \nabla_\p\log p(a\mid x, \p) R(a \mid x)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;where $R(a\mid x) = p(y\mid x,a,\t)$ or $\log p(y\mid x,a,\t)$.&lt;/p&gt;
&lt;p&gt;If $A_n^* = \emptyset$ this setup reduces to usual policy gradient training, and if $\tilde{A}_n = \emptyset$ and $\abs{A_n^*}=1$ (i.e. $K=1$) this reduces to the EM algorithm (Algorithm 1) in &lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1801.03526&#34;target=&#34;_blank&#34;&gt;Abolafia 2018&lt;/a&gt; is similar (where $K\geq 1$), except that the reward function is assumed to be fixed through out training, so the top-$K$ buffer $A_n^*$ cannot diminish in total score over time.&lt;/p&gt;
&lt;h3 id=&#34;information-theory&#34;&gt;Information theory&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt; plots the quantities $H_a$ and $H_b$ as diagnostic tools and measures of &amp;ldquo;module collapse&amp;rdquo; and training convergence. I used the same quantities in my own experiments and found them to be similarly helpful.&lt;/p&gt;
&lt;p&gt;There is theoretical justification for these quantities, and they may even be used as regularizers.&lt;/p&gt;
&lt;p&gt;Let $A$ be the routing random variable and let $X$ be the input random variable, distributed jointly by $p(a \mid x, \p)p(x)$ where $p(x)$ is the true and unknown input distribution.&lt;/p&gt;
&lt;p&gt;The mutual information between $A$ and $X$ decomposes:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\I(A, X) = \H(A) - \H(A \mid X)&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;We cannot explicitly compute these entropy terms because we do not have access to $p(x)$ or $p(a \mid \p)$.&lt;/p&gt;
&lt;p&gt;Assume we can only explicitly compute $p(a \mid x, \p)$. Let&amp;rsquo;s also suppose that we can explcitily compute $\H(A \mid X=x) = -\sum_{a\in\mc{A}} p(a \mid x, \p) \log p(a \mid x, \p)$. Though summing over $\mc{A}$ is still intractable, if we suppose that the routing distribution factors into independent choices which are themselves tractable to enumerate (like the choice for each layer in &lt;a href=&#34;https://arxiv.org/abs/1811.05249&#34;target=&#34;_blank&#34;&gt;Kirsch et al.&lt;/a&gt;): $\mc{A} = \mc{A}_1\times\mc{A}_2\times\dots$ and $a = (a_1, a_2, \dots) \in \mc{A}$ s.t.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
p(a \mid x, \p) = \prod_{l=1}^L p(a_l \mid x, \p_l)\,,&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;then we can tractably compute the conditional entropy as the sum of entropies of each choice:&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\H(A \mid X=x) &amp;amp;= \sum_{l=1}^L \H(A_l \mid X=x) \\&lt;br&gt;
&amp;amp;= \sum_{l=1}^L \sum_{a_l\in\mc{A}_l} p(a_l \mid x, \p_l) \log p(a_l \mid x, \p_l)\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Now we can do a Monte Carlo approximation of the entropy terms of interest using the existing dataset. The statistical properties of this MC estimation is discussed in &lt;a href=&#34;https://arxiv.org/abs/1905.06922&#34;target=&#34;_blank&#34;&gt;On Variational Bounds of Mutual Information&lt;/a&gt;. Let $B \subseteq D$ be a minibatch uniformly sampled from dataset $D$.&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\H(A \mid X) &amp;amp;= -\E_{p(x)}[\H(Y\mid X=x)] \\&lt;br&gt;
&amp;amp;\approx \frac{1}{\abs{B}}\sum_{n \in B} \H(Y\mid X=x_n)&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;Letting $q(a \mid \p)$ be a Monte Carlo approximation of the marginal distribution $p(a\mid \p)$, derived from&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
p(a \mid \p) &amp;amp;= \E_{p(x)}p(a \mid x, \p) \\ &amp;amp;\approx \frac{1}{\abs{B}}\sum_{n \in B}p(a \mid x, \p) \\&lt;br&gt;
&amp;amp;= q(a\mid \p)\,,&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;we can approximate the marginal entropy,&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;
\begin{aligned}&lt;br&gt;
\H(A) &amp;amp;= -\E_{p(a \mid \p)}[\log p(a \mid \p)] \\&lt;br&gt;
&amp;amp;\approx -\E_{q(a \mid \p)}[\log q(a\mid \p)]\,.&lt;br&gt;
\end{aligned}&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;We can think of $\I$ as measuring the bijectivness of the mapping from $x$ to $a$, where $\H(A)$ measures surjectivity and $\H(A\mid X)$ measures anti-injectivity. See &lt;a href=&#34;http://zhat.io/articles/primer-shannon-information#expected-mutual-information&#34;&gt;http://zhat.io/articles/primer-shannon-information#expected-mutual-information&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;$\H(A)$ measures module use. If its maximized, all the modules are getting used equally often.&lt;br&gt;
$\H(A\mid X)$ measures convergence. If its maximized, then the router is completely confident that there is exactly one appropriate routing choice for any given input.&lt;/p&gt;
&lt;p&gt;The ideal is that all modules get used often and the router thinks there is one routing choice per input.&lt;/p&gt;
&lt;p&gt;$\H(A)$ is a typical RL regularizer (called entropy regularization, see &lt;a href=&#34;https://arxiv.org/abs/1602.01783&#34;target=&#34;_blank&#34;&gt;A3C&lt;/a&gt;). However maximizing $\I(A,X)$ (where $x$ are env states) is uncommon. It may be unnecessary since $p(a \mid x)$ naturally becomes peaky over the course of training.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>